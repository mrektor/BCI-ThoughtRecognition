{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model, neighbors, datasets\n",
    "from sklearn import svm\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities functions for working with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_matrix_two_blocks(y, percentage1, percentage2, seed):\n",
    "    \"\"\"Build k indices for k-fold.\"\"\"\n",
    "    if(percentage1+percentage2==1):\n",
    "        num_row = len(y)\n",
    "        #print(num_row)\n",
    "        interval_1 = int(percentage1*num_row);\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        indices = np.random.permutation(num_row);\n",
    "        first_indices = indices[0:interval_1];\n",
    "        second_indices = indices[interval_1:num_row];\n",
    "        return [np.array(first_indices),np.array(second_indices)]\n",
    "    else:\n",
    "        print('>>>>>>>>>>>ERROR:Not valid splitting percentage')\n",
    "        \n",
    "        \n",
    "##\n",
    "## This function reutrn a list of matrices. Each matrix correspond to a question instance in which each row is a channel, and in the coloumn it develop the signal in time\n",
    "## The function also manage to standardize the time length\n",
    "def channels_to_vector(channels): \n",
    "    time_instances=[];\n",
    "    dim=channels.shape;\n",
    "    #find the length min of the signal in the specified temporal instance\n",
    "    length_min=len(channels[0,1]);\n",
    "    for i in range (0,dim[1]):\n",
    "        single_measurement=channels[0,i];\n",
    "        single_length=single_measurement.shape[0]\n",
    "        if(single_length<length_min):\n",
    "                length_min=single_length;\n",
    "    #export the signals\n",
    "    for i in range (0,dim[1]):\n",
    "        single_measurement=channels[0,i];\n",
    "        dim1=single_measurement.shape;\n",
    "        time_instance=[];\n",
    "        for j  in range (0,dim1[1]):\n",
    "            if(len(single_measurement[:,j])>length_min):\n",
    "                single_signal=single_measurement[:,j][0:length_min]\n",
    "            else:\n",
    "                single_signal=single_measurement[:,j]\n",
    "            #put in a list \n",
    "            time_instance.append(np.asarray(single_signal).reshape(len(single_signal),1).T);\n",
    "       # create the matrix of the signals per a single time instance \n",
    "        time_instance=np.concatenate(time_instance);\n",
    "        time_instances.append(time_instance);   \n",
    "    return time_instances;\n",
    "\n",
    "\n",
    "##\n",
    "# Create the train data matrix\n",
    "##\n",
    "## usage\n",
    "def get_feature_matrix_and_labels(channel_structure,label,features_extracted,connectivity_feature):\n",
    "    list_train=[]\n",
    "    list_labels=[]\n",
    "    cont=0;\n",
    "    index_connectivity=0;\n",
    "    list_row=[]\n",
    "    \n",
    "    for time_instance in channel_structure:\n",
    "        dim1=time_instance.shape\n",
    "        #indipendent_components=extract_ICs(time_instance,n_ICA_components);\n",
    "        for j  in range (0,dim1[0]):\n",
    "           \n",
    "            features=features_extracted[cont,:];\n",
    "            list_row.append(features);\n",
    "            cont=cont+1;\n",
    "        \"\"\"feature_dictionary[\"fft_max_frequencies\"]=0;\n",
    "        for single_component in indipendent_components:\n",
    "            features=feature_extraction(single_component,feature_dictionary,features_extracted)\n",
    "            list_row.append(features);\"\"\"\n",
    "        list_row.append(connectivity_feature[index_connectivity,:]);\n",
    "        index_connectivity=index_connectivity+1;\n",
    "        labels=get_labels(1,label);\n",
    "        feature_row=np.concatenate(list_row);\n",
    "        list_train.append(feature_row.reshape(len(feature_row),1).T)\n",
    "        list_labels.append(labels);\n",
    "        list_row=[]\n",
    "        \n",
    "    train_TX=np.concatenate(list_train)\n",
    "    labels=np.concatenate(list_labels,axis=0)\n",
    "    \n",
    "    return train_TX,labels.T.reshape(labels.size)\n",
    "\n",
    "\n",
    "### Description\n",
    "def get_labels(number, string):\n",
    "    if(string==\"No\"):\n",
    "        return np.zeros(number)    \n",
    "    if(string==\"Yes\"):\n",
    "        return np.ones(number)\n",
    "    \n",
    "## description\n",
    "def select_features(weights,matrix,th):\n",
    "    cont=0;\n",
    "    i=0;\n",
    "    while(cont<len(weights)):\n",
    "        if(weights[cont]<th):\n",
    "\n",
    "            mask = np.ones(matrix.shape[1], dtype=bool)\n",
    "            mask[i] = False\n",
    "            matrix=matrix[:,mask]\n",
    "        else:\n",
    "            i=i+1;\n",
    "        cont=cont+1;\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG feature loading\n",
    "\n",
    "Import data from previous analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 120 is out of bounds for axis 0 with size 120",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2ebce5312fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m##Structuring of the data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#the code below create the train matrix with respect to the signal given in \"channel_structure\" but using the features contained in \"features_extracted*\" and in \"connettivity_feature*\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mfeature_dataset_yes_EEG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEEG_yes_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature_matrix_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels_structure_yes_EEG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Yes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_extracted_yes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconnectivity_feature_yes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mfeature_dataset_no_EEG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEEG_no_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature_matrix_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels_structure_no_EEG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"No\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_extracted_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconnectivity_feature_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4a2c7d1d2fd0>\u001b[0m in \u001b[0;36mget_feature_matrix_and_labels\u001b[0;34m(channel_structure, label, features_extracted, connectivity_feature)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_extracted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcont\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mlist_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mcont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcont\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 120 is out of bounds for axis 0 with size 120"
     ]
    }
   ],
   "source": [
    "#Import data from mat files\n",
    "yes_EEG_contents = sio.loadmat('EEGyes.mat')\n",
    "no_EEG_contents = sio.loadmat('EEGno.mat')\n",
    "\n",
    "channels_no_EEG=no_EEG_contents[\"EEGno\"]\n",
    "channels_yes_EEG=yes_EEG_contents[\"EEGyes\"]\n",
    "\n",
    "#Features Loading\n",
    "features_extracted_yes   = sio.loadmat('FeaturesYes.mat')['FeaturesYes']\n",
    "features_extracted_no    = sio.loadmat('FeaturesNO.mat')['FeaturesNo']\n",
    "connectivity_feature_yes = sio.loadmat('ConnectivityFeaturesYes.mat')['ConnectivityFeaturesYes']\n",
    "connectivity_feature_no  = sio.loadmat('ConnectivityFeaturesNo.mat')['ConnectivityFeaturesNo']\n",
    "\n",
    "channels_structure_yes_EEG = channels_to_vector(channels_yes_EEG)\n",
    "channels_structure_no_EEG  = channels_to_vector(channels_no_EEG)\n",
    "\n",
    "##Structuring of the data:\n",
    "#the code below create the train matrix with respect to the signal given in \"channel_structure\" but using the features contained in \"features_extracted*\" and in \"connettivity_feature*\".\n",
    "feature_dataset_yes_EEG, EEG_yes_labels = get_feature_matrix_and_labels(channels_structure_yes_EEG,\"Yes\",features_extracted_yes,connectivity_feature_yes);\n",
    "\n",
    "feature_dataset_no_EEG, EEG_no_labels = get_feature_matrix_and_labels(channels_structure_no_EEG,\"No\",features_extracted_no,connectivity_feature_no);\n",
    "\n",
    "#Merge the labeled data\n",
    "feature_dataset_full = np.concatenate((feature_dataset_yes_EEG, feature_dataset_no_EEG), axis=0 )\n",
    "labels = np.concatenate((EEG_yes_labels,EEG_no_labels), axis=0)\n",
    "\n",
    "\n",
    "print(\"The dataset have shape:\")\n",
    "print(feature_dataset_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leave_one_out(X, Y, classifier):\n",
    "    svm_total_acc_test = []\n",
    "    for i in range(X.shape[0]):\n",
    "#SVM classifier definition\n",
    "        i1 = [j for j in range(X.shape[0])]\n",
    "        i1.remove(i)\n",
    "        i2 = i\n",
    "        train=X[i1,:]\n",
    "        labels_train=Y[i1]\n",
    "\n",
    "        test= X[i2,:]\n",
    "        labels_test=Y[i2]\n",
    "        clf_temp = classifier\n",
    "        clf_temp.fit(train, labels_train)  \n",
    "\n",
    "        #Accuracy on test\n",
    "        predicted_labels_test = clf_temp.predict(test)\n",
    "        SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "        svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "    return(np.mean(svm_total_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the best number of features\n",
    "\n",
    "Only the top-k features that have the best ANOVA F-test Score are retained.\n",
    "An hard-margin (C=1) SVM linear classifier is trained and its performances assessed with a full search leave-one-out\n",
    "\n",
    "Might require some computational time (spoiler: best k seems to be 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot_perf = []\n",
    "for k in range(1,300):\n",
    "    print('progress: ' + str(k/300*100) + ' %')\n",
    "    reducer = SelectKBest(f_classif, k)\n",
    "    feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "    svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "            decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "            max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "            tol=0.001, verbose=False)\n",
    "    perf_temp = leave_one_out(feature_dataset_reduced, labels, svc)\n",
    "    tot_perf.append(perf_temp)\n",
    "\n",
    "best_k = np.argmax(tot_perf)+1\n",
    "print(\"smallest k that gives best Leave-one-out results:\")\n",
    "print(best_k)\n",
    "print()\n",
    "print(\"wich have lead to the top performance:\")\n",
    "print(np.max(tot_perf))\n",
    "\n",
    "\n",
    "#What are those features?\n",
    "reducer = SelectKBest(f_classif, best_k)\n",
    "feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "boolean_vec = reducer.get_support()\n",
    "idx =[]\n",
    "for i in range(len(boolean_vec)): \n",
    "    if boolean_vec[i] == True: idx.append(i)\n",
    "print()\n",
    "print(\"index of features retained:\")\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_k = np.argmax(tot_perf)+1\n",
    "print(\"smallest k that gives best Leave-one-out results:\")\n",
    "print(best_k)\n",
    "print()\n",
    "print(\"wich have lead to the top performance:\")\n",
    "print(np.max(tot_perf))\n",
    "\n",
    "\n",
    "#What are those features?\n",
    "reducer = SelectKBest(f_classif, best_k)\n",
    "feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "boolean_vec = reducer.get_support()\n",
    "idx =[]\n",
    "for i in range(len(boolean_vec)): \n",
    "    if boolean_vec[i] == True: idx.append(i)\n",
    "print()\n",
    "print(\"index of features retained:\")\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of performances with varying size train/test\n",
    "\n",
    "Definition of utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_SVM_experiments(X, Y, clf_parameters, fraction_train_test, num_experiments):\n",
    "    \n",
    "    seed=range(num_experiments)\n",
    "    svm_total_acc_test  = []\n",
    "    svm_total_acc_train = [] \n",
    "    dataset_length=X.shape[0];\n",
    "    \n",
    "    for single_seed in seed:\n",
    "        [i1,i2]=split_matrix_two_blocks(X, fraction_train_test, 1-fraction_train_test,single_seed)\n",
    "        \n",
    "        train =X[i1,:]\n",
    "        labels_train=Y[i1]\n",
    "        \n",
    "        test = X[i2,:]\n",
    "        labels_test=Y[i2]\n",
    "        \n",
    "        #SVM classificator definition\n",
    "        C_best = clf_parameters['C']\n",
    "        gamma_best = clf_parameters['gamma']\n",
    "        kernel_best = clf_parameters['kernel']\n",
    "        \n",
    "        clf = svm.SVC(C = C_best, kernel = kernel_best, gamma = gamma_best, random_state = single_seed)\n",
    "        #SVM fit on train data\n",
    "        clf.fit(train, labels_train)  \n",
    "        #print(test.shape)\n",
    "        #print(labels_test.shape)\n",
    "        \n",
    "        #Accuracy on test\n",
    "        predicted_labels_test = clf.predict(test)\n",
    "        SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "        svm_total_acc_test.append(SVM_accuracy_test)\n",
    "        \n",
    "        \n",
    "        #Accuracy on train\n",
    "        predicted_labels_train = clf.predict(train)\n",
    "        SVM_accuracy_train = get_accuracy(predicted_labels_train, labels_train)\n",
    "        svm_total_acc_train.append(SVM_accuracy_train)\n",
    "        #print(\"Accuracy: \"+ str(SVM_accuracy) + \"; iteration  \" + str(single_seed) )\n",
    "    return svm_total_acc_test, svm_total_acc_train\n",
    "\n",
    "def performance_assesment_fraction(X, Y, num_experiment, clf_parameters):\n",
    "    fracs = np.linspace(0.2,0.9,25)\n",
    "    accuracy_test_mean  = []\n",
    "    accuracy_test_std   = []\n",
    "    accuracy_train_mean = []\n",
    "    accuracy_train_std  = []\n",
    "\n",
    "    for frac_tr_te in fracs:\n",
    "        print(\"Evaluation progress: \" + str(int((frac_tr_te-fracs[0])/(fracs[-1]-fracs[0])*100)) + \" %\")\n",
    "        acc_test, acc_train = classification_SVM_experiments(X, Y, clf_parameters, frac_tr_te, num_experiment)\n",
    "        #saving of metrics of interest\n",
    "        accuracy_test_mean.append(np.mean(acc_test))\n",
    "        accuracy_test_std.append(np.std(acc_test))\n",
    "        accuracy_train_mean.append(np.mean(acc_train))\n",
    "        accuracy_train_std.append(np.std(acc_train))\n",
    "\n",
    "    #plot the figure\n",
    "    plt.figure(figsize=(10, 7), dpi=80)\n",
    "    plt.errorbar(fracs, accuracy_test_mean, yerr=accuracy_test_std, label=\"Error bars plot\", fmt=\"s-\",  linewidth=3)\n",
    "    plt.errorbar(fracs, accuracy_train_mean, yerr=accuracy_train_std, label=\"Error bars plot\", fmt=\"s-\",  linewidth=3)\n",
    "    plt.grid(b=True, which='major', color='k', linestyle='--', alpha = 0.4)\n",
    "    plt.minorticks_on()\n",
    "    plt.title('SVM perfomances over different train/test dataset of reduced features')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Train/test fraction')\n",
    "\n",
    "    plt.legend(['Test Accuracy', 'Train Accuracy'], loc=4)\n",
    "    plt.savefig('train_test_acc_fine_tuned2.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual calling of the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "para = {'C' : 1, 'kernel' : 'linear', 'gamma' : 'auto' } #parameters of the SVM\n",
    "\n",
    "performance_assesment_fraction(feature_dataset_reduced, labels, 5000, para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-Two-out evaluation\n",
    "\n",
    "note: this code could be optimized to be 2 times faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "                    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                    tol=0.001, verbose=False)\n",
    "\n",
    "X = feature_dataset_reduced\n",
    "Y = labels\n",
    "\n",
    "svm_total_acc_test = []\n",
    "#performances assessment with leave three out\n",
    "n = X.shape[0]\n",
    "for i in range(n):\n",
    "    print(\"progress: \" + str(i/n*100) + \" %\")\n",
    "    for j in range(n):\n",
    "        if(j!=i):\n",
    "            i1 = [l for l in range(n)]\n",
    "            i1.remove(i)\n",
    "            i1.remove(j)\n",
    "            i2 = [i, j]\n",
    "                    \n",
    "            train=X[i1,:]\n",
    "            labels_train=Y[i1]\n",
    "\n",
    "            test= X[i2,:]\n",
    "            labels_test=Y[i2]\n",
    " \n",
    "            clf = svc      \n",
    "            #SVM fit on train data\n",
    "            clf.fit(train, labels_train)  \n",
    "\n",
    "            #Accuracy on test\n",
    "            predicted_labels_test = clf.predict(test)\n",
    "            SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "            svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"mean of test accuracy\")\n",
    "print(np.mean(svm_total_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-three-out Evaluation\n",
    "\n",
    "note: this code could be optimized to be 3! = 6 times faster, this will take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "                    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                    tol=0.001, verbose=False)\n",
    "\n",
    "X = feature_dataset_reduced\n",
    "Y = labels\n",
    "\n",
    "svm_total_acc_test = []\n",
    "#performances assessment with leave three out\n",
    "n = X.shape[0]\n",
    "for i in range(n):\n",
    "    print(\"progress: \" + str(i/n*100) + \" %\")\n",
    "    for j in range(n):\n",
    "        if(j!=i):\n",
    "            for k in range(n):\n",
    "                if(k!=j and k!=i):\n",
    "            #SVM classifier definition\n",
    "                    i1 = [l for l in range(n)]\n",
    "                    i1.remove(i)\n",
    "                    i1.remove(j)\n",
    "                    i1.remove(k)\n",
    "                    i2 = [i, j, k]\n",
    "                    \n",
    "                    train=X[i1,:]\n",
    "                    labels_train=Y[i1]\n",
    "\n",
    "                    test= X[i2,:]\n",
    "                    labels_test=Y[i2]\n",
    "                #print(i1)\n",
    "                #print(i2)\n",
    "                    clf = svc      \n",
    "                #SVM fit on train data\n",
    "                    clf.fit(train, labels_train)  \n",
    "\n",
    "                #Accuracy on test\n",
    "                    predicted_labels_test = clf.predict(test)\n",
    "                    SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "                    svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"mean of test accuracy\")\n",
    "print(np.mean(svm_total_acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
