{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model, neighbors,datasets\n",
    "from lib.helpers import *\n",
    "from sklearn import svm\n",
    "from lib.cross_validations_lib import *\n",
    "#import peakutils\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities functions for working with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_matrix_two_blocks(y, percentage1, percentage2, seed):\n",
    "    \"\"\"Build k indices for k-fold.\"\"\"\n",
    "    if(percentage1+percentage2==1):\n",
    "        num_row = len(y)\n",
    "        #print(num_row)\n",
    "        interval_1 = int(percentage1*num_row);\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        indices = np.random.permutation(num_row);\n",
    "        first_indices = indices[0:interval_1];\n",
    "        second_indices = indices[interval_1:num_row];\n",
    "        return [np.array(first_indices),np.array(second_indices)]\n",
    "    else:\n",
    "        print('>>>>>>>>>>>ERROR:Not valid splitting percentage')\n",
    "        \n",
    "        \n",
    "##\n",
    "## This function reutrn a list of matrices. Each matrix correspond to a question instance in which each row is a channel, and in the coloumn it develop the signal in time\n",
    "## The function also manage to standardize the time length\n",
    "def channels_to_vector(channels): \n",
    "    time_instances=[];\n",
    "    dim=channels.shape;\n",
    "    #find the length min of the signal in the specified temporal instance\n",
    "    length_min=len(channels[0,1]);\n",
    "    for i in range (0,dim[1]):\n",
    "        single_measurement=channels[0,i];\n",
    "        single_length=single_measurement.shape[0]\n",
    "        if(single_length<length_min):\n",
    "                length_min=single_length;\n",
    "    #export the signals\n",
    "    for i in range (0,dim[1]):\n",
    "        single_measurement=channels[0,i];\n",
    "        dim1=single_measurement.shape;\n",
    "        time_instance=[];\n",
    "        for j  in range (0,dim1[1]):\n",
    "            if(len(single_measurement[:,j])>length_min):\n",
    "                single_signal=single_measurement[:,j][0:length_min]\n",
    "            else:\n",
    "                single_signal=single_measurement[:,j]\n",
    "            #put in a list \n",
    "            time_instance.append(np.asarray(single_signal).reshape(len(single_signal),1).T);\n",
    "       # create the matrix of the signals per a single time instance \n",
    "        time_instance=np.concatenate(time_instance);\n",
    "        time_instances.append(time_instance);   \n",
    "    return time_instances;\n",
    "\n",
    "\n",
    "##\n",
    "# Create the train data matrix\n",
    "##\n",
    "## usage\n",
    "def get_feature_matrix_and_labels(channel_structure,label,features_extracted,connectivity_feature):\n",
    "    list_train=[]\n",
    "    list_labels=[]\n",
    "    cont=0;\n",
    "    index_connectivity=0;\n",
    "    list_row=[]\n",
    "    \n",
    "    for time_instance in channel_structure:\n",
    "        dim1=time_instance.shape\n",
    "        #indipendent_components=extract_ICs(time_instance,n_ICA_components);\n",
    "        for j  in range (0,dim1[0]):\n",
    "           \n",
    "            features=features_extracted[cont,:];\n",
    "            list_row.append(features);\n",
    "            cont=cont+1;\n",
    "        \"\"\"feature_dictionary[\"fft_max_frequencies\"]=0;\n",
    "        for single_component in indipendent_components:\n",
    "            features=feature_extraction(single_component,feature_dictionary,features_extracted)\n",
    "            list_row.append(features);\"\"\"\n",
    "        list_row.append(connectivity_feature[index_connectivity,:]);\n",
    "        index_connectivity=index_connectivity+1;\n",
    "        labels=get_labels(1,label);\n",
    "        feature_row=np.concatenate(list_row);\n",
    "        list_train.append(feature_row.reshape(len(feature_row),1).T)\n",
    "        list_labels.append(labels);\n",
    "        list_row=[]\n",
    "        \n",
    "    train_TX=np.concatenate(list_train)\n",
    "    labels=np.concatenate(list_labels,axis=0)\n",
    "    \n",
    "    return train_TX,labels.T.reshape(labels.size)\n",
    "\n",
    "\n",
    "### Description\n",
    "def get_labels(number, string):\n",
    "    if(string==\"No\"):\n",
    "        return np.zeros(number)    \n",
    "    if(string==\"Yes\"):\n",
    "        return np.ones(number)\n",
    "    \n",
    "## description\n",
    "def select_features(weights,matrix,th):\n",
    "    cont=0;\n",
    "    i=0;\n",
    "    while(cont<len(weights)):\n",
    "        if(weights[cont]<th):\n",
    "\n",
    "            mask = np.ones(matrix.shape[1], dtype=bool)\n",
    "            mask[i] = False\n",
    "            matrix=matrix[:,mask]\n",
    "        else:\n",
    "            i=i+1;\n",
    "        cont=cont+1;\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG feature loading\n",
    "\n",
    "Import data from previous analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset have shape:\n",
      "(60, 386)\n"
     ]
    }
   ],
   "source": [
    "#Import data from mat files\n",
    "yes_EEG_contents = sio.loadmat('EEGyes.mat')\n",
    "no_EEG_contents = sio.loadmat('EEGno.mat')\n",
    "\n",
    "channels_no_EEG=no_EEG_contents[\"EEGno\"]\n",
    "channels_yes_EEG=yes_EEG_contents[\"EEGyes\"]\n",
    "\n",
    "#Features Loading\n",
    "features_extracted_yes   = sio.loadmat('FeaturesYes.mat')['FeaturesYes']\n",
    "features_extracted_no    = sio.loadmat('FeaturesNO.mat')['FeaturesNo']\n",
    "connectivity_feature_yes = sio.loadmat('ConnectivityFeaturesYes.mat')['ConnectivityFeaturesYes']\n",
    "connectivity_feature_no  = sio.loadmat('ConnectivityFeaturesNo.mat')['ConnectivityFeaturesNo']\n",
    "\n",
    "channels_structure_yes_EEG = channels_to_vector(channels_yes_EEG)\n",
    "channels_structure_no_EEG  = channels_to_vector(channels_no_EEG)\n",
    "\n",
    "##Structuring of the data:\n",
    "#the code below create the train matrix with respect to the signal given in \"channel_structure\" but using the features contained in \"features_extracted*\" and in \"connettivity_feature*\".\n",
    "feature_dataset_yes_EEG, EEG_yes_labels = get_feature_matrix_and_labels(channels_structure_yes_EEG,\"Yes\",features_extracted_yes,connectivity_feature_yes);\n",
    "\n",
    "feature_dataset_no_EEG, EEG_no_labels = get_feature_matrix_and_labels(channels_structure_no_EEG,\"No\",features_extracted_no,connectivity_feature_no);\n",
    "\n",
    "#Merge the labeled data\n",
    "feature_dataset_full = np.concatenate((feature_dataset_yes_EEG, feature_dataset_no_EEG), axis=0 )\n",
    "labels = np.concatenate((EEG_yes_labels,EEG_no_labels), axis=0)\n",
    "\n",
    "\n",
    "print(\"The dataset have shape:\")\n",
    "print(feature_dataset_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leave_one_out(X, Y, classifier):\n",
    "    svm_total_acc_test = []\n",
    "    for i in range(X.shape[0]):\n",
    "#SVM classifier definition\n",
    "        i1 = [j for j in range(X.shape[0])]\n",
    "        i1.remove(i)\n",
    "        i2 = i\n",
    "        train=X[i1,:]\n",
    "        labels_train=Y[i1]\n",
    "\n",
    "        test= X[i2,:]\n",
    "        labels_test=Y[i2]\n",
    "        clf_temp = classifier\n",
    "        clf_temp.fit(train, labels_train)  \n",
    "\n",
    "        #Accuracy on test\n",
    "        predicted_labels_test = clf_temp.predict(test)\n",
    "        SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "        svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "    return(np.mean(svm_total_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the best number of features\n",
    "\n",
    "Only the top-k features that have the best ANOVA F-test Score are retained.\n",
    "An hard-margin (C=1) SVM linear classifier is trained and its performances assessed with a full search leave-one-out\n",
    "\n",
    "Might require some computational time (spoiler: best k seems to be 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 0.33333333333333337 %\n",
      "progress: 0.6666666666666667 %\n",
      "progress: 1.0 %\n",
      "progress: 1.3333333333333335 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 1.6666666666666667 %\n",
      "progress: 2.0 %\n",
      "progress: 2.3333333333333335 %\n",
      "progress: 2.666666666666667 %\n",
      "progress: 3.0 %\n",
      "progress: 3.3333333333333335 %\n",
      "progress: 3.6666666666666665 %\n",
      "progress: 4.0 %\n",
      "progress: 4.333333333333334 %\n",
      "progress: 4.666666666666667 %\n",
      "progress: 5.0 %\n",
      "progress: 5.333333333333334 %\n",
      "progress: 5.666666666666666 %\n",
      "progress: 6.0 %\n",
      "progress: 6.333333333333334 %\n",
      "progress: 6.666666666666667 %\n",
      "progress: 7.000000000000001 %\n",
      "progress: 7.333333333333333 %\n",
      "progress: 7.666666666666666 %\n",
      "progress: 8.0 %\n",
      "progress: 8.333333333333332 %\n",
      "progress: 8.666666666666668 %\n",
      "progress: 9.0 %\n",
      "progress: 9.333333333333334 %\n",
      "progress: 9.666666666666666 %\n",
      "progress: 10.0 %\n",
      "progress: 10.333333333333334 %\n",
      "progress: 10.666666666666668 %\n",
      "progress: 11.0 %\n",
      "progress: 11.333333333333332 %\n",
      "progress: 11.666666666666666 %\n",
      "progress: 12.0 %\n",
      "progress: 12.333333333333334 %\n",
      "progress: 12.666666666666668 %\n",
      "progress: 13.0 %\n",
      "progress: 13.333333333333334 %\n",
      "progress: 13.666666666666666 %\n",
      "progress: 14.000000000000002 %\n",
      "progress: 14.333333333333334 %\n",
      "progress: 14.666666666666666 %\n",
      "progress: 15.0 %\n",
      "progress: 15.333333333333332 %\n",
      "progress: 15.666666666666668 %\n",
      "progress: 16.0 %\n",
      "progress: 16.333333333333332 %\n",
      "progress: 16.666666666666664 %\n",
      "progress: 17.0 %\n",
      "progress: 17.333333333333336 %\n",
      "progress: 17.666666666666668 %\n",
      "progress: 18.0 %\n",
      "progress: 18.333333333333332 %\n",
      "progress: 18.666666666666668 %\n",
      "progress: 19.0 %\n",
      "progress: 19.333333333333332 %\n",
      "progress: 19.666666666666664 %\n",
      "progress: 20.0 %\n",
      "progress: 20.333333333333332 %\n",
      "progress: 20.666666666666668 %\n",
      "progress: 21.0 %\n",
      "progress: 21.333333333333336 %\n",
      "progress: 21.666666666666668 %\n",
      "progress: 22.0 %\n",
      "progress: 22.333333333333332 %\n",
      "progress: 22.666666666666664 %\n",
      "progress: 23.0 %\n",
      "progress: 23.333333333333332 %\n",
      "progress: 23.666666666666668 %\n",
      "progress: 24.0 %\n",
      "progress: 24.333333333333336 %\n",
      "progress: 24.666666666666668 %\n",
      "progress: 25.0 %\n",
      "progress: 25.333333333333336 %\n",
      "progress: 25.666666666666664 %\n",
      "progress: 26.0 %\n",
      "progress: 26.333333333333332 %\n",
      "progress: 26.666666666666668 %\n",
      "progress: 27.0 %\n",
      "progress: 27.333333333333332 %\n",
      "progress: 27.666666666666668 %\n",
      "progress: 28.000000000000004 %\n",
      "progress: 28.333333333333332 %\n",
      "progress: 28.666666666666668 %\n",
      "progress: 28.999999999999996 %\n",
      "progress: 29.333333333333332 %\n",
      "progress: 29.666666666666668 %\n",
      "progress: 30.0 %\n",
      "progress: 30.333333333333336 %\n",
      "progress: 30.666666666666664 %\n",
      "progress: 31.0 %\n",
      "progress: 31.333333333333336 %\n",
      "progress: 31.666666666666664 %\n",
      "progress: 32.0 %\n",
      "progress: 32.33333333333333 %\n",
      "progress: 32.666666666666664 %\n",
      "progress: 33.0 %\n",
      "progress: 33.33333333333333 %\n",
      "progress: 33.666666666666664 %\n",
      "progress: 34.0 %\n",
      "progress: 34.333333333333336 %\n",
      "progress: 34.66666666666667 %\n",
      "progress: 35.0 %\n",
      "progress: 35.333333333333336 %\n",
      "progress: 35.66666666666667 %\n",
      "progress: 36.0 %\n",
      "progress: 36.333333333333336 %\n",
      "progress: 36.666666666666664 %\n",
      "progress: 37.0 %\n",
      "progress: 37.333333333333336 %\n",
      "progress: 37.666666666666664 %\n",
      "progress: 38.0 %\n",
      "progress: 38.333333333333336 %\n",
      "progress: 38.666666666666664 %\n",
      "progress: 39.0 %\n",
      "progress: 39.33333333333333 %\n",
      "progress: 39.666666666666664 %\n",
      "progress: 40.0 %\n",
      "progress: 40.33333333333333 %\n",
      "progress: 40.666666666666664 %\n",
      "progress: 41.0 %\n",
      "progress: 41.333333333333336 %\n",
      "progress: 41.66666666666667 %\n",
      "progress: 42.0 %\n",
      "progress: 42.333333333333336 %\n",
      "progress: 42.66666666666667 %\n",
      "progress: 43.0 %\n",
      "progress: 43.333333333333336 %\n",
      "progress: 43.666666666666664 %\n",
      "progress: 44.0 %\n",
      "progress: 44.333333333333336 %\n",
      "progress: 44.666666666666664 %\n",
      "progress: 45.0 %\n",
      "progress: 45.33333333333333 %\n",
      "progress: 45.666666666666664 %\n",
      "progress: 46.0 %\n",
      "progress: 46.33333333333333 %\n",
      "progress: 46.666666666666664 %\n",
      "progress: 47.0 %\n",
      "progress: 47.333333333333336 %\n",
      "progress: 47.66666666666667 %\n",
      "progress: 48.0 %\n",
      "progress: 48.333333333333336 %\n",
      "progress: 48.66666666666667 %\n",
      "progress: 49.0 %\n",
      "progress: 49.333333333333336 %\n",
      "progress: 49.666666666666664 %\n",
      "progress: 50.0 %\n",
      "progress: 50.33333333333333 %\n",
      "progress: 50.66666666666667 %\n",
      "progress: 51.0 %\n",
      "progress: 51.33333333333333 %\n",
      "progress: 51.66666666666667 %\n",
      "progress: 52.0 %\n",
      "progress: 52.33333333333333 %\n",
      "progress: 52.666666666666664 %\n",
      "progress: 53.0 %\n",
      "progress: 53.333333333333336 %\n",
      "progress: 53.666666666666664 %\n",
      "progress: 54.0 %\n",
      "progress: 54.333333333333336 %\n",
      "progress: 54.666666666666664 %\n",
      "progress: 55.00000000000001 %\n",
      "progress: 55.333333333333336 %\n",
      "progress: 55.666666666666664 %\n",
      "progress: 56.00000000000001 %\n",
      "progress: 56.333333333333336 %\n",
      "progress: 56.666666666666664 %\n",
      "progress: 56.99999999999999 %\n",
      "progress: 57.333333333333336 %\n",
      "progress: 57.666666666666664 %\n",
      "progress: 57.99999999999999 %\n",
      "progress: 58.333333333333336 %\n",
      "progress: 58.666666666666664 %\n",
      "progress: 59.0 %\n",
      "progress: 59.333333333333336 %\n",
      "progress: 59.66666666666667 %\n",
      "progress: 60.0 %\n",
      "progress: 60.333333333333336 %\n",
      "progress: 60.66666666666667 %\n",
      "progress: 61.0 %\n",
      "progress: 61.33333333333333 %\n",
      "progress: 61.66666666666667 %\n",
      "progress: 62.0 %\n",
      "progress: 62.33333333333333 %\n",
      "progress: 62.66666666666667 %\n",
      "progress: 63.0 %\n",
      "progress: 63.33333333333333 %\n",
      "progress: 63.66666666666667 %\n",
      "progress: 64.0 %\n",
      "progress: 64.33333333333333 %\n",
      "progress: 64.66666666666666 %\n",
      "progress: 65.0 %\n",
      "progress: 65.33333333333333 %\n",
      "progress: 65.66666666666666 %\n",
      "progress: 66.0 %\n",
      "progress: 66.33333333333333 %\n",
      "progress: 66.66666666666666 %\n",
      "progress: 67.0 %\n",
      "progress: 67.33333333333333 %\n",
      "progress: 67.66666666666666 %\n",
      "progress: 68.0 %\n",
      "progress: 68.33333333333333 %\n",
      "progress: 68.66666666666667 %\n",
      "progress: 69.0 %\n",
      "progress: 69.33333333333334 %\n",
      "progress: 69.66666666666667 %\n",
      "progress: 70.0 %\n",
      "progress: 70.33333333333334 %\n",
      "progress: 70.66666666666667 %\n",
      "progress: 71.0 %\n",
      "progress: 71.33333333333334 %\n",
      "progress: 71.66666666666667 %\n",
      "progress: 72.0 %\n",
      "progress: 72.33333333333334 %\n",
      "progress: 72.66666666666667 %\n",
      "progress: 73.0 %\n",
      "progress: 73.33333333333333 %\n",
      "progress: 73.66666666666667 %\n",
      "progress: 74.0 %\n",
      "progress: 74.33333333333333 %\n",
      "progress: 74.66666666666667 %\n",
      "progress: 75.0 %\n",
      "progress: 75.33333333333333 %\n",
      "progress: 75.66666666666667 %\n",
      "progress: 76.0 %\n",
      "progress: 76.33333333333333 %\n",
      "progress: 76.66666666666667 %\n",
      "progress: 77.0 %\n",
      "progress: 77.33333333333333 %\n",
      "progress: 77.66666666666666 %\n",
      "progress: 78.0 %\n",
      "progress: 78.33333333333333 %\n",
      "progress: 78.66666666666666 %\n",
      "progress: 79.0 %\n",
      "progress: 79.33333333333333 %\n",
      "progress: 79.66666666666666 %\n",
      "progress: 80.0 %\n",
      "progress: 80.33333333333333 %\n",
      "progress: 80.66666666666666 %\n",
      "progress: 81.0 %\n",
      "progress: 81.33333333333333 %\n",
      "progress: 81.66666666666667 %\n",
      "progress: 82.0 %\n",
      "progress: 82.33333333333334 %\n",
      "progress: 82.66666666666667 %\n",
      "progress: 83.0 %\n",
      "progress: 83.33333333333334 %\n",
      "progress: 83.66666666666667 %\n",
      "progress: 84.0 %\n",
      "progress: 84.33333333333334 %\n",
      "progress: 84.66666666666667 %\n",
      "progress: 85.0 %\n",
      "progress: 85.33333333333334 %\n",
      "progress: 85.66666666666667 %\n",
      "progress: 86.0 %\n",
      "progress: 86.33333333333333 %\n",
      "progress: 86.66666666666667 %\n",
      "progress: 87.0 %\n",
      "progress: 87.33333333333333 %\n",
      "progress: 87.66666666666667 %\n",
      "progress: 88.0 %\n",
      "progress: 88.33333333333333 %\n",
      "progress: 88.66666666666667 %\n",
      "progress: 89.0 %\n",
      "progress: 89.33333333333333 %\n",
      "progress: 89.66666666666666 %\n",
      "progress: 90.0 %\n",
      "progress: 90.33333333333333 %\n",
      "progress: 90.66666666666666 %\n",
      "progress: 91.0 %\n",
      "progress: 91.33333333333333 %\n",
      "progress: 91.66666666666666 %\n",
      "progress: 92.0 %\n",
      "progress: 92.33333333333333 %\n",
      "progress: 92.66666666666666 %\n",
      "progress: 93.0 %\n",
      "progress: 93.33333333333333 %\n",
      "progress: 93.66666666666667 %\n",
      "progress: 94.0 %\n",
      "progress: 94.33333333333334 %\n",
      "progress: 94.66666666666667 %\n",
      "progress: 95.0 %\n",
      "progress: 95.33333333333334 %\n",
      "progress: 95.66666666666667 %\n",
      "progress: 96.0 %\n",
      "progress: 96.33333333333334 %\n",
      "progress: 96.66666666666667 %\n",
      "progress: 97.0 %\n",
      "progress: 97.33333333333334 %\n",
      "progress: 97.66666666666667 %\n",
      "progress: 98.0 %\n",
      "progress: 98.33333333333333 %\n",
      "progress: 98.66666666666667 %\n",
      "progress: 99.0 %\n",
      "progress: 99.33333333333333 %\n",
      "progress: 99.66666666666667 %\n",
      "smallest k that gives best Leave-one-out results:\n",
      "21\n",
      "\n",
      "wich have lead to the top performance:\n",
      "0.9666666666666667\n",
      "\n",
      "index of features retained:\n",
      "[66, 67, 71, 82, 115, 165, 169, 173, 192, 244, 256, 260, 262, 272, 276, 287, 288, 291, 292, 304, 320]\n"
     ]
    }
   ],
   "source": [
    "tot_perf = []\n",
    "for k in range(1,300):\n",
    "    print('progress: ' + str(k/300*100) + ' %')\n",
    "    reducer = SelectKBest(f_classif, k)\n",
    "    feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "    svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "            decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "            max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "            tol=0.001, verbose=False)\n",
    "    perf_temp = leave_one_out(feature_dataset_reduced, labels, svc)\n",
    "    tot_perf.append(perf_temp)\n",
    "\n",
    "best_k = np.argmax(tot_perf)+1\n",
    "print(\"smallest k that gives best Leave-one-out results:\")\n",
    "print(best_k)\n",
    "print()\n",
    "print(\"wich have lead to the top performance:\")\n",
    "print(np.max(tot_perf))\n",
    "\n",
    "\n",
    "#What are those features?\n",
    "reducer = SelectKBest(f_classif, best_k)\n",
    "feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "boolean_vec = reducer.get_support()\n",
    "idx =[]\n",
    "for i in range(len(boolean_vec)): \n",
    "    if boolean_vec[i] == True: idx.append(i)\n",
    "print()\n",
    "print(\"index of features retained:\")\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest k that gives best Leave-one-out results:\n",
      "21\n",
      "\n",
      "wich have lead to the top performance:\n",
      "0.9666666666666667\n",
      "\n",
      "index of features retained:\n",
      "[66, 67, 71, 82, 115, 165, 169, 173, 192, 244, 256, 260, 262, 272, 276, 287, 288, 291, 292, 304, 320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "best_k = np.argmax(tot_perf)+1\n",
    "print(\"smallest k that gives best Leave-one-out results:\")\n",
    "print(best_k)\n",
    "print()\n",
    "print(\"wich have lead to the top performance:\")\n",
    "print(np.max(tot_perf))\n",
    "\n",
    "\n",
    "#What are those features?\n",
    "reducer = SelectKBest(f_classif, best_k)\n",
    "feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "boolean_vec = reducer.get_support()\n",
    "idx =[]\n",
    "for i in range(len(boolean_vec)): \n",
    "    if boolean_vec[i] == True: idx.append(i)\n",
    "print()\n",
    "print(\"index of features retained:\")\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of performances with varying size train/test\n",
    "\n",
    "Definition of utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_SVM_experiments(X, Y, clf_parameters, fraction_train_test, num_experiments):\n",
    "    \n",
    "    seed=range(num_experiments)\n",
    "    svm_total_acc_test  = []\n",
    "    svm_total_acc_train = [] \n",
    "    dataset_length=X.shape[0];\n",
    "    \n",
    "    for single_seed in seed:\n",
    "        [i1,i2]=split_matrix_two_blocks(X, fraction_train_test, 1-fraction_train_test,single_seed)\n",
    "        \n",
    "        train =X[i1,:]\n",
    "        labels_train=Y[i1]\n",
    "        \n",
    "        test = X[i2,:]\n",
    "        labels_test=Y[i2]\n",
    "        \n",
    "        #SVM classificator definition\n",
    "        C_best = clf_parameters['C']\n",
    "        gamma_best = clf_parameters['gamma']\n",
    "        kernel_best = clf_parameters['kernel']\n",
    "        \n",
    "        clf = svm.SVC(C = C_best, kernel = kernel_best, gamma = gamma_best, random_state = single_seed)\n",
    "        #SVM fit on train data\n",
    "        clf.fit(train, labels_train)  \n",
    "        #print(test.shape)\n",
    "        #print(labels_test.shape)\n",
    "        \n",
    "        #Accuracy on test\n",
    "        predicted_labels_test = clf.predict(test)\n",
    "        SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "        svm_total_acc_test.append(SVM_accuracy_test)\n",
    "        \n",
    "        \n",
    "        #Accuracy on train\n",
    "        predicted_labels_train = clf.predict(train)\n",
    "        SVM_accuracy_train = get_accuracy(predicted_labels_train, labels_train)\n",
    "        svm_total_acc_train.append(SVM_accuracy_train)\n",
    "        #print(\"Accuracy: \"+ str(SVM_accuracy) + \"; iteration  \" + str(single_seed) )\n",
    "    return svm_total_acc_test, svm_total_acc_train\n",
    "\n",
    "def performance_assesment_fraction(X, Y, num_experiment, clf_parameters):\n",
    "    fracs = np.linspace(0.2,0.9,25)\n",
    "    accuracy_test_mean  = []\n",
    "    accuracy_test_std   = []\n",
    "    accuracy_train_mean = []\n",
    "    accuracy_train_std  = []\n",
    "\n",
    "    for frac_tr_te in fracs:\n",
    "        print(\"Evaluation progress: \" + str(int((frac_tr_te-fracs[0])/(fracs[-1]-fracs[0])*100)) + \" %\")\n",
    "        acc_test, acc_train = classification_SVM_experiments(X, Y, clf_parameters, frac_tr_te, num_experiment)\n",
    "        #saving of metrics of interest\n",
    "        accuracy_test_mean.append(np.mean(acc_test))\n",
    "        accuracy_test_std.append(np.std(acc_test))\n",
    "        accuracy_train_mean.append(np.mean(acc_train))\n",
    "        accuracy_train_std.append(np.std(acc_train))\n",
    "\n",
    "    #plot the figure\n",
    "    plt.figure(figsize=(10, 7), dpi=80)\n",
    "    plt.errorbar(fracs, accuracy_test_mean, yerr=accuracy_test_std, label=\"Error bars plot\", fmt=\"s-\",  linewidth=3)\n",
    "    plt.errorbar(fracs, accuracy_train_mean, yerr=accuracy_train_std, label=\"Error bars plot\", fmt=\"s-\",  linewidth=3)\n",
    "    plt.grid(b=True, which='major', color='k', linestyle='--', alpha = 0.4)\n",
    "    plt.minorticks_on()\n",
    "    plt.title('SVM perfomances over different train/test dataset of reduced features')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Train/test fraction')\n",
    "\n",
    "    plt.legend(['Test Accuracy', 'Train Accuracy'], loc=4)\n",
    "    plt.savefig('train_test_acc_fine_tuned2.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual calling of the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation progress: 0 %\n",
      "Evaluation progress: 4 %\n",
      "Evaluation progress: 8 %\n",
      "Evaluation progress: 12 %\n",
      "Evaluation progress: 16 %\n",
      "Evaluation progress: 20 %\n",
      "Evaluation progress: 25 %\n",
      "Evaluation progress: 29 %\n",
      "Evaluation progress: 33 %\n",
      "Evaluation progress: 37 %\n",
      "Evaluation progress: 41 %\n",
      "Evaluation progress: 45 %\n",
      "Evaluation progress: 50 %\n",
      "Evaluation progress: 54 %\n",
      "Evaluation progress: 58 %\n",
      "Evaluation progress: 62 %\n",
      "Evaluation progress: 66 %\n",
      "Evaluation progress: 70 %\n",
      "Evaluation progress: 74 %\n",
      "Evaluation progress: 79 %\n",
      "Evaluation progress: 83 %\n",
      "Evaluation progress: 87 %\n",
      "Evaluation progress: 91 %\n",
      "Evaluation progress: 95 %\n",
      "Evaluation progress: 100 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq4AAAHnCAYAAAB5QN8/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAAIABJREFUeJzs3Xl8W2ed7/HPz7a8JE7sOFvjuFnqNE1bku5NupO0cGdI\nYChMUphSpgwwDHCZgQJ3ZmDgMgxc1oGWy5SWKUO5kGEmYS1ugdImbWnahO5JS9s0adI0S7PbcRIv\nsv3cP86RLcuSLPuRLEv+vl8vvWxJR+c8+upI+vnxc55jzjlEREREREa7knw3QEREREQkEypcRURE\nRKQgqHAVERERkYKgwlVERERECoIKVxEREREpCCpcRURERKQgqHAVERERkYKgwlWKmpnNMbPfm9kx\nM3sk3+2R9MzsGjNzcdc/ZWb3xl2PmNlqMztiZsfNrMbMJpnZPWbWbGa789Py/EnMqNCZ2W4zuzHf\n7RgJZvYGM3vRzFrN7Cs53tYXzOyBXG4jgzakfW3H+ntZMqPCdYwzs7lm9mMz2xsWAnvDD44ZZnaO\nmTkzOzfJ4yaZ2Ukzuy4sDl14vTZhufeE9z08cs+qn38EjgK1zrlL89QGGSbn3P9xzr0x7qY/B5YC\nc5xz1c65FuBvgFOA6c65hny0M8bMbszkC9fMHjCzL2Rjm0kyykhYNP0x2+0J1/f68H1flq11ptnW\nTjN7X663E7e92OfdvCys7tvAHc65Cc65v8/C+gpd1t/LZva5PH7/SA6ocJV7gFbgdc65auA84L8B\n55x7BniU4MMk0Y1AC/CzuNt2AH+ZsNwHgeey3OZBmVlF+GsjsNk51zPSbZA+ZlaepVU1Ai87544l\n3PZH51zHcFcat7+MGiPQprcDP83xNiS9RuCpTBc2s5KR+GMgj7zfy7kyGj8jxiznnC5j9AJMBhxw\nfppl3kVQ2E5IuP0F4F/C3+eE6/lbgg+d2DIXAPuALwIPp9nGjcBu4O/Cn4eB/wCq45apBb4DvBLe\nfw9wWtz9dwJrwmUOAr8GtgPdQCdwHPhUuOwlwO8JemJ3AF8GKuLWtRP4HPDb8HEvAcuA1wObwzzu\nA06Je8yHgWeBY8BrwA+BKXH3fw54GPjfYSZHgNuBsrhlGoDVYQbHgKdjrw1QCnwceJ7gD4YngKvj\nHnsO8CDQHD6vJ4Az0mS+PFymBdgKfAIoCe/7T+B7CcufH+Y4Pby+AGgC9gN7gFuB8QkZ/jPwmzCv\nf0jRjguATWHOjwM3EfzR1C+3uNe4M3xNj4ev8TogGl6OA7eFy84Mn8ce4ADwY2Bq3HofIOjt+q8w\nr9uG8Lw+S98ffNuBa8P7rgDagZ6wLceB65M859vov18eT3gffDjcTutQ9q2E53ZL+PxbgFeBDya0\noSRc13mp2hMu96bw9TlK8D7424T35H8Bh8K2bSXoEZ8FtBF8JsRy+FSK178a+B7Be3oPfZ8BN4b3\nVwJrw/tagReBD8c9/tdh3u3hdp4Lb3898Ei43qME+8m5cY+bFb6GR8KMngWuyPB5nwif2wni9rkk\nz60U+GSYSwvB/v2n4X3zw8e6MKvj8duPW8eccJn3As+Eyy4J73t3eFsLQefAOxIee0PY9laCDoZv\nAw8k7MvvS3iMA66Ju35JmN2hMKv1QFWGn8lpX9skz3W47+WU7w/gevp/ZhwneJ++Pnyu8Z+/NwK7\n032nZNie/0nwudBK8DlyZ6rPYV2Gd8l7A3TJ8w4QFGKPAe8BFhEWL3H3V4Rvzg/G3bYM6AIawuux\nD9f5BIXgVeHtdwBfIOGLNUkbbgzX931gfPjB8Bjw7+H9Fn5grgbqwjZ9BfgjEAmXuTP8wPsrIAKM\nC29/APhC3LZmEXzhfBQoB04n+NC/OW6ZnQQfxucQfPn8K0Gx+TNgKjCB4Evx9rjHvD18/iXAbIIv\nvR/H3f+5sH2fCLc7n+CL4D3h/VUEX3DfB6aE6zkLmB33+KeBM8L7rg2fR2N4/waCgqosvJxLWGQm\nyfsigg/zVeGyFwB7gY/Gvb6t9P/D4TvAz8LfpxB8kH8sfC2mEBTy/56Q4WsEX3wWez0S2jExXM+/\nhOs5C9hGisI12fW41/5HCfvsC8DXCfanaoIvs9/FLfNAmN+bwjzHDeF57SIo5EsICu1jwMS4fXl3\nstwT2vwAcftlwvvgu2GbY/twJvtWYuHaEr6OJeHju4F5cctcQdBzna49Swn+ELo6XM/rCIrg68P7\nvwjcTfB+sLBtZ4X3vZ6EwiBFDt8FniT4o208wf7fRV/hWkXw2VQbtmE50AH8j4TXJLEAuwy4lOC9\nNiHczitAeXj/auDfCQrjEoL31dwMn/ec8LnNG+S5fZygUDuf4H32DoL33flxy/QrFJOsI7atDcCp\nBJ9HFeG+sgu4MGzj5QT74eXh4y4l+Lx5c7jtNxMUvQ8Mkltve4Czw8d8mOD9UR6+rhVk9pmc9rVN\n8XzvZOjv5SG9P1LtnyQvXPt9pwzWHoLvk5ME/8EkvP/KwT4PdBnaJe8N0CXPO0DQ6/p54A8EvRZH\nwjdlfA/kl4Fn4q6vBX4edz324TqPYEzpj4Ga8IN0VrIPjoQ23EjwxVoTd9ufEnzIl9LX2xdfSJWG\nH6qxD+o7gUeTrPsB+heu/wg8lbDMteGHjYXXdwKfibv/nPD5XRJ328cT15NknYfjrn+OuEIhLsfv\nhL//OUHPREWK9bUQ92Ud3vY74J/C39cT/KHQmMFrfnv86xfe9jHghfB3Iygg3xdeH0fwRf6m8PpN\niVkTFAodQGlchl8apB3XE/RIlMbd9hH8C9e3EfSGWNxtM8PXMPbH1gPEfbkN8Xl9Nu7+8eF6F8ft\ny76F64AiP4N9K7Fw/Y+ExxwErou7fjPwtUHac1fiawh8Grgv/P1/AxsJ/hBK/IP39QxSuBIUGu3A\nm+NuqyHoQb0xzeN+Cfxr3PWdJBRgSR4zKWzPwvD694FfERRnlrDsYM97DpkVri8Cf5ek7bfFXc+0\ncE18728GPpBw278TjJeN/f7ThPt/ytAK128DTSnalfYz2eO1vZMhvpeH+v5ItX+SvHBN/DxI2x5g\nbpjBdYR/zOqS/YvGuI5xzrnDzrnPOucuJvhg+Svg/QQFXsztwOvM7FIzOwX4M4IeuGS+B6wg6Fl8\nyDm3K8OmHHXBgTYxOwj+yp1O8FdsGbA7PNq0maDIg6AXIv4xgzmV4N848bYR9OxMjbttX9zvJ1Lc\nNiF2xczeZmaPmNkBMztG8Fd4nZmVxj1mb8J249cxF9jpkoztMrPpBL2Ta2PPP8zgUoIPTQg+dB2w\nLjxy92Yzqx749IHUGcyCsGoMhmq8N7xvJUEP7G/C66cDFyS05Z5w+6fErXOw16MBeNU51z2Ex2Ti\ndIL95mhc+54jKEBnpdlWps+r93V0zsX2jQlkxwHn3Mn4GzLctxKl29cg+AL+GemdDvxdQh7/AMwI\n7/8acC/BH0yHzWztEA9YmkrQg9X7OoSfAUdi182swsy+bmZbzawlbMOfAtPSrdjMFpnZr8xsT5hZ\nbBuxx32CYJ//GbDfzL4fvs8yed6ZSvs+G6Jk++q/JrTxnUB9eH9DkscM9b01l6D4Tmawz+RBX9sM\nDfpeHub7I1PJck/ZHufcDoKe9fcAu8zsMTN7ZxbaIXFUuEov51yHc+4XBP8ePT/u9h0ERcsHgfcR\n/KX+uxTrOEDw78NPk7q4TWaSmdXEXZ9D8G+a/QT/cu4kGEdUG3epcs79OO4xmRyA9SpwWsJtjQR/\nJR8cQnt7mVkDQe/p/yX48JpIML4Mgt7LTOwE5qQ4iKmZoPdiRcLzH++c+yCAc+4V59z7nXOzCXoT\n3kD/Pz7ivUrwnOM1EvzrMeZO4EIzO5vgNf++6zvA7TWCHoz4ttQ45yqdc3vi1jHY67EbODXhC2bO\nII/JxGvAKwntqw3bFz8lWmL7Mn1e6WR6EGCq5frdnqV9qx8zu4igd2zjIO15DfhyQh4TnHNnAzjn\nToZ/9J5DsP90AT9Is75EBwm+8OfEta2GoHc05iaCf3O/GZjknKslGNca/9yTbWstQdH4ujCzubFN\nhG0/7Jz7mHPuDIJxvnOAb2TyvDN8bpDZ+yxTyfbVDyW0sdo596bw/t0MfC8lXm8l+I8BAGZWn3D/\nToJ/wScz2GdyJq9tJtK+lzN8fyR7vVrDn+Pjbkt8/skeO+hni3Pul865PyEYavQ1YLWZpcpRhkGF\n6xgWTmn15bB3osLMSs3saoIxXg8lLH4rwb+z/4bgX10uzao/TlA4/XoIzXEEPQjjww/QfwZ+GPbG\nPUww+P47ZjYtru1vN7NxQ9gGBIPqzzCzj5hZuZk1EoyxvGOQ55RONcF76ZBzrt3MTid10ZhKE8GB\nILea2RQLnGVms8Ne2NuAr5rZmeF9VWZ2ZewD0YJpmBrMzAiGaHSFl2T+A1ge5ldqZucRHETy3dgC\nzrm9BK/fVwh6dv8j7vHfB84zsw+Z2biwPaea2VuH8ZxLgc+G+98CggM4fP0MiJjZv8T+GDKzaWZ2\n3SCPy8bzeg2YYmaTM1guky+zbOxbid5OMF45fn9P1p5bgI+Y2dVmVhZeXmdmVwKY2VvM7GwLjnI/\nSfDHX1fc+iAYO5pU+IfQj4DPmdlMMxtPMJ48vl01BAXQQaDEzFYCiVN/vZZkO7GhSi1mVheut5eZ\nvcPMGs2shKCI6Yhre9rnHbalJ91zC90BfMLMzg3XsYpgTPUdgzwuEzcDnzGziyyYaaAi/P2C8P4f\nAG8xs+Xhe3x5uO14jwPvNLNaM5tIMCQs3neAN5jZ34SfNxEzu8qCo+vTfiZn+NpmYrD3cibvj9eA\nWWZWGXfbVoLX/QNhfucCf+3bHjM7w8zeZGbVzrkugiFeEAyFkyxR4Tq2dRL8VbiW4KjRwwQf2l8h\n4YOeoIjZRzAQ//vpVuqc2+Ocu98NbQqq14AtBB8ozxIcPf/RcH3dBIXwSWCTmbUSHE17LUP8IHTO\nvULwxXcdwUFn6wie2/8aynoS1vkCwYfl/wvb9gOCD+2hrKON4GCaaoIcWug78AGCf23+mOC1aibo\nDflHguEUEPyx8QeCo2Zj05glndDcObeJ4I+QTxMUy2uBbxG89vHuIDgY5n7n3M64x+8iOOjqDQS9\nWs0EMzAsHOJzbiH4Mn0Twb73I4bWS59qva1h+2YBWyz49+EjwJWDPC4bz2sdwTjGrRb8K/EvUiz3\nrwR/QB214N+NqdrkvW8lkWyYwID2hP99uYFgDPyB8HIHwWcGBL2YvyDIaQ/Bv1DfGz52K0Ev2Pow\nh39I0ZaPEezvsff+FvqKXgjG279KcGDVXoIDpn6RsI7PA38WbmdzeNtf0TfEZSMD/4g+h+C1is0M\n0UzwHhv0eYfv1U8Bd4TbvDXFc/sG8G/ATwj+Rf73wNucc4+nWD5jzrlbCMZu3hauew9B79748P6H\nCQqxW8Ln9l76//EJ8E8Exf2rBDOM/DxhG88C1xAMQdhL8N+vzxKMZ87kM3mw1zaT55n2vZzh++O/\nCYY87A1fr8vD9f5lmNEx4EvE/eE+3PYQHMD2aSA2ROVfgXc75xKHjIiH2MEoInljwZlUvuDyPHm8\nSLEzs4UEBdsprv/YYhGRgqAeVxGRsaMS+IiKVhEpVMV8Bg4REYnjnHuMYI5kEZGCpKECIiIiIlIQ\nNFRARERERAqCClcRERERKQhFOcY1nOtvZVlZ2crp06cPuny2RKNRIpHI4AtKSsrQj/Lzpwz9KD9/\nytCfMvQz0vnt2bOn0zlXkcmyRT3GtaGhwe3evXvEtrd69Wquv/76EdteMVKGfpSfP2XoR/n5U4b+\nlKGfkc7PzPZkOiWmhgqIiIiISEFQ4SoiIiIiBUGFq4iIiIgUBBWuWTRjxox8N6HgKUM/ys+fMvSj\n/PwpQ3/K0M9ozk8HZ4mIiIhI3ujgLBEREREpOipcs2jjxo35bkLBU4Z+lJ8/ZehH+flThv6UoZ/R\nnF/OC1cz+5aZ7TQzZ2bnplluhZm9YGYvmdnPzGxi3H3OzLaY2dPh5Ypct3s4tm/fnu8mFDxl6Ef5\n+VOGfpSfP2XoTxn6Gc35jUSP60+Ay4FXUi1gZtXA94C3OudOB/YCn0lY7Arn3Lnh5fc5a62IiIiI\njEo5L1ydcw855wY7QupPgaeccy+E128F3pnblomIiIhIISnLdwNCs+jfI7sTmGFmZc65rvC29WZW\nAtwPfMY5dyJxJWZ2E3ATUAVUVVZWsnr16gEbmzFjBsuWLQOCcRzJusQbGxtZsmQJAOvWrWPfvn0D\nllm4cCGLFi0CoKmpiQ0bNgxYZvHixcybNw+ANWvWEI1GByyzdOlS6uvriUajrFmzZsD9AMuXL6e2\ntpbm5mbuvvvupMusWrWKSCTC3r17Wb9+/YD7I5EIq1atAmDbtm1s2rRpwDI1NTWsWLECgM2bN7Nl\ny5YBy+Qqv5aWlgEZKj/llyiX+QH9MlR+yi9RrvODvgyV3/DygyBD5Vc4+Q3FiE2HZWY7CYYCPJ3k\nvo8D851zHwivjwNagQrnXJeZzXLO7TKz8cBtQKtz7kODbXOkp8PSuZH9KUM/ys+fMvSj/PwpQ3/K\n0M9I51eI02HtAmbHXZ8D7Iv1tjrndoU/TxAMIxiVB2c1NjbmuwkFTxn6UX7+lKEf5edPGfpThn5G\nc36jpcd1ArAduNI594KZfRtod859wswmAR3OuZPhUIFvAHXOuXcPtk2dgEBERERkdBtVPa5mdruZ\n7QYagN+a2bbw9s+b2d8AOOdagfcBvwjvbwD+JVzFAmCjmT0DbAEmAx/NdbtFREREZHQZiVkFPuCc\na3DOlTnnpjvn5oW3f9Y5d1vccnc55xY45+Y5597qnGsJb3/UObfIOXeOc+5s59wNzrkjuW73cKxb\nty7fTSh4ytCP8vOnDP0oP3/K0J8y9DOa8xstY1yLQrIj92RolKEf5edPGfpRfv6UoT9l6Gc056fC\nVUREREQ4dLyDb/5uK/fvr+Sbv9vKoeMd+W7SACpcRURERIQjJzq55f6XWHegklvuf4kjJzrz3aQB\nVLiKiIiISEFQ4SoiIiIiBUGFaxYtXLgw300oeMrQj/Lzpwz9KD9/ytCfMixeI3YCgpFkZiuBlXV1\ndSsPHz6c7+aIiIiIjHpb97fyxm8+1Hv93o9dyfzpE3K+3VF1AoJ8cM6tdc6tqqqqyndTRERERCRL\nirJwzZempqZ8N6HgKUM/ys+fMvSj/PwpQ3/KsHipcM2ilpaWfDeh4ClDP8rPnzL0o/z8KUN/yrB4\nqXAVERERkYKgwlVERERECoIKVxEREREpCCpcRURERKQgqHDNosWLF+e7CQVPGfpRfv6UoR/l508Z\n+lOGxass3w0oJvPmzct3EwqeMvSj/PwpQz/Kz58y9FfMGR463sEPH32l9/oNl8xmSnVFHls0slS4\nioiIiBSIIyc6ueX+l3qvL180Y0wVrhoqkEVr1qzJdxMKnjL0o/z8KUM/ys+fMvSnDItXURauZrbS\nzNa0tbWN6Haj0eiIbq8YKUM/ys+fMvSj/PwpQ3/KsHgVZeHqnFvrnFtVVVWV76aIiIiISJYUZeEq\nIiIiIsVHhauIiIiIFAQVriIiIiJSEFS4ZtHSpUvz3YSCpwz9KD9/ytCP8vOnDP0pw+KlwjWL6uvr\n892EgqcM/Sg/f8rQj/Lzpwz9KcPipcI1izT9hj9l6Ef5+VOGfpSfP2XoTxkWLxWuWaQJj/0pQz/K\nz58y9KP8/ClDf8qweOmUryIiIiJZcuh4Bz989JXe6zdcMntMnZI111S4ioiIiGTJkROd3HL/S73X\nly+aocI1izRUQEREREQKQlEWrma20szWtLW15bspIiIiIpIlRVm4OufWOudWVVVV5bspIiIiIpIl\nRVm45svy5cvz3YSCpwz9KD9/ytCP8vOnDP0pw+KlwjWLamtr892EgqcM/Sg/f8rQj/Lzpwz9KcPi\npcI1i5qbm/PdhIKnDP0oP3/K0I/y86cM/SnD4qXCNYvuvvvufDeh4ClDP8rPnzL0o/z8KUN/yrB4\nqXAVERERkYKgExCIiIjImKKzWxUuFa4iIiIypujsVoVLQwVEREREpCCocBURERGRgqDCNYtWrVqV\n7yYUPGXoR/n5U4Z+lJ8/ZehPGRYvFa5ZFIlE8t2EgqcM/Sg/f8rQj/Lzpwz9KcPiVZSFq5mtNLM1\nbW1tI7rdvXv3juj2itGoyvD4QVj/pb7L8YP5btGgRlV+BUoZ+lF+/pShP2VYvIqycHXOrXXOraqq\nqhrR7a5fv35Et5cVuS7Ohrj+IWWY67afPAQPfrnvcvJQ9tado7b35leARfdoUZDv41FE+flThv6U\nYfHSdFiF4PhBeOyOvusXvQ+qp2Zn3bHiLObst2Zv3blef67bnkuFnHsu98eRWL+IiBQsFa7ZEH7R\nLjy8Gdbvyv4XbSEXaFJ8VHSLSI7pBAGSigrXbAi/aBcBPHiPCkuR0SrXRbcKY5Gs0AkCJBUVriIi\n2VLIvcUqukWkAKhwlVFFU5j4UX7+Rm2GBTJEI2l+KoqHZNTugwVEGRYvFa4yqmjSaD/Kz58y9JM0\nP43TH5JC2QdH8zjUQslQhi7nhauZfQt4CzAbOM8593SK5VYAXwdKgS3Ajc65Y+F9i4HvAlXAbuAG\n59yeXLc9I9F26DzR/7bOE8Htkcr8tElEZCxRj25eaByq5MNIzOP6E+By4JVUC5hZNfA94K3OudOB\nvcBnwvtKgNXAR51z84F7gJtz3eiMRNvhGwvgjqv7337H1cHt0fbsbCNVYTya1z1M27Zty9u2i4Hy\n86cM/eQlvwKcczkd7YP+lGHxynmPq3PuIQAzS7fYnwJPOedeCK/fCtwLfBK4AOhyzsVmE74d+IKZ\nVTrn8ldhAXR3QtvR5Pe1HYX9z0LFRCgpBSsJf5YGP0vKBt7W+7MEzPoK48Rt3HE1VE2Cm14Yfq9u\nLtcdv40h9kZv2rSJefPm+W13DFN+/pShn6LLLw8zURRdhnmgDIvXaBnjOov+PbI7gRlmVpZ4n3Ou\n1cyOAfXAyyPZyCFL7IkdCisBSsB1Jb+/7Sh87w0QGQdlFVBWCWXl4c8KKK3o+z3Zfa4nfdHdsgeq\npwSPKS0PCumhyHVhrCEaIlIMkhXG2aIhFFKERkvhmhVmdhNwU+x6dXU1q1evHrDcjBkzWLZsGQAb\nN25k+/btA5ZpbGxkyZIlAKxbt459+/YNWOacBafxumw1PpHrAXrSL/Pa5lxtHb59fl9TMLqtjG6L\n0G0RLFJJ1YQ6KKvgWFuUEx3ddJeU0W3lvctNqKnllDSF8cN3/AP1817HaaefCWWVPPjIJlpOdPDH\nJ57mJ12tdJcE27p4yaW9fzWvWbOGaDRKSU+Ut+34Ryp6TvZf7x1X01Eyjp/N/RI9Jf2PKF2+fDm1\ntbU0Nzdz9913J23WqlWriEQi7N27lwfvv5dJHbv5k7j7f3fPL3jD9XMhUsm2bdvYtGnTgHXU1NSw\nYsUKADZv3syWLVsGLDNz+mRev2BKv9t+c9dPOVrR0NvuTPa/hQsXsmjRIgCamppoaWlhw4YNQTs6\n9rIiYflYfomWLl1KfX090WiUNWvWJM0mPr+Hm5r6rbupqYmWiif75ZfsdIuRSKT3gIm0+V3c2O+2\n2PpjfN6/yXLp3UZLC0BvhgCLFy8esP8lis/vtymyGer+lyy/yd0H+u2PiblAZvtfqvxSZTOU/Q9S\n5xcvvu1D3f+S5ZfY9mTZZLz/JeSXuO5Nmzax+M1nAn7fH/H5xWtqamLD4zuAoe9/ifnVdOxlxa6+\novjYrKv51S/vHbAOGHz/S5bf/vYSYGLvMg8+8CDzrxve/hevsbGRurln97utqamJ6ZV934mp9r+Y\nDRs2pM0vse1d0a6k9QIM/fuj6dcP9lt3U1MTDRNKh7X/JZoxYwYNZ1/U77bEbIb7/QEDc4nJ1vdH\nqvyGwpxz3ivJaENmOwnGsA44OMvMVgLvdc79SXj9LOBe51yDmV0E/NA5tyC8bwJwCKgZbKhAQ0OD\n2717d5afSZz2Y/DlU3O3fgmGT8R6iiNVwc+SCBx6MfVjzv0LKK8Oeop7L5Gwtzn8vbQ86Hnu/b08\n6JUuLQfn4D9XQcexgevO1RCNbKwbWL16NdevenswTCW+x/9998P012WnN/rA83Drkr7rH9oI0870\nX+9IrD+Dda9evZrrr78+Z+sftgLJPWl+BdL2EV93ivWv/t2Tw98HB1l3Ntu+fccOfvW9z/def/N7\nP0vj3LmjYt2DvY+37m/ljd98qPf6vR+7kvnTJwyvsSO47lyvP9dtT8XM9jjnGjJZdrT0uP4G+Dcz\nWxCOc/0Q8F/hfU8AETNbGo5z/QDwq7yPb83E++4Pii7XDT3dQS9qTzf0dMXd1g09PQnXw2U7WqHp\no6nXf/EHgp9d7dDVAd0dwc+udujq7Lu9qz3JfW0jk4Ev1w3RE8El0yY//Z+5a0/bUfjybCivgrKq\noBAc8LMyGMKR7D4s/RCNIzugehqUjwvWM8QhGiU90cIeoqEhICIFo7T9MB8t+1nv9Z3tHwayU7jm\nct1S2EZiOqzbgeXAKcBvzazVOTfPzD4P7HXO3RaOW30f8ItwXOuzwF8COOd6zOxdwO1mVkkw48AN\nuW53RkrLg2IgVe+Zbw9X+7H0heuyf4LKgV36ma27Bb48K/X9f7EWSkqCgqG3AG7rK357b4+7P9rW\nt1znCdjzxPDaNtp1t0NbO5CiAPXxnbjeESsJC+Cq4Gf5+PDnuPD22O/jg2XKx3Nu20vpC+Pdj0FV\nbdBrXRrp63EecL104ONHYtzyKCi6a2pqhr8NUX5ZoAz9DZZh6clDfLTsJ3HXzwJy37Mo/kZiVoEP\npLj9swnX7wLuSrHso8DAwUD5FqkMvkxz9W/ZwQrj0nKPdVekX/fcK/2L7nTDKD65PZhZobcXOKEw\n7lcIJxTJ7cfgkW+lXvfsS4N/93d3Br3L3cku0WDdrnv4zzHXXA90Hg8uGRr0n4A/SDaKMRnrG1ZR\nUtZXzKYriv/reqgYHx4YWN43HKOsPPVtvUM0KoL/RKRbf1fbiMyiERtjNqxtqLd4+PlJr2xlePRk\nJ5PSXC8Nmn/3AAAgAElEQVRmg2WoHt3CNVqGChSuSGXQExavfHx2vqhyWRjnu+gurx7+NgYrXN/5\n35n3RPd0B0VsfFF78gjcdlnqx7zp68HP3p7ntsx/dp7M7hyTOeOC4SXdHZk/ZPt9uWsOwFfmhIVu\nVdgLHQ7J6Dc0I+73+PuM9EXxoRdh/NRwveODgn0owzRGSW+xSLyWtmi/QjXxuuSGenNzS4XraJfr\nwniUFd2bN29OeqRtP9nsiS4J586Nb095dfrHLLrOY4jGID3RN/wyKLKi4XCL6Mmg2I2eCH+2xf1+\nMlym77boiaNEOo4Mr22FIPbHRUfL4MsOxe1X9r9upXFDMar6hmb0DttIuG6D9Ea/thnGT+kb1hEZ\nB6UZfvyO0jmXU8noPSxpKUN/+cxQvbm5pcJVcmcYhfGWLVsG/7DJd2+x1xCNQdY9a4lX+3/2/+7g\nupc/nnqBDzwcrD82XKKnq+/37ij0RJNcDy+drbDuC6nXfdZbg+EN3dHwYMDOsNe2s+/33qEbcfe7\nQaZ9ywfXHTzfztbsrO97bxh4W2l5QlEcFsLlCddLytIXxc//Eipr+8+QERve0W8WjYTfS0pzcqKT\nAe9hHdA3ZBl9DkpaxZzhWO/RVeEqhWkU9hbnfd1Aj5WlL4ynnO43RCNd4fqW/zu8nujusHg+eQhu\nXph6ubfeFhZaJ4OiJHoyHK7RFo6Hbu+7r6ut7/ZoW3D7sT1Db1suxXqP2z17j3/218N8oPUdmBdN\nMY667Sj8+B1QUR1OSxcbjhHOlBE/TV04c0bD8Wdg2ynhrBglyaeWK7ID+kRG0ljv0VXhKpJMgQ7R\n6CmJ5K4wzlVPdGlZcLFp6dd/9rV+RXe6IRrv+U1vUfzgfb/hqksuCovgcBhGrADuHZpxsu/+zhPQ\ncRyOFNq50TMcx/zywMno07kK4Ee3D75g21H42ryEIriyf4EcO/PfgNvD2xyDTC/3cjC9XCScvq6k\nJPMnkschGiU9Ayd6H866Ldp/3RZV0S3pFUJvrgrXbBg3Ba76BzZv2cyihYuC6yL5kqvCONdDNHK5\n/sGK7vrzete/e+M+WLRyaOsfrDB+/7qg97F3nPLJvkuy26JtfeOYO44V79Ry2RyOkcx3Lul/vawy\nbnhGFUmHavSOWy5JXxT/8ZdQMSEYllFSGv6Mv5Sm+BleerqDkwO0N/df9x1X87aScRB9h/csGrMT\n2j/7Z2/JatGds8JYRXfeFEJvrgrXbKieCkv/kS17V7NoaRbOdpIoLIz7XRfJh1z2ROdy/fkeFz3t\n7Nz1Fv+vHUFB1js2uXNov7e3wG/+PvX6X7cSXNfAuZtjQzIS53AezWJtT1WQDsXPhztEY3AVPSfh\n5tcFr2vimf1iZ/wri535ryLh/vDsf+mK7m33BQcL9hbysROqhJdk8zjHy2VhXOhFt+RcURau4Slk\nV9bV1Y3odmfMmJGbFYeF8ViQswzHCOWXRoZF8bAyzGdvcWz6L8YNb/3tx9IXriu+kfnYZed44P7f\n8vrLlgQF4vGDcPvlqZf/k68EPxPnck42h3Oyk6F0noT2HJwIZDQ4cTB36/7vQTpYUk47F9422Cwa\nD3wpeExJSbBsrMfZwllcrCThemnfDC9dnenXfXh78J0Ya09pJOmiKd/HuS6MVRTnXFEWrs65tcDa\nhoYGN5LbXbZs2UhurigpQz/Kz9+wMyzW3uKhjF024/XX/Enf9cggxfS5fzH8qeVg8N7od98Vjl1u\n6xuC0fuzLW6oRsJt0bbglNsHnht+2wqZ77RzG27Obnvi3XZp/+tWGvYYV8b9rGRZZBz84OaB9w1W\ndG9fH05dFz+UJDaF3SDzO6u3eEQUZeEqQ6BhCCKjX6HOopHLqeUyWf+pi3M7RCMyLphSznUHY1Z7\nuhIuibd19/1sPwb/9Y7U67/mc0HPZPwUcrEz/sWfMCXZ/dF2OPjH4T3vQuO6h3yGwbTSvSax+Z2T\nFbWZTF33xJ0wrq7voMOUByHG3R9fKKu3GFDhmlUbN25kyZIlgy84moyyYQgFmeEoovz8jckMs1gY\n98uvmA/o6x2iMUztx9Lff+F7c3eik7/bHPQeJptKrneauRRTy3W1B+OiX2hKvf7Jpwc/XaxQ7+kr\n7nt/9sRdD4t5RvSfpEPnO79zuiE5qZRWxBWz5ekL45//Tdxpt2Njn+N/Jp6CO245B6y5ntkd/Z9b\nVnuLs0SFaxZt37597H3hDWaIPbrK0I/y86cM/QzITwf0JZemMO4oGUdFLk90Uj3dv+j+cprC9f3r\nhld0xw4q+2qao9jffVfYE90eV3QP/PnCc0+z4LTZ4W2x0263B1PX7Xtq6G3Ll9iUdZmcffuPP89N\nG9qOBr36KlxlTMhlj66GOYhILkUqOdoVYVLcTUe7IkzK4hCNV57fFPRqhV5521088swO3pmFE50k\nW/fsMz2GT8TkagiIWdCTnYXhH08cWM2CtyQ5CG2w3ui/fSY4SCzduOhU97W3wIt3p153ZHxQhPZ0\nDdp+SU2FqxSuUTbMQUSKT0tbtF/hmnjdS6QSF+nfW+wi44MTieRo3dkcF52TwjjfRfeEU3I3Lvrj\nLwQ90d1dQQHbb4q5uNkyBsyiEf7e3gwPfDn1+huvCYYzdHeGY6HjT7Pd2Tc+OnZfgVLhKpKKenRF\nRJLLcWFckEV3pj3RsbMFJg5xGUz7sfSF68rvD2nqumBO57C4PXkY/u2iobUnT1S4iqSiYQ4iIsUn\nV4VxvnuLhzh1HWXhiSsqSDkf7mikwjWLGhsb892EgjdmMsxRUTxm8sshZehH+flThv7ylmGx9xaP\nAipcs0hHIvtThn5688tlj26R9xZrH/Sj/PwpQ39Fm2Gh9hZnkQpXkWKUy2EOuT4orsgLYxGRUSmX\nvcVZVJLvBuSCma00szVtbW0jut1169aN6PaKkTL0UxT5xQrj2KV6avbWHSuKY5ckRXFRZJhH+cjv\n6MnOtNcLjfZBf8qweBVlj6tzbi2wtqGhYURPw7Fv376R3FxRUoZ+lN8gMugt9spQvcV52QdzOmVV\nHuh97E8ZFq+iLFxFRPKikGeiUNEtMuZ1V07m5q639V5/c+XkPLYmORWuIiKFINdjiwu46C6EL1sZ\nO3K9P+Zy/d3jpnBz15/3Xn/TKPwDVoWriIjkVo6L7lx+2RZ0EaK252X9uS7+CqG4zCUVriIiIikU\nchGitudv/ZI7RTmrQL4sXLgw300oeMrQj/Lzpwz9KD9/ytCfMixeKlyzaNGiRfluQsFThn6Unz9l\n6Ef5+VOG/pRh8dJQARERyalDxzv44aOv9F6/4ZLZTKmuyGOLRKRQqcc1i5qamvLdhIKnDP0oP3/K\n0E+y/I6c6OSW+1/qvRw5UdgnCMg17YP+lGHxUuGaRS0tLfluQsFThn6Unz9l6Ef5+VOG/pRh8VLh\nKiIiIiIFoSgLVzNbaWZr2tra8t0UEREREcmSoixcnXNrnXOrqqqq8t0UEREREcmSoixcRURERKT4\naDqsLFq8eHG+m1DwlKEf5edvrGaYrSmrxmp+2aQM/SnD4qXCNYvmzZuX7yYUPGXoR/n5G6sZxqas\nilm+aMawCtexml82KUN/yrB4aaiAiIiIiBQEFa5ZtGbNmnw3oeApQz/Kz99ozfDQ8Q6++butvZdD\nxzvy3aSkRmt+hUQZ+lOGxUtDBbIoGo3muwkFTxn6UX7+RmuG2fpXfq6N1vwKiTL0pwyLl3pcRURE\nRKQgqHAVERERkYKgwlVERERECoIKVxEREREpCEVZuJrZSjNb09bWNqLbXbp06YhurxgpQz/Kz58y\n9KP8/ClDf8qweBVl4eqcW+ucW1VVVTWi262vrx/R7RUjZehH+flThn6Unz9l6E8ZFi9Nh5VF0WiU\nSCSS72YUNGXoR/n588kwW6dNLWTaB/0pQ3/KsHgVZY9rvmjCY3/K0I/y8+eTYWyu1djlyInOLLas\nMGgf9KcM/SnD4qXCVUREREQKggpXERERkTGuPdrNiY6ufred6OiiPdqdpxYlpzGuIiIiImNYe7Sb\nJf/nfprb+p8q99pbH6G2KsLGT11NZaQ0T63rTz2uIiIiImNYtLtnQNEa09wWJdrdM8ItSi3nPa5m\ndjrwA2AK0ALc6Jx7LslynwT+kqCYfhF4j3OuObzPAc8Csf7qjzjnfp/rtotIcdFR/yIi0N3jeOlA\nK0/vauapXc08/sqRfDcpYyMxVOB24LvOuTvN7M+BO4GL4hcwszcA7wEWO+dazeyfgC8CH45b7IpY\nITtaLV++PN9NKHjK0I/ySy921H/M8kUzBhSuytCP8vOnDP0pw/4Otnbw9KvNPLXrKE/tambz7mZO\ndI6usauZymnhambTgAuBN4Y3/RT4tpnNc85ti1v0HOBh51xreP0e4AH6F66jXm1tbb6bUPCUoR/l\n508Z+lF+/pShv2LNMN0BVLExqB1d3Ty39xhP7WruLVZ3Hx3ZM4nmUq57XE8F9jnnugCcc87MdgGz\ngPjC9QngQ2Z2CrAfuB6YYGZ1zrlY//V6MysB7gc+45w7keO2D1lzc3PRvllGijL0o/z8KUM/ys+f\nMvRXjBmmO4BqXHkpbzt/Jlv2HOP5vcfozHBMammJseCUCZxdP5E1j+/ORbOzblTMKuCcW29mXwea\nCMax/jy8K/ZnxWzn3C4zGw/cBnwN+FDieszsJuCm2PXq6mpWr149YHszZsxg2bJlAGzcuJHt27cP\nWKaxsZElS5YAsG7dOvbt2zdgmYULF7Jo0SIAmpqauOeee7jsssv6LbN48WLmzZsHBBMiR6MDBz8v\nXbqU+vp6otFoykmTly9fTm1tLc3Nzdx9991Jl1m1ahWRSIS9e/eyfv36AfdHIhFWrVoFwLZt29i0\nadOAZWpqalixYgUAmzdvZsuWLQOWyVV+LS0tbNiwoV+Gyk/5JfLJb397CTBxwPKx/IB+GQ41v6am\npn7rb2pqYnplT1byO9xVDowbsO54PvmlymYo+x+kzi9efNuzsf8ltj1ZNsPd/xLXvWnTJua/5Rog\ne+/feE1NTWx74vdcdtll3u/fxLYfO9bK6vvuGrAOGN77N3H9Dz7wIPOvy877t27u2f1uS3xNU+1/\nMRs2bOCmm25KmV9i27uiXUnrBRj651/Trx8kcX9smFDq/fnX3g3NbcmL8ZOd3fxo466k98WbWNbD\nqeO6uOi0qbxp8VksnFnD/ff+mkNHd1FVOpG27oHH7NdWRbjrFz+H7tx9fwyFOee8V5Jy5cFQgW1A\nnXOuy8wM2AdcnjBUIPFxS4C1zrlTk9x3CcGY2YWDbb+hocHt3j1yf0GsXr2a66+/fsS2V4yUoR/l\nl97W/a288ZsP9V6/92NXMn/6hH7L+GSYyfqHK5frzub6k+VXKG0f6XWnWv9j992VlffxWM59sPfx\naG57ovZoNxu2HeLXz+7jJ0/syfhxlZESFs6s4bxZkzjv1FrOnVXLjJqqtNt5ft8xrr31kd7bfv6h\nSzlzxsScT4VlZnuccw2ZLJvTHlfn3AEzexJ4F8FBWW8HdicrWs1shnNun5mNAz4PfDW8fRLQ4Zw7\nGQ4VuA54KpftFpH80ZH/IjLWHWztYN0L+7nv+QP8/qWDtEcH/9f/nLpxnD8nKFLPmzWJM06ZQKQ0\n81lPKyOljK/oXxaOrygbNfO3xozEUIEPAHea2aeAYwSzB2Bmnwf2OuduC5e7NyxMy4EfAt8Ob18A\n3B5OiVUGPAn83Qi0W0TyIJMj/0VEiolzjq37j3Pf8/u57/n9PP1qM0P9h/iv/vZyJlRGctPAUSTn\nhatz7kXgkiS3fzbhetJ//TvnHgUGDgQSkbxQj6iIiL9odw9/2HGkt1h99Uj6I/+nT6xg/7GOEWrd\n6DUqDs4SkcKhHlERkeQGm66q5WSUB7Ye4L7nD/DAiwdobe9KsabAwpk1XHPmdK4+cxrzpo5nyZfW\nJT3DVW1VZEjDAgqZCtcsih0xKMOnDP0oP3/K0I/y86cM/eUjw3TTVVVFSlk0s4bHdx2luyf1GIDy\nshIua5zMNWdN5+oF0zmlprLf/Rs/dXXeDqAaLVS4ZlEkUvxjS3JNGfpRfv6UoR/l508Z+stHhtHu\nnqS9oQBt0W427Ux+WtXJ48tZtmAa15w1ncvnTRlwgFS8QjmAKpdUuGbR3r17qa+vz3czCpoy9KP8\n/ClDP8rPnzL0N5IZtrZHeeKVo2zYdijjx5w+rZprzprONWdO49xTJ1FaYjlsYXEZGwMiRkiySZtl\naJShH+XnTxn6UX7+lKG/XGZ4sLWDe7bs43N3Pcfyb/2ec/75Xm78/mP8++93pH3cRXMm8U/Lz+SB\nT7ye3910FX//Jwu4YHaditYhUo+riIiISBLOOXYdOckfdhzhsZ1HeGznUXYcGt4Z5//jxovGxHRV\nuabCVaQIacoqEZHk0h35Hykt4cXXWnls5xH+sPMIj+04woHWzKagqhsf4ciJ5GNcJXuKsnA1s5XA\nyrq6unw3RSQvNGWViMhA6Y78LysxKiMlHO/ozmhds+rGcdGcOi6eO4mL5tRRX1Op6apGQFEWrs65\ntcDahoaGIZ53QkRERIpVR7Q75ZH/XT0uZdFqBmdMn8DFc+u4aE5wSZyqCjRd1UgoysI1XzSFiT9l\n6Ef5+VOGfpSfP2XoLz7Dg60d/P6lgzy49SAPbT2Y2eNLjYUza7hobh0Xz6njwtl11Iwb/HXRdFW5\np8I1izRptD9l6Ef5+VOGfpSfP2XoJ9rdw+wLr+arv3mBh146yLN7jmX82A8vbeTyeVM5b1atis1R\nSoWriIiIFLTdR0/y0NZDPLj1ABu2HeZ4R/pTqabyN1c16sj/UU6FaxZt27aNefPm5bsZBU0Z+lF+\n/pShH+XnTxkOrj3azaYdR3jwxYM89NJBth04PuhjFpwygUtOm8z3H9mZ+wZKzqhwzaJNmzbpw8bT\nWMkwV9NVjZX8ckkZ+lF+/sZ6hsmmqzreHuX5fcd4dPthHtx6kI0vH6ajqyfteiZWlnHF6VO5av5U\nrpw/lVNqKmmPdvPzp/boyP8CpsJVJA80XZWIyECppqt623ceHfSxZrCooZar5k+lY8eTfPK9qyhL\nKEQrI6U68r/AqXAVERGRIUk3iX+64q+jq5tDxzs5cKydA60dHGjt4GBrBwdb2zlwrIPXjrWnnK4q\nmSnVFWGP6hSuOH0qdePLAVi9+rEBRWuMjvwvbCpcRUREJGPpJvGvrijlc285m+aTUQ6GhemB1vbe\n35tP+p1ZqtTgwjl1XHVGMATgzFMmUlJiXuuUwqLCVURERDK2++jJlL2ixzu6+cTazTnb9sN/v4wZ\ntVU5W7+Mfipcs6impibfTSh4ytCP8vOnDP0oP3+jLcMjJzrZ+PJhNmw7xCPbD7Pj0Imsrbu6ooxp\nEyqYOqGCaRMrqamM8KNNr6RevjKzsmW0ZSjZU5SFq5mtBFbW1dWN6HZXrFgxotsrRsrQj/Lzpwz9\nKD9/+c7wREcXf9hxpLdQ/eO+zCfwj5lSXc7UCZVMm1DRV5iGxenUuNvGlfcvQ1rbo2kL10zlO0PJ\nnaIsXJ1za4G1DQ0NLt9tkcKVqymrRERGk46ubp7a1cwj2w6xYfthnnm1ma6e4X99PvWZa5g0fnif\nlZHSEmqrIpquSlIqysI1XzZv3syiRYvy3YyCNpoyLMQpq0ZTfoVKGfpRfv6ykWG6o/4jpSU8u6eF\nDdsP8ej2wzy28wjt0fRzogLMmTyOS+dN4bxZtXwyzTjWVEfzZyJb01VpPyxeKlyzaMuWLXqjeFKG\nfpSfP2XoR/n5880w3VH/ZaVGZVkJxzu6B13PtAkVXDZvCpc2TubSeVOYGR4U1R7t5otNz+esVzQb\n01VpPyxeKlxFRESKSLS7J+VR/13djuPdyYvWiZVlXNI4OSxWp9A4dTxmA6ea0iT+kk8qXEVERApc\nS1uUR7cHR/7/fuvBjB5TGSnhojl1XDZvCpc1TuGs+omUZjgnqibxl3xR4SoFSwdPichY1dHVzROv\nHGXDtkM8vO0wW3Y3k+nxVB+46jSWnTGNc2fVUlGmQlMKiwpXKViFePCUiMhw9PQ4/rjvWFioHsr4\ngKpk/ufSeUyojGS5hSIjQ4VrFs2YMSPfTSh4ytCP8vOnDP0ov8ylOvJ/yrRTAHj1yEkeDgvVR7Yd\n4mgGp0udWVvFktPq+OmTe3LS5kKh/bB4qXDNomXLluW7CQVPGfpRfv6UoR/ll5l0R/6Xl5Yw/cl1\nvHq0bdD11I6LcGl4QNXl86Ywq24cHV093P/8gTE9F6r2w+KlwlVERGQEnezs4qX9x1Me+d/Z3ZOy\naK0oK+HiuXW9hepZMyZSknBAlY76l2KmwjWLNm7cyJIlS/LdjIKmDP0oP3/K0E8x5ZduEv9UxV9P\nj+PQiQ72Nrezt7mNvc1t7D4a/Nzb0sbe5naOnOjMuA1msGhmTW+hev7sSRkVnmP9qP9i2g+lv6Is\nXM1sJbCyrq5uRLe7fft2vVE8KUM/ys+fMvRTLPml+1f+hMoybrnuPA4d72BPcxt7wgI1KE7b6ewa\n3kFT8VZd2MCyBdNYctpkaseVe69vrCmW/VAGKsrC1Tm3Fljb0NAw/JMti4jImNXZ1Z3yX/mt7V38\n1Q8ey+n2P7PiLB35L5JEURauIiIiQ9HT49h6oJU/7DjCph1H2Pjy4aysd0p1OfW1VdTXVDFzUhX1\ntVXMrK2kdlyEd3x3U1a2ITKWqHCVnNJJAkRkNOrq7uG5vcd6C9XHdh6hJUUPayrlpSXU11aGxWhV\nv5+x21ONKW2PdlNbFUnaq1tV2jMmjvwXGQ4VrpJTOkmAiIwG7dFuNu9u4Q87DrNpxxGefOUoJzq7\nh72+9Z94PbPrxg04oj9T6Y78f+bBe8bMQVQiQ6XCNYsaGxvz3YSCpwz9KD9/ytDPSOeX6sj/I8c7\neG5fX4/q0682Z3TQVKTUWNRQy7mn1vK9h3ekXG5Kdfmwi9aYVEf+Lzhd+6AvvY+LlwrXLNIRjP6U\noR/l508Z+hnJ/NId+Z+pykgJ58+axMVz67h4bh3nnTqJqvJS2qPd/PSJ3XmZxF/7oD9lWLxUuIqI\nSMFpbY/y0NaDKY/8T2VCRRkXzpnExXMnc/HcOhbOrKG8bGARqkn8RUYnFa5ZtG7dOp1mzpMy9KP8\n/ClDP7nKr62zmydeOcqjLx/ike2H2by7he6ewWc8rBtfzsVz6np7VM+cMZHSDP/Fn69J/LUP+lOG\nxUuFaxbt27cv300oeMrQj/Lzpwz9ZCu/zq4enn61mUe3H+aR7Yd4alcznd1Dm9j/lx++lEUNtZj5\njUUdadoH/SnD4qXCVURE8q6ru4dn9x7jke2HeHT7YR7feZS26PCP+gc4bWp1wRWtIpKeClcREcmZ\nVEf9t3V0sePwyd5C9Q87jtCasFwydePLueS0ySxpnMw5DTW85dsbctV0ERmFirJwNbOVwMq6urp8\nN0VEZMxKd9S/AZmck3tCZRmL507m0sbJXNI4mTOmT+idhirdJP65PvJfRPKjKAtX59xaYG1DQ0Mm\nn4siIpJlXd09PPNqc8qj/lN9OFdFSrlobh2XNgbF6tn1NSkPptKR/yJjT1EWrvmycOHCfDdhyEbb\nKVkLMcPRRPn5U4bDc7Kzi6d3NfMcs3jXHZt4ctdRTmZwZqryshIumDWJS8JCdVFDbdLpqVLJ15H/\nuaR90J8yLF4qXLNo0aJF+W7CkI22U7IWYoajifLzpwwzc/h4B4/tPMrjO4/w2CtHeW5PC10ZTE8V\n7453X8Dlp08t6CIzF7QP+lOGxUuFq4jIGJfqAKr2aDeVkVKcc+w6cpI/7DjC4zuP8tgrR3j54Anv\n7S4+bbKKVhEZEhWuWdTU1MSKFSvy3YyCpgz9KD9/Yy3DdAdQVUVKuXL+FJ7c1czB1o6M1jeuzHHp\n6dO5cE4dZ9dP5Ibv/SEXzS5qY20fzAVlWLxUuGZRS0tLvptQ8JShH+Xnb6xl2NrWlfIAqrZoN799\nbn/ax8+sreLiuXVcOGcSF82pY9Pv7uKGdwUFg476H56xtg/mgjIsXipcRUSKXFd3D7uPtrHj0Ale\nPnSCHYeOs+PQCXYcPMHelvaM12MGZ0yfwEVz6rhobh0Xzp5EfW1Vv2Uei5sAQEf9i0i2ZVS4mtmP\ngf/rnHtk0IVFRCSrBhuDCuCc40BrBy8fPBEUpWFx+vKhE+w6fHLIB07FXDBrEotPq+OiOXWcP3sS\nNVWRIT2+GI/6F5H8ybTHdT1wq5n1AP8GrHbOZfRnupmdDvwAmAK0ADc6555Lstwngb8ESoAXgfc4\n55rD+xYD3wWqgN3ADc65PRm2XUSkYKUbg1pRVsKyBdPYdeQkOw6dyGj6qaG6868uYkLl0IpVEZFc\nyWiAkXPuu865c4G/Ba4GdpjZV81sdgYPvx34rnNuPvAV4M7EBczsDcB7gEucc2cBTwBfDO8rAVYD\nHw3XcQ9wcybtFhEpdEdOdKYcg9rR1cOvn32N5/Yey7honVhZxrmn1vK282by8TfM52srNW2QiBSO\noY5xfRF4HrgCWAA8bGbfds59JdnCZjYNuBB4Y3jTT4Fvm9k859y2uEXPAR52zrWG1+8BHgA+DFwA\ndDnn1of33Q58wcwqM+31HSmLFy/OdxMKnjL0o/z85TvDru4eNu9p4aGtB/n9S4d4atfRIa+jvKyE\nuZPHM3fKeOZODX6eNmU8p02tZtK4CGZ9A1Hbo918sen5rB1Ale/8ioEy9KcMi1emY1yXAB8BXk/Q\nY7rEObfHzMYTFLJJC1fgVGCfc64LwDnnzGwXMAuIL1yfAD5kZqcA+4HrgQlmVhcu23tqJ+dcq5kd\nA+qBlxPaeRNwU+x6dXU1q1evHtCoGTNmsGzZMgA2btzI9u3bByzT2NjIkiVLAFi3bh379u0bsMzC\nhQt7JzluamqipaWFTZs29Vtm8eLFzJs3D4A1a9YQjQ78cli6dCn19fVEo1HWrFkz4H6A5cuXU1tb\nS+jEGzYAACAASURBVHNzM3fffXfSZVatWkUkEmHv3r2sX79+wP2RSIRVq1YBsG3bNjZt2sT+9hJg\nYu8yDz7wIPOvC44I3rx5M1u2bBmwnqHmF6+pqYnplT1A8vyAfhmmyy+x7V3RrqSvNwwvv8T1/+Y3\nv2H+X64E+vJLVFNT0zsFS7r8Gs6+KGUuMPz9D0j6ukL29r+mpl/3W3es7cPZ/xLV1NQw/6Kr+t2W\nmI3P+zdZLrFtxB+FHGvbUN+/TU1NSbMZbP872mnULriEDduP8PBLB2ntyPxf/qeNjzK9socpFd3M\nmlTFO1cso76mimef3RLsf4chehhefDHoeUiW30dPg31tJdz+cl/bYwdQPfL7B4e0/6XKL178a5qN\nz7/E1zVxn4HM97/E92/iujdt2sT8t1wDZO/7I16s7Zs2bfL+/khs+7Fjray+764B64DR9/1RN/fs\nfrclvqbp9r94+fj+aPr1gyTujw0TSoe1/yXK9fdHqs/IXNcvQ2HODT5g38w2A7eQZGyrmX3AOXd7\nisddAPync+6MuNv+APyDc25dwrIfAv4K6AZ+DnwJqAHeAPy1c+5/xC17gKB47le4JmpoaHC7d+8e\n9PmNZVv3t/LGbz7Ue/3ej13J/OkTCmL9ant+1q+2+6//REcXG18+3Nur+vKh4U/mv+Vzb8zKGNSx\nkPtoW3eu16+252f9avvQmdke51xDJstmOsZ1kXPue8n+NZ+qaA29Cswws7KwYUbQg7oryXpudc5d\n6JxbTDBMYLdz7li4bO9YWjObQFDQ7s2k7SMp1V8bkjll6Ef5+RtuhumO/O/pcWzZ3cK/rd/Gdbc/\nyrmfv5f3/uBxfvDoKymL1vHlpVxz5nQ+9aYFw2pPvmgf9KcM/SnD4pXpUIF7CI7kPxxenwLc6ZxL\ne1oK59wBM3sSeBfBEIO3ExSk2xKXNbMZzrl9ZjYO+Dzw1fCuJ4CImS0Nx7l+APjVaBvfCiTtRs+G\nQ8c7+OGjvaMluOGS2UyprsjJtvItVxmOFcrP33AyTHfkf6TUqK4o4+jJ9Os1g0Uza7ji9KlcOX8q\n582qJVJaQnu0m1vXby+YSfy1D/pThv6UYfHK9OCs+ljRCuCcO2Rm9Rk+9gPAnWb2KeAYwewBmNnn\ngb3OudvC5e4NZxAoB34IfDvcVo+ZvQu43cwqCXpab8hw20XhyIlObrn/pd7ryxfNKNrCVaQQRbt7\nUh75H+12KYvWGTWVXHH6FK6cP5XLGqcwaXz5gGU0ib+ISJ9MC9dSMyuLHWRlZuUEBeagnHMvApck\nuf2zCdcXplnHo4DmbBGRUaGzq4c/7jvGk68c5cldR3nilcyO/K+MlLDktMlccfpUrpo/hcap1f2O\n8E/9OE3iLyICmReuvwbWmtkt4fW/I5iySkSk6B041s6Tu47y5K5mnnzlKFv2tNDR1TP4A0PvuWwO\n15w5nQtmT1KxKSLiIdPC9dPAp+gbd3oXqafAEhEZdTI5bSpAt4NnXm3uV6juaW7z2vZNb5ivs0+J\niGRBRoWrcy4K/HN4kRSWLl2a7yYUPGXoR/kll+7gqYmVZXzx2oU8u6eFJ3cd5ZlXJ9H57IaM1lte\nVsKimTW8bmYNdz6yMwctLzzaB/0pQ3/KsHhlfOYsM7sYOBeojN3mnPtWLhpVqOrrMz1eTVJRhn6U\nX3LpDp461t7FR378VEbrmVlbxXmzajl/1iTOnz2Js2ZMpLwsOPL/F0/tKZgj/3NJ+6A/ZehPGRav\nTKfD+hTw5wRzsD5IcFKA+wEVrnGi0SiRiP4d6EMZ+lF+/XV19/Dc3mM8tPXAkB9bXlbCwpk1nB9X\nqE6fWJl0WR3530f7oD9l6E8ZFq9Me1z/ArgQ2Oice7uZnQH8n9w1q7DE5lndsmULCxcuLOp5VnNt\nzZo1XH/99fluRsEa6/lFu3vYvLuFTTsOs+nlIzzxylGOJ4xrTaW+ppLzZk/CHXyZ9197NWfX11Be\nlnlPqY78D4z1fTAblKE/ZVi8Mi1c251z7WZWYmbmnHvRzBpz2jIPZrYSWFlXVzci2+ubZ7WSdfe/\npHlWRUZIR1d3UKi+fJhNO47w+M6jtEW7h7ye+2+6isZp1QCsXv08582alO2miohIFmRauLaZWQR4\nGvi6me0GRm03gnNuLbC2oaHB5bstIpK5wY78b49289Su5t4e1Sd3Hc1oWqqKMqOjK/XHwbSJ+kNT\nRKQQZFq4fpDghAMfJxgicBlj7OxVIpJb6Y78rwjHm27e00JnBoXquPJSLpg9iSWnTWbx3DrOmD6B\nK766XgdPiYgUuEELVzMrBW5wzv09cAJ4f85bJSJjTvPJaMoj/zu6eng8zdmpJlSUceGcSSwOC9XX\nzawZUIzq4CkRkcI3aOHqnOs2M02IJiLeenoc+461s/3AcbYfPM7LB0+w/WDw+/5jHRmvZ2JlGRfP\nrWPx3MksOW0yZ86YQNkgvaY6eEpEpPBlOlTgHjP7NPB94HjsRufcsZy0Ssas5cuX57sJBS3X+WV6\n9qm2zm5ePhRfmJ5g+4Hj7Dh0YlgHTwFcvWAql82byuLT6lhwykRKS8zruaSifdCP8vOnDP0pw+KV\naeH62fDnvwAOsPCnuiokq2pra/PdhIKWy/zSjUGtipTy9gtmsutIG9sPHPc+RWoyN7/jvBE5bar2\nQT/Kz58y9KcMi1emp3zVkQsyIpqbm/WB4yGX+aU7+1RbtJsfbdw1pPVVV5TROHU8jVOraZxWzYya\nSm5a80w2mupF+6Af5edPGfpThsVLBamMKnfffXe+m1DQcpHfsfYoP31iNx/60RPDevzM2iquOH0K\nN146h3956+v4z/cvZtOnrmbL597IL//n5XzjunP58NJ5vGnhDGqrkveojuSR/9oH/Sg/f8rQnzIs\nXpme8rWHYGhAP845DRUQKULHO7q474/7adq8j4e2HqSze/ApqM6YPoHTp1f39qA2Th3P3CnjGVee\n2YgknTZVREQGk+kY1wlxv1cB70bjW0WKysnOLu5//gBNm/ey/sWDGc2XGu8nH7zEewyqjvwXEZF0\nMh3jeiLu6gngG2a2CfhaTlolIiOirbObB148QNPmfdz/wn7ao6mL1dOnVfPSgeMp7xcREcm1THtc\n+zGzBcCULLcla8xsJbCyrq4u300RGXXao908uPUgd2/ex33P7+dkZ+rpqU6fVs2KRfUsXzSDhklV\nSWcVAJ19SkRERkamY1yP0jfGtZRgOqyP5KpRvpxza4G1DQ0NqU9OLlKkks212nyyk988u4/fPref\n3/1xP8cT7o932pTxrFg0gxXn1DN/+oR+92kMqoiI5FOmPa7nxv3eBbzmnBveLOIiaaxatSrfTSho\nf3bt25P2iq66fWPax82ePI4Vi2awfGE9Z86YgFnyyf3HwhhU7YN+lJ8/ZehPGRavTAtXBxxwzrUD\nmFmlmdU7517NXdNkLIpEcj/BfDHrsZKUc60maphUxfJFM3jzonrOrp+Yslgda7QP+lF+/pShP2VY\nvDItXH8CXBl33cLbFme9RTKm7d27l/r6+nw3o+DsaW7j50/u5r827Uy73CkTK3jzOfUsX1TPOQ01\nKlaT0D7oR/n5U4b+lGHxyvRoivJYbyuAc64NqMhNk2QsW79+fb6bUDCOd3Sx9vFXeed3N3LZl9fx\n9Xu3srulM+1jfvvRK/n08rM499RaFa0paB/0o/z8KUN/yrB4ZTxUwMymOecOAJjZKQS9riIygrp7\nHI9uP8xPn9zNb559jbbo0Iaal5TobSsiIoUr08L1W8CjZvbD8Pq7gH/OTZNEJNG2A6385Ik9/OKp\nPbx2rD3pMqUlxpxxnWw/rrFdIiJSnDI9AcH3zWwH8Kbwpvc4536fu2aJyJETnfzqmb389MndbN7d\nknK5M2dM5O3nz+Qt59Zzzy9+ys0vT9VcqyIiUpQynce1EnjQOfdAeL3EzCrjx72KSGaSzbN6oqOL\n9mg3ZrD+hYP89MndrH/hAF09yacinlJdwbXn1XPteQ2cVT+x9/ZIieZaFRGR4pXpUIF1wJ8CsW6f\nCcDdwOW5aJSMXcU+hUl7tDvpPKvX3voI5aUlVJX///buPLyq8lz/+PcJSUggQIgoUxgUiBOBqCgB\nqRW01grOBVtBRdtqHerU1lrOOR08VntO+2vVKq21qFVpK7RFa/BYK6gVMDgyKAoEFEWQUWYCO8n7\n+yM7McNOSPJmZ629c3+ua19mrb2GZ98swuPa71orhZ37Yz8cID01hbOO68nFJ+XyhcE9SI1x9jQt\nLa1d3Gs1npL9GIw35edPGfpThsmrqY1rJ+dc9XeVzrmdZpYVp5qkHUv2m0ZHyisavM/qwfIKDu6v\nqDf/5IHdufjEXL6S35tumY3/Mk72/NqCMvSj/PwpQ3/KMHk1tXFNMbMs59weADPr2ox125yZTQQm\n5uTkBF2KSC0VDXz1X1f/nE5cdGJfLjyhLwMO6xznqkRERBJDU6/UmAm8YGZTzWwq8Dzwx7hV5ck5\nN9s5NykzMzPoUqSZSkpKgi4hLrbuOcD0l0o45zeNX9P41ZP6Mvvbo3j5+6dz85l5zW5akzW/tqQM\n/Sg/f8rQnzJMXk29q8D/mNmnwHgqH//6G2BvPAuT9mnx4sUMHjw46DJahXOOxR9sZ+bij3junY1E\nyg99tvXH5x5Pl4yWj81KpvyCogz9KD9/ytCfMkxeTf663zn3RzNbDHwD+H/AeuCpeBUmkqh27ovw\nt7fWM3PxOtZs0f/fiYiItJZDNq5m1gm4hMqG9SggExjlnHs/zrWJJAznHEvX72Rm8TqeWbaB0kj9\ni6wATh10GEs+3sHeg/WfeKX7rIqIiDSu0cbVzB4CLgL+DfwP8H/AajWtIpX2Hijj6SUbmLl4He9u\n2BVzmZzO6Uwckculp/RnwGGdKY2U6z6rIiIiLXCoM65fA94AHgT+6ZxzZta0y6JFktj7n+5iZvFH\nzHn7E/YciH3f1VMG5jC5sD9nD+1Fx9TPG1LdZ1VERKRlDtW49qZymMCPgN+b2WOA7uorcdOtW7eg\nSwBiP91qx76DPPn6R8x6Yz1vrvss5npdOqZy0Yl9mVw4gLyeXdqi1FrCkl8iU4Z+lJ8/ZehPGSav\nRhvX6H1bZwAzzOw44Cog3cwWAU8456a3QY3SjkyYMCHoEhp8utWkB4sbXCe/bzemFPbn3OF96JQe\n3C2Ow5BfolOGfpSfP2XoL5kzzOmczk1nDKk13Z40564CK4DvmdntwPlUNrFqXCXpHIiUN/h0q5oy\n0lI4f3hfJhf2Z1hudhtUJiIi7V2PrI7c8qW8oMsITLMvYXbOlTnn/uacGx+PgqR9W7ZsWZvv0znH\nh1v3MnPxOq6f+Ran//KlRpc/qkdnfnLucSyedib/89VhoWpag8gv2ShDP8rPnzL0pwyTV2gf2yrt\n0/Llyxk2bFjc97NpVykLS7ayaM02FpVsZcPO0iav+9T1o+maGc6vZtoqv2SmDP0oP3/K0F+QGbb3\nr/LjLSkbVzObCEzMyckJuhQJiR37DlK8dhsLS7axaM1WrwcDmFkrViYiIm0tns1lIn+VX5XL8uXL\nyc/PD2XTnZSNq3NuNjA7NzdXt+5KUrGu+t97oIzSSDkZaR3Yd7CM1z7YzqtrtrFwzVbe3bALd4ij\nIcUgPzebkwd05w8LPohj9SIiEqREbi7jqSqXmZtfZ3JI80nKxlWSW0NX/V84fREZqSkc36cryz7Z\nSaT80P/fcnTPLowefBijB/Vg5FE5dM1IozRSzl/fXB/zAi093UpERCQ4alwl4UTKKxq86r+0rII3\nP9rR4Lr9czoxetBhjB7cg1FHHcbhXTrWWyYjrQPF087Q061ERERCRo2rhErv3r0PuUykvKLJ2zu8\nS8fKRnVQ5VnVfjmdmrReoj7dqin5SeOUoR/l5y9RMoznOFHfbSdKhmEV5vzUuEqojBs3rsH3ysor\neHrJBu55YVXj2zj6cE7LO5xTB/dg8BFZ7epiqsbyk6ZRhn6Un79EyTCe40R9t50oGYZVmPNT4yqh\nV17hKFq2gXtfWM3arYe+G8C9Xz+BLhl6MrGIiEiy0VUmEirFxZ8/VrUi2rB++Z5/c9NfljSpaW3v\nauYnLaMM/Sg/f8rQnzL0E+b81LhKqKxZs4aKCsdz72zkK/e+wg1/epuSzXtqLTPgsE50So891rS9\nX/W/Zs2aoEtIeMrQj/Lz11oZVo0TrXqF8Z6c8aLj0E+Y84v7UAEzGwL8EegB7ASmOufejbHcD4Ar\ngINAKXCjc+616HsOeAcojy7+HefcK/GuXdqWc473dqUy4TcLWLFxV733++d04sYzhnBBQR/KKpyu\n+hcRaYTuVSrJqC3GuD4I/N4596iZfRV4FDi55gJmVgBcBxzvnNtjZlOA+4FTaiz2Bedcw/c5koTl\nnOOllVv41b9WsfyTLKB209o3O5MbzxjMRSfmVp9NTe1AQl71LyIiIi0X18bVzI4ARgBnRWf9Dbjf\nzAY750pqLOqANKAzsAfIBtbHszYJnnOOV1Zv5Vf/WsWSj+v/P0nvbhncMG4wE0/qR3pq+/36X0RE\nRCrF+4xrP2Cjc64MwDnnzOwjoD9Q3bg655aa2a+BD8xsO3AAOK3Otl40sxRgHvBfzrl6V+qY2a3A\nrVXTWVlZzJw5s15RvXv3rr7VQ3FxccyxHIMGDaKwsBCA+fPns3HjxnrL5OfnM2zYsHrzi4qK6JlR\nea/RkSNHMnjwYABmzZpFJFL/xvljx46lT58+RCIRZs2aVe/9TaUpQNeY269p0qRJpKWlsWHDBl58\n8cV676elpTFp0iQASkpKWLx4cb1tv/zSy+RdMgGAZcuWsXz58nrbaW5+NRUVFXFExwrW7k3l1T05\nvLflYL1luqRWcPoRpYzovoORhw2oblrr5le39rJIWcw/b4Dx48eTnZ3Njh07mDt3bsxl6uZXd/vP\nPfcceVdMBD7Pr65u3boxYcKh88s9vtaXDvX+TJt7/BUVFbFz504WLlwI1M8GWn78Qe38ior+j1jH\nY0uOv7q6detG3slfrDWvbjY+f39j5VK1j507dwJUZwjN//tbVFQUM5uWHH91bStLBz6/D3Gs3wNN\nPf5i5ddQNs05/qDh/GqqWXtzj79Y+TXld2RTj7+6+dXd9uLFi8k770ygdf79yOmczlf6OQ4cOADA\ni889w9LFlRm2xr8f0LLff3W1NL+64vHvb83jr8rChQuVH4mTX3OYO9QD3H02bnYS8Cfn3NE15r0G\n3O6cm19j3pHAn4CLnXMbzOwG4GvOuTHR9/s75z4ys87A74DdzrnrDrX/3Nxct359/E/crtq0m7N+\n/e/q6edvOY28nl0SYvvx3HZppLzeONQ7Lziep9/ewOvrPqu3fI+sjpxzZAemTTqtSV/5K/f6iouL\nKSwsTMja22L7Tdl2VYbx2n5LJUrusfJLlNpj2brnAI+/uq56+rJRA+iRVf+Je63J5xiUSsrQT1vn\nZ2afOOdym7JsvM+4fgz0NrNU51yZVd4Jvj/wUZ3lLgaWO+c2RKcfAX5jZunOuYPOuY8AnHN7zWw6\n8Ps41y2eSiPlFN41r96jWf/zqXrX5XFY53S+/cVBTCkcQGYDdwuQptEvan/K0E+y5RfEBU7JlmEQ\nlKGfMOcX18bVObfZzN4CplB5UdbFwPo641sB1gJXmlmWc24PMAFY5Zw7aGbdgQPOuX3RoQKXAG/H\ns27xFymvqNe01pXdKY1rThvE5aMG1LvQSkRERKSutrji5RrgGjNbBdwOXAlgZneY2bejy8wB/gG8\nYWZLgZuAS6PvHQMUR+cvBw4Dbm6DusVDeUXjQ1C+M24Qr9w2lmtPH1SraZ0/f34ja8mhKD9/ytCP\n8vOnDP0pQz9hzi/up7mccyuBUTHm/6jGzw74YfRVd7lXgfpXQElord2yh1ueXNLoMlefNijmY1lj\nDSKXplN+/pShnyDyq7rRfs3pRKZj0J8y9BPm/PT9rLSaigrHI4s+5H+fe58DZfXveiAiEg+60b5I\n+6HGVVrFum17+f7sZbz24fagSxEREZEkpcZVvFRUOJ5YvI67n32f/ZHyWu91TE2JeeY1OzOt+glY\nIiIiIk2lxlVa7OPt+/jB35axaM22WvP75WTyi68Op6Bfdr37uM65bjTH9u6qR7OKtCPJNgZVRIKj\nxlWazTnHn1/7mJ/NXcHeg7XPsl5WOIDbv3JM9Z0C6t7mqnPH1Eab1vz8/NYvuB1Rfv6UoZ9Y+WkM\navPoGPSnDP2EOT81rtIsG3bs5wd/W8Yrq7fWmt83O5P//eowTh3cw2v7sR6hK02n/PwpQz/Kz58y\n9KcM/YQ5v6RsXM1sIjAxJycn6FKShnOO2W+u57+fWcHuA2W13vv6Kf2Yds6xMW9vJSIiItJakvIK\nGefcbOfcpMzMzKBLSQqbdpVy1aOvc9tfl9VqWnt1zeCPV53C3RcNa7WmtaioqFW2014pP3/tNcOq\ncahVr5aOQ22v+bUmZehPGfoJc35JecZVWodzjqeWfMKPn36XXaW1z7J+9aRc/mvCcXTLbN2zrDt3\n7mzV7bU3ys9fe82wtcahttf8WpMy9KcM/YQ5PzWuEtPm3aX8x5x3+NeKTbXmH96lIz+/KJ8zju0Z\nUGUiIiLSXqlxlVqcc/xj6QZ+9PQ77NgXqfXehSf05cfnHkd2J93KRkRERNqeGtd2rDRSzt46F1r9\n5B/v8ura2k+/6pGVzp0X5HP20F5tWZ6I1KB7oYqIqHFtt0oj5RTeNY8d+2ufVa3btI4f1pv/Pn+o\n/pEUCZjuhSoiosa13YqUV9RrWmvKzkzlzgvzmTCsTxtWBSNHjmzT/SUb5edPGfpRfv6UoT9l6CfM\n+alxlZjmXD+GI3t0bvP9Dh48uM33mUyUnz9l6Ef5+VOG/pShnzDnl5T3cZVDW1DnyVd19cjS0AAR\nEREJFzWu7YxzjgdeLOHamW8FXUpMs2bNCrqEhKb8/ClDP8rPnzL0pwz9hDk/DRVoR/YcKOP7s5fy\nf+98GnQpDYpEGh53K4em/Pz5ZKgr/3UMtgZl6E8Z+glzfknZuJrZRGBiTk5O0KWExgdb93L1Y2+w\nevOeQy6bnZlGWgedjBdpLl35LyISX0nZuDrnZgOzc3NzXdC1hMH89zdx01+WsLvGY1uP6NKRe792\nAhlpKVw4fVH1/DnXjebY3l3JSOsQRKkiIiIiDUrKxlUqVVRUjmf91QurcDVa+BP7Z/PbKSfRs2sG\nqzbtrrVO546palpFREQklNS4JqndpRG+O2spz6/YVGv+5JH9+fG5x5OeqqEA0v5oDKqISGJT45qE\n1mzZw9WPvcGaLXur56V3SOGO84/na6f0D7CyQxs7dmzQJSQ05de4poxBVYZ+lJ8/ZehPGfoJc35q\nXJPMv1Zs4tYnl7D7wOfjWXt27cjvppzECf27B1hZ0/Tp07ZP6ko2ys+fMvSj/PwpQ3/K0E+Y81Pj\nmiQqKhz3zV/NPS+srjX/5IHdeWDyiRzRJSOgyponEomQlpYWdBkJS/n5U4Z+lJ8/ZehPGfoJc34a\n6JgEdpVGuPrxN+o1rZePGsDMbxYmTNMK4b7pcSJQfv6UoR/l508Z+lOGfsKcn864JriSzbu5+rE3\nWbu1xnjW1BTuvGAok0b0C7AykZbRBVQiItIQNa4J7J/vfsqtTy5h78Hy6nm9u2XwuyknMbxfdoCV\nibScbuIvIiINUeOagCqc4/89v5LfzC+pNf+UI3OYPvlEemR1DKgyERERkfhR45qAfvT0u7z2wfZa\n86aOHsh/jD9Wj2oVERGRpJWUjauZTQQm5uTkBF2Kt9JIOXtr3NoKqNW0dkxN4a4L87n4pNy2Lk1E\nRESkTSVl4+qcmw3Mzs3NdYdcOMRKI+UU3jWPHfsjMd/v0y2DBy8bQX5utzauLH7Gjx8fdAkJrS3y\nS/aLp3QM+lF+/pShP2XoJ8z5JWXjmiwi5RUNNq0Af766kAGHdW7DiuIvO1sXlfloi/yS/eIpHYN+\nlJ8/ZehPGfoJc34aEBlSy9bv4Dt/ervRZZLtTBfAjh07gi4hoSk/f8rQj/Lzpwz9KUM/Yc5PjWvI\nvLnuM6Y+8hrn3b+Ql1ZtCbqcNjd37tygS0hoys+fMvSj/PwpQ3/K0E+Y89NQgZBYvHYbv5lfwoKS\nrUGXIiIiIhJKalwD5Jxj0Zpt3DdvNYvr3N4KIDMthf2RigAqExEREQkfNa4BcM7x8qot/GZ+CW+u\n+6ze+106pjL11IFMHtmfs+95JeYFWtmZabpnq4iIiLQralzbkHOOee9t5jfzV7N0/c5673fNSOUb\nY45i6qkD6ZaZBkDxtDN4b+MuLpy+qHq5OdeN5tjeXclI69BmtYuIiIgETY1rG6iocDy/4lPum1fC\nio276r3fvVMa3/zCUVw+agBdMtJqvZeR1oHOHWv/MXXumKqmVURERNodNa5xVF7heHb5Ru6fX8LK\nTbvrvd8jK52rTzuKySMH1GtO26tJkyYFXUJCq8ov2R8SEE86Bv0oP3/K0J8y9BPm/NQteYr1SNZd\n+yPMeuMjHnx5LWu27K23zhFdOvLtLw7i66f0JzNdZ05rSktLO/RC0qCq/JL9IQHxpGPQj/Lzpwz9\nKUM/Yc4vKRtXM5sITMzJyYnrfhp6JOtXf/dqzOX7dMvg2tMHMXFEP33V34ANGzbQp0+foMtIWMrP\nnzL0o/z8KUN/ytBPmPNLysvSnXOznXOTMjMz47qfQz2StUpu90zuviifl74/lstGDVTT2ogXX3wx\n6BISmvLzpwz9KD9/ytCfMvQT5vyS8oxrWPTvnsl3zhjCBSf01a2rRERERDypcY2jp284le6dOwZd\nhoiIiEhS0GnAOErVWVYRERGRVqPOSkREREQSghpXD2kdUsjOjH3LCD2StWXCfAuORKD8/ClDP8rP\nnzL0pwz9hDk/jXH1kJHWQY9kbWVhvulxIlB+/pShH+XnTxn6U4Z+wpyfTgl60iNZRURERNpGQ33A\n+gAAIABJREFU3BtXMxtiZovMbJWZvW5mxzew3A/MbIWZLTGzYjM7pcZ7I81saXQb882sb7zrlmCU\nlJQEXUKbqHoka9WrtR7J2l7yiydl6Ef5+VOG/pShnzDn1xZnXB8Efu+cywP+B3i07gJmVgBcB5zi\nnCsA7o++MLMUYCZwc3QbzwL3tEHdEoDFixcHXUKbqHoka9WrR1br3DatveQXT8rQj/Lzpwz9KUM/\nYc4vro2rmR0BjACeiM76G9DPzAbXWdQBaUDn6HQ2sD7680lAmXOu6jEODwLnmllG3AoXERERkdCJ\n98VZ/YCNzrkyAOecM7OPgP5A9Xlo59xSM/s18IGZbQcOAKdF3+4PrKux7G4z2wX0AdbW3JmZ3Qrc\nWjWdlZXFzJkz6xXVu3dvxo0bB0BxcTFr1qypt8ygQYMoLCwEYP78+WzcuLHeMvn5+QwbNqze/KKi\nInpmVAAwcuRIBg+u7NNnzZpFJFL/EbFjx46lT58+RCIRZs2aVe/9TaUpQNeY269p0qRJpKWlsWHD\nhpiPa0tLS6secF1SUsLixYvrbfvll14m75IJACxbtozly5fX205z86upZu018ysqKmLnzp0sXLiw\n1vKN5Ve39rJIWcw/b4Dx48eTnZ3Njh07mDt3bsxl6uZXd/vPPfcceVdMBD7Pr65u3boxYULr5teU\n468l+VU51PEHLcuvrljHX11B5wfUylD5Kb+64p0ffJ6h8mtZflCZofJLnPyaw5xz3htpcONmJwF/\ncs4dXWPea8Dtzrn5NeYdCfwJuNg5t8HMbgC+5pwbY2YXA1c7575cY/nNQKFzrlbjWldubq5bv359\nY4u0ilWbdnPWr/9dPf38LaeR17NLQmw/bLXPnDmTyZMnx2XbzRXv7cdDc/KT2JShH+XnTxn6U4Z+\n2jo/M/vEOZfblGXjPcb1Y6C3maUCmJlReQb1ozrLXQwsd85tiE4/ApxqZunRZQdULWhmXYBuwAZE\nREREpN2Ia+PqnNsMvAVMic66GFjvnKt7udpaKhvVrOj0BGCVc+4g8CaQZmZjo+9dAzzjnCuNZ+0S\njG7dugVdQkJTfv6UoR/l508Z+lOGfsKcX1s8gOAa4FEzmwbsAq4EMLM7gA3Oud8Bc4CTgTfM7ACw\nF7gUwDlXYWZTgAejF2RtAC5rg7olAFXje6RllJ8/ZehH+flThv6UoZ8w5xf3xtU5txIYFWP+j2r8\n7IAfRl+xtvEqUP8qKBERERFpN/TkLAmVZcuWBV1CQlN+/pShH+XnTxn6U4Z+wpyfGlcJlVi3/5Cm\nU37+lKEf5edPGfpThn7CnJ8aVxERERFJCG1xcZZIQsrpnM5NZwypNS0iIiLBUeMq0oAeWR255Ut5\nQZchIiIiURoqICIiIiIJISkbVzObaGaz9u/fH3Qp0ky9e/cOuoSEpvz8KUM/ys+fMvSnDP2EOb+k\nbFydc7Odc5MyMzODLkWaady4cUGXkNCUnz9l6Ef5+VOG/pShnzDnl5SNq4iIiIgkHzWuEirFxcVB\nl5DQlJ8/ZehH+flThv6UoZ8w56fGVUJlzZo1QZeQ0JSfP2XoR/n5U4b+lKGfMOen22FJwtJ9VkVE\nRNoXNa6SsHSfVRERkfZFQwVEREREJCGocRURERGRhKDGVUJl0KBBQZeQ0JSfP2XoR/n5U4b+lKGf\nMOenxlVCpbCwMOgSEpry86cM/Sg/f8rQnzL0E+b81LiKiIiISEJIysbVzCaa2az9+/cHXYo00/z5\n84MuIaEpP3/K0I/y86cM/SlDP2HOLykbV+fcbOfcpMzMzKBLkWbauHFj0CUkNOXnTxn6UX7+lKE/\nZegnzPklZeMqIiIiIslHjauIiIiIJAQ1riIiIiKSENS4ioiIiEhCUOMqoZKfnx90CQlN+flThn6U\nnz9l6E8Z+glzfqlBFyDJLadzOjedMaTWdGOGDRsW75KSmvLzpwz9KD9/ytCfMvQT5vzUuEpc9cjq\nyC1fygu6DBEREUkCGiogoVJUVBR0CQlN+flThn6Unz9l6E8Z+glzfmpcJVR27twZdAkJTfn5U4Z+\nlJ8/ZehPGfoJc35qXEVEREQkISRl42pmE81s1v79+4MuRURERERaSVI2rs652c65SZmZmUGXIiIi\nIiKtJCkbVxERERFJPmpcJVRGjhwZdAkJTfn5U4Z+lJ8/ZehPGfoJc35qXCVUBg8eHHQJCU35+VOG\nfpSfP2XoTxn6CXN+alxFREREJCGocZVQmTVrVtAlJDTl508Z+lF+/pShP2XoJ8z5qXGVUIlEIkGX\nkNCUnz9l6Ef5+VOG/pShnzDnp8ZVRERERBKCGlcRERERSQhqXEVEREQkIahxFREREZGEkJSNq5lN\nNLNZ+/fvD7oUaaaxY8cGXUJCU37+lKEf5edPGfpThn7CnF9SNq7OudnOuUmZmZlBlyLN1KdPn6BL\nSGjKz58y9KP8/ClDf8rQT5jzS8rGVRJXmG/BkQiUnz9l6Ef5+VOG/pShnzDnp8ZVQiXMNz1OBMrP\nnzL0o/z8KUN/ytBPmPNLDboACVZO53RuOmNIrWkRERGRMFLj2s71yOrILV/KC7oMERERkUPSUAER\nERERSQhqXEVEREQkIahxFREREZGEEPfG1cyGmNkiM1tlZq+b2fExlvmymS2p8dpgZm/VeN+Z2fIa\n738h3nVLMMaPHx90CQlN+flThn6Unz9l6E8Z+glzfm1xcdaDwO+dc4+a2VeBR4GTay7gnPsn8M+q\naTMrAl6ss50vOOd2xLlWCVh2dnbQJSQ05edPGfpRfv6UoT9l6CfM+cX1jKuZHQGMAJ6Izvob0M/M\nBjeyTh/gDODxeNYm4bRjh/7fxIfy86cM/Sg/f8rQnzL0E+b84n3GtR+w0TlXBuCcc2b2EdAfKGlg\nnanAs865zXXmv2hmKcA84L+cc3vrrmhmtwK3Vk1nZWUxc+bMejvo3bs348aNA6C4uJg1a9bUW2bQ\noEEUFhYCMH/+fDZu3Fhvmfz8fIYNG1ZvflFRET0zKgAYOXIkgwdX9umzZs2K+TSKsWPH0qdPHyKR\nSMyb/m4qTQG6xtx+TZMmTSItLY0NGzbw4ot1T1hDWloakyZNAqCkpITFixfXW6Zbt25MmDABgGXL\nlrF8+fJ6y8Qjv6KiInbu3MnChQs59dRTq5dpjfyg8muP7OxsduzYwdy5c2Muo/yUH1ArQ+Wn/OqK\nd37weYbKr2X5QWWGt956q/JLkPyaw5xz3htpcONmJwF/cs4dXWPea8Dtzrn5MZY3YDVwo3Pu2Rrz\n+zvnPjKzzsDvgN3OuesOtf/c3Fy3fv361vgojVq1aTdn/frf1dPP33IaeT27JMz2w2TmzJlMnjw5\n6DISlvLzpwz9KD9/ytCfMvTT1vmZ2SfOudymLBvvi7M+BnqbWSpUN6b9gY8aWP6LQAY1xrsCOOc+\niv53LzAd0MVZIiIiIu1MXBvX6Nf9bwFTorMuBtY75xoaJvAN4FHnXHnVDDPrbmadoj+nAJcAb8ev\nahEREREJo7a4q8A1wKNmNg3YBVwJYGZ3ABucc7+LTncDLgLy66x/DPCgmblovW8BN7VB3SIiIiIS\nInFvXJ1zK4FRMeb/qM70TqBzjOVeBepfASUiIiIi7UpcL84Kmi7OSjyRSIS0tLSgy0hYys+fMvSj\n/PwpQ3/K0E9b5xemi7NEmkW/aPwoP3/K0I/y86cM/SlDP2HOT42rhMqGDRuCLiGhKT9/ytCP8vOn\nDP0pQz9hzk+Nq4RKrBs3S9MpP3/K0I/y89deM3TOUVFRQXl5uffrpZdeapXttNdXa+dXUVFBaw1N\nbYu7CoiIiIjEVFFRwebNm9mxY0erNTd5eXmsWrWqVbbVHsUjPzMjOzubI444gpSUlp83VeMqIiIi\ngVm3bh0pKSkMHDiw1cZWbt++nZycnFbZVnsUj/wikQibNm1i3bp1HHnkkS3eTlI2rmY2EZiog1ZE\nRCS8KioqKC0tZciQIaSmtl5LkpKSQocOHVpte+1NPPLr0KEDffv2ZfXq1VRUVLT4rGtSNq7OudnA\n7Nzc3OS915eIiEiCqxoaUPlE+ObZuucAj7+6rnr6slED6JHVsdVqk9ZX9efsMyQkKRtXSVxhvgVH\nIlB+/pShH+XnTxkeWmmknI+37+Peeaur551+9OFkdUwlI61Dixph+VyY81PjKqEyadKkoEtIaMrP\nnzL0o/z8KcPGlUbKKbxrHjv2R2rNv3D6IrIz0yiedobX+MyCggIADh48yMqVK8nPr3wS/dFHH82T\nTz7Z7O39/e9/Jzc3l1NOOaXR5U499VS2bdvG+++/3/yiW1mYh1qqcU0AOZ3TuemMIbWmRUREkk1p\npJyPtu9rdJm9B8rqNa1VduyP8N7GXXTu2Hh70z+nExlpscdwLlmyBIAPP/yQgoKC6umW+vvf/05h\nYWGjjev777/PunXryMrKYsGCBYwZM8Zrn01RVlbWquOK20riVdwO9cjqyC1fygu6jDZRUlLC4MGD\ngy4jYSk/f8rQj/Lz154z/Gj7vlqPOG+JC6cvOuQyPo9O/+Mf/8j06dOJRCJ06dKFBx54gKFDh7Jw\n4UK+853vUFFRQVlZGTfeeCO9evXi2Wef5aWXXuIPf/gDN910E1deeWW9bc6YMYPLL7+c7t27M2PG\njFqN6z/+8Q/uuOMOIpEIKSkpPPTQQ4wYMYKFCxdy2223sXv3bgDuuusuJkyYQG5uLs899xxDhw4F\nKs8g33///YwZM4YxY8YwYsQIiouL6dKlC0VFRZx33nls27aN0tJSCgoK+P3vf09KSgoZGRnMmDGD\n++67D6gcwjJnzhx+9rOfcdRRR3HbbbcBsGLFCr7yla+wdu3aNrkgTo2rhMrixYvb7S/s1qD8/ClD\nP8rPnzIMr5dffpm//vWvvPLKK6Snp/Piiy8yefJkli5dyl133cUPf/hDJk6cCMBnn31G9+7dOeec\ncygsLOSGG26Iuc1IJMLjjz/OK6+8QteuXTnmmGO477776NKlC++99x7f/OY3WbBgAXl5eRw8eJDS\n0lK2bt3KhRdeyFNPPcXo0aOpqKhgx44dTfoMq1ev5pVXXiEtLY2Kigr+/Oc/k5OTg3OOa665hunT\np3PllVeyYMEC7r77bhYsWECvXr3Yu3cvKSkp3HjjjUyYMIHvfe97pKSk8MADD/Dtb3+7ze7ioMZV\nREREpAmefvpp3n777Vpf+2/ZsoWDBw8ybtw4fvrTn/L+++9zxhlnMHr06CZts6ioiLy8PIYMqRwS\n+MUvfpG//OUvfOtb3+L5559nwoQJ5OVVfuuanp5Oeno6Tz/9NEOHDq3eR0pKSpPHpV522WXVFwA6\n5/jlL3/Js88+S3l5OTt37mTfvsqhGnPnzuXyyy+nV69eAHTu3BmA4447jsGDB1NUVMTYsWOZNWsW\n7733XpP23RrUuIqIiEgo9M/pxPO3nNboMnsPlDU6HGDOdaOJ7N9DdnZ2o/tpCeccV111FXfccUe9\n97773e9ywQUXMG/ePG677TZOPPHE6q/ZGzNjxgxWrFjBwIEDAdi/fz+ffvop3/rWt1pUY2pqKuXl\n5dXTpaWltd7Pysqq/rnqTO8rr7xCly5d+NWvfsWiRYceanHTTTdx77338vHHH3POOefQo0ePFtXa\nEi1/5paIiIhIK8pI60Bezy6Nvo7t3ZXszNi3DMvOTOPY3l0Z1KNTo9to6MKsQzn//PN57LHHWL9+\nPVD5AIU33ngDgJUrVzJo0CCuvvpqbr/9doqLiwHo2rUrO3fujLm9DRs28PLLL/PBBx/w4Ycf8uGH\nH/LJJ5/wwQcf8O6773L22Wczd+7c6sevHjx4kF27djFmzBjefffd6iazoqKC7du3AzB48GAWL14M\nwKuvvkpJSUmDn+ezzz6jR48edOnShV27dvHYY49Vv3feeefx2GOP8emnnwKwd+9e9u/fD8A555zD\nunXruPvuuxscAhEvalxFREQkYWSkdaB42hnMua72V/FzrhtN8bQzWtyUNsXpp5/OXXfdxXnnncfw\n4cM5/vjjmT17NgD33HMPxx9/PCeccAI//elP+cUvfgHA5ZdfzsyZMykoKOCRRx6ptb1HH32Uc845\nhy5dPr9QLDU1lUsuuYQZM2Zw9NFH84c//IGvf/3rDB8+nMLCQlavXs1hhx3GnDlz+N73vsewYcM4\n8cQTqxvln/3sZ9xzzz0UFBTwxBNPcOyxxzb4eaZOncquXbs45phjGD9+PKed9vnZ7rFjxzJt2jTO\nOusshg8fzumnn862bduAyvu8XnXVVfTt25eTTz65dcJtIg0VkFDp1q1b0CUkNOXnTxn6UX7+lOGh\nZaR1qHfLq87Rhw8ArXKh0MCBA2Ne8HTppZdy6aWX1pv/29/+NuZ2CgsLWbFiRcz3pk2bFnN+zSEG\n5557Lueee269ZUaPHh3za/2RI0c2uL8FCxbUmu7evTvz5s2rt1zV577qqqu46qqrYm7rpZde4uab\nb475XjwlZeNqZhOBiWG+ga7ENmHChKBLSGjKz58y9KP8/CnDpmnsHueNjW+VQ2ssv8WLF3PppZcy\nbNiwQB6WkZSNq3NuNjA7Nze35Q/DFRERkdBqT/c4D5ORI0eyZs2awPavMa4SKsuWLQu6hISm/Pwp\nQz/Kz58y9Fd1SydpmTDnp8ZVQmX58uVBl5DQlJ8/ZehH+flThv6qrn6Xlglzfkk5VEBERESS3J4t\n8PofPp8++ZuQdXhw9UibUOMqIiIiiWffVnj5559PH3+BGtd2QEMFREREJLFESuHg3trzDu6tnO+p\noKCAgoICjjvuODp06FA9fckllzR7W1deeSWvvPJKi+rYuXMnnTp14pprrmnR+slKZ1xbQdUtOZYv\nX05+fn6tW3KIiIhIK4qUwq+Ogf2f1Z7/hzMgszvc+r7X5pcsWQLAhx9+SEFBQfV0LGVlZaSmNtxK\n1X3gQHP8+c9/5pRTTmH27Nn8+te/plOnlj2mtjkO9XnCQGdcW0HVLTmmFHTnli/l0SOrY9AlJaze\nvXsHXUJCU37+lKEf5eevXWcYKYXN7zX+2vRO/aa1yv7PYNM7dNy5tvFttPDM7AsvvMCwYcOYOnUq\nBQUF/OMf/+Dxxx/nlFNO4YQTTqCgoIBnn322evkxY8ZQVFQEwJQpU7j22msZN24ceXl5TJw4kUgk\n0uC+ZsyYwbRp0xg1alT107kAnHPcddddDB06lOHDhzNq1CgOHDhQvc7w4cMZPnw4I0aM4OOPP6ak\npIQePXpUr79jx47q5rSsrAwz4yc/+Qknn3wy//mf/8mSJUuYMGECJ554Iscddxx333139boHDhzg\nu9/9bvW+x48fj3OOY489ltdee616uenTpzN58uQWZXwo4W6rE8y4ceOCLiHhKUM/ys+fMvSj/Py1\n6ww/+wCmF/pt4w9nkHWoZa4rhiMafhRqY9555x2mT5/OmDFjANi6dStTpkzBzFi7di2jR4/m448/\nJi0trd66S5cuZd68eaSnp3Pqqafy1FNPMXHixHrLLVu2jM2bN3PmmWeyZ88e7rnnHq644goAHn74\nYZ555hkWLVpE165d2b59O2lpabzwwgvcfffdLFiwgF69erF3715SUlL45JNPDvmZ0tPTef311wHY\ntWsXL730Eh07dmTfvn2MGjWKL33pS4wYMYI777yTDz74gLfeeov09HS2bNmCmXHjjTdy//3389hj\njwGVjetDDz3UonwPRWdcRURERJooLy+vumkFWLt2LWeffTZDhw7loosuYvv27axbty7muhdddBGZ\nmZl06NCBk08+ucEb+c+YMYMrrriClJQUzj33XFauXMmqVasAKCoq4tprr6Vr164A5OTkkJKSwty5\nc7n88svp1asXAJ07dyYzM7NJn6nmY1337dvHN77xDfLz8xk1ahQff/xx9XCJoqIibr75ZtLTK4dE\nHn545cVwl19+Of/617/YsmVLddM7atSoJu27udS4tqLi4uKgS0h4ytCP8vOnDP0oP3/KMNyysmqf\nz500aRLXXnst77zzDkuWLCEjI4PS0thDETIyMqp/7tChA2VlZfWWOXDgADNnzuThhx9m4MCBDBky\nhNLSUh5++OEW1Zuamkp5eXn1dKzaan6m22+/nZycHN5++22WLl3KmDFjGvw8VTp37syUKVN46KGH\neOCBB7jhhhtaVGtTaKhAK1qzZg2FhZ5fcbRzytCP8vOnDP0oP3/tOsPuR1Z+jd+Yg3srL8RqyDfn\nsWNfhOzs7Mb300p27NjBkUdWbu/RRx9l9+7dXtt76qmnOOaYY1iwYEH1vOXLl3PWWWdx5513ct55\n5/Hb3/6WCy64gK5du/LZZ5/RrVs3zjvvPL71rW9x9dVX1xoq0KdPHw4ePMjKlSs5+uijq7/Ob8hn\nn31GXl4eqamprFixgnnz5nHWWWcBcN5553HPPfdQWFhYPVSg6qzrDTfcwKmnnkp5eTmPP/64VwaN\nScrG1cwmAhNzcnKCLkVERESaKi3j0GNPI6WVdw+IdYFWZnfoOZTyXXvhsMPiU2Md9957L+effz45\nOTmceeaZ9O3b12t7M2bMqHdhU35+PocffjjPPvssU6dO5dNPP2XUqFGkpaXRuXNn5s+fz9ixY5k2\nbRpnnXUWZkZ6ejpz5swhNzeXe++9l7PPPpsePXpw8cUXN7r/H/3oR0yePJm//OUvDB48uNaY62nT\npjFt2jQKCgpIT0+nX79+PPPMMwAMGDCA/Px8hg0bVuvMcmsz51zcNh603Nxct379+jbb38yZM+N2\nFV17oQz9KD9/ytCP8vPXnjIsLy9n1apV5OXl0aFDh6avGCmtvLtAzTOv35wHPYdCWgbbtm3jsDZq\nXJNRS/LbvXs3xxxzDK+++ir9+/ePuUxDf95m9olzLrcp+0nKM64iIiKSxNIyIHsAfPH2z+dlD6ic\nL23ugQce4Oc//zk33nhjg01ra1HjKiIiIokn63AY+8OgqxDg+uuv5/rrr2+TfemuAq1o0KBBQZeQ\n8JShH+XnTxn6UX7+lKG/jh31ICAfYc5PY1xFREQkEBUVFaxcuZIhQ4aE/lGj4q+srIzVq1dz9NFH\nk5Ly+blTjXEVERGR0EtJSSEjI4NPPvmEnj17xnzalCSHSCTCpk2byMjIqNW0Npca11Y0f/789v2o\nvlagDP0oP3/K0I/y89feMhwwYACbN2/mww8/pLW+BS4tLY3rLZmSXTzyMzOys7M54ogjvLajxrUV\nbdy4MegSEp4y9KP8/ClDP8rPX3vLMCUlhV69etGzZ0+cc63SvD755JNccsklrVBd+9Ta+ZlZ9cuX\nGlcREREJXGs1NgDOuebdF1ZqCXN+uquAiIiIiCQENa4iIiIikhCSsnE1s4lmNmv//v1BlyIiIiIi\nrSSp7+NqZgeALc1YJRPw6XazgD0e67dGDYm+vm+GQdcf9Po6BoPPMOj6g15fx2DwGQZdf9DrgzJM\ntGPwcOdc0556UHUFn14OYJbn+utDUEOir++VYQjqD3p9HYM6BoNeX8egjsFA11eGiX8MNvZKyqEC\nHmYHXQD+NST6+r6Crj/o9VtD0J8h6PV9BV1/0Ou3hqA/Q9Dr+wq6/qDXbw1Bf4ag1/cVt/0n9VCB\ntmZm610TH1kmsSlDP8rPnzL0o/z8KUN/ytBPmPPTGdfW9augC0gCytCP8vOnDP0oP3/K0J8y9BPa\n/HTGVUREREQSgs64ioiIiEhCUOMqIiIiIglBjWszmdkQM1tkZqvM7HUzOz7GMvlm9m8ze9/M3jGz\nh80sM4h6w6iJGR5pZm+a2ZJohrPNrHsQ9YZNU/Krs/yjZubMLLutagy7Jh6DA82sPHoMVr0GBVFv\n2DT1GDSz/mb2jJmtNLMVZvadtq41rJp4DH65zvG3wczeCqLesGnGMfiD6LG3xMyKzeyUtq41rJqR\n4fej/w6vMLM5gf9bEq/7bCXrC5gPTI3+/FXg9RjLDAGGRX/uADwJ/CTo2sPyamKGHYHMGtP3AvcG\nXXsYXk3Jr8ayFwEPAQ7IDrr2sLyaeAwOBHYEXWsYX03Mz4A3gYk15vUMuvawvJrz97jGOkXAd4Ou\nPQyvJh6DBcA6ICs6PQV4Lejaw/JqYoZfAlYAXaLT/wk8EGTdujirGczsCKAEyHHOlZmZARuBMc65\nkkbW+x4w1Dk3tW0qDa+WZGhmHYAHgT3OuZvbrtrwaU5+ZtYTmAuMBXYB3Z1zO9q65rBpaoZmNhBY\n4pzTmeoampHfmcAdzrnRAZUaWi38PdgHWAMMcM5tbrtqw6cZx+Bw4P+AE5xzm8zsBmCcc+6iQAoP\nkWZk+D0gzzl3dXT6ROAl51zXIOoGDRVorn7ARudcGYCr7Po/Avo3tIKZdQa+CTzdJhWGX5MzNLN0\nM1sCbKXyLPaP27LQkGrOMfgQcJtzbncb1pcImpNh5+iQlbfM7EfR/4lq75qa33HAFjP7i5m9Hf2K\n8ag2rjWsmv1vCTAVeLa9N61RTcrPObcU+DXwgZmtB24BNFylUlOPwTeBM82sV7S5nQx0MbOcNq22\nBjWucWRm6VQOE3jeOTcn6HoSjXPuoHOuAOgJvA9cE3BJCcPMvgl85JybH3QtCWwj0Nc5dxJwJvAF\n4LvBlpRQUoFxwH87504A/gnMCrakxBRtGK4CZgRdSyIxsyOpHC412FXeTP/XVP6bLE3knHsR+CWV\nw1SKgS3Rt8qCqkmNa/N8DPQ2s1So/mXSn8r/S6nFzNKo/AuyEbipLYsMuSZnWMU5dxB4BLisTSoM\nt6bmNxY438w+NLMPo/OWmdkJbVZpeDUpQ+fcgaqzW8657cDDVDav7V1Tj8GPgLedc+9Gpx8HToz+\nbmzvmvt78ItABpXNvzQ9v4uB5c65DdHpR4BToyeV2rsmH4POuenOuRHOuZHAS8B659yutiy2JjWu\nzRD9R+wtKgd4Q+VfivUxxhamAn8BtgNXOw0krtaMDAeYWafozynARGBZW9YaRk3Nzzk7bRJ+AAAF\nj0lEQVQ32TnXzzk30Dk3MDp7mHPu7barNpyacQweUdVkmVlHKs/cKL8m5kfl2MJcM+sbnT4HeM85\nF2mbSsOrGRlW+QbwqHOuvC3qC7tm5LeWykY1Kzo9AVgVPRnSrjXnGDSz3tH/dgLuAP63reqMRRdn\nNZOZHQ08ChxG5QUvVzrnlpvZHcAG59zvzGwy8ASVjVZVwAudc9cHUXPYNDHDc4GfRVdJofIv2C3O\nuW1B1BwmTckvxjoOXZxVrYnH4EVU/pIup/Jr7/nA95xzBwIqOzSaegya2VlU/iNnwE7geufc8mCq\nDpdmZNgN2ADkO+fWBlVv2DTx77ABdwEXAgeAvcB3nHNvBlR2qDTjGFxO5b/D6VR+c/LfQZ6QU+Mq\nIiIiIglBQwVEREREJCGocRURERGRhKDGVUREREQSghpXEREREUkIalxFREREJCGocRURERGRhKDG\nVUTaBTNbEn2tMLPyGtPNfgSkmT1iZk1+ipaZvRt9oMFVZpbX3P3V2Vaj2zCzU83sHTN728zO9NlX\njW0eZWZX15n3TzMb1BrbFxFpqtSgCxARaQvOuQIAMxsILKmajsXMUp1zDT6L2zl3ZVP3a2bHAtud\nc5vN7CpgM7CqqevHcKhtTAX+6Jz7RYxaGv1cjTgKuBr4fdUM59yXW7AdEREvOuMqIu2emZ1pZsvM\n7FEzWwKcZ2aXmdlr0TOXS8zsnBrLLzCzCdGfnzCz35rZfDNbZWazqx4VG3UBMMfMvg0UAPdFt/fl\n6Po/iO7nLTN71sz6RedfYGbLo8u+Y2YTGtpGjbr+g8pHN94Ufb+Lma03s5+b2WvAw2bW18xeNLM3\no2eC740+YQirNC26v6Vm9mr0cbe/A46LbnNOdNn1ZjY0+nOemc2LZrgk+uQ7zCzVzJyZ/TD6GT8w\nsyta+89PRNoPnXEVEak0FLjOObcAwMx6AE8455yZHQUsMrN+zrlIjHWHA2cAB4GFVDars6PvXQB8\n3Tm31symAD93zhVF93E5MBAodM5VmNmVwP3A+VQ+8niqc+51M0sBujjndtbdRk3OuZ9Fz/AWO+fu\nj+4DoDswMvpZMoFznXN7zCwVeIbKZvevVJ7NPRcY7ZzbZWY5QAT4dnSfIxrI7s/AdOfcDDM7Blho\nZsOBT6Pv73POnRJtdBeZ2ePOuYoG/yRERBqgxlVEpNKqqqY16ihgppn1BcqAHGAAUBJj3b875/YD\nmNnrwKDoz32Bjo08Y/4CKs+gvhVtMDsA5dH35gG/MbO/Ac8755Z6fLZHajxbPAX4hZmNBgw4IlrD\nX4EJwG+dc7sAnHPbo5+jwQ2bWXcqm/5Houu8b2bFwJjoNgFmRt97J3p29wg+b2pFRJpMjauISKU9\ndaZnATc7554CMLNdQEYD65bW+Lmcz3+3XgA83cg+DbjTOfdw3TecczdGz1COBZ4ws0ecc7869MeI\nqeZn+z6fn4EtNbP7aPhztZSrM91QPiIizaIxriIisWUDHwCY2VSgSwu2cQEwp8b0LqBbjemngOui\nZy0xs3Qzq7qI7Bjn3DvOud8ADwKFDWyjuboDG6NNa2/gqzXe+wdwrZl1jdbQPTpMocF9Ouc+A94B\nroiukxetdUGs5UVEfOj/ekVEYrsJeNrMtgMvAJ80Z2UzywYGOOeW1Jj9IPC/ZvZ94AfOuT9Gm9aX\nzcxR+Tv5IWBJdLmjqBxjuhe4poFt/LOZn+seYJaZvQNsAP5V471HgV7Aq2ZWtd9xwNtASXSd1c65\nC+ts8+vA78zsFqACuNI5tz46hlZEpNXY58OeRESktUQvohrhnLs56FpERJKFGlcRERERSQga4yoi\nIiIiCUGNq4iIiIgkBDWuIiIiIpIQ1LiKiIiISEJQ4yoiIiIiCUGNq4iIiIgkBDWuIiIiIpIQ/j/o\nJsTGj6T+NAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ee8de48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "para = {'C' : 1, 'kernel' : 'linear', 'gamma' : 'auto' } #parameters of the SVM\n",
    "\n",
    "performance_assesment_fraction(feature_dataset_reduced, labels, 5000, para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-Two-out evaluation\n",
    "\n",
    "note: this code could be optimized to be 2 times faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 0.0 %\n",
      "progress: 1.6666666666666667 %\n",
      "progress: 3.3333333333333335 %\n",
      "progress: 5.0 %\n",
      "progress: 6.666666666666667 %\n",
      "progress: 8.333333333333332 %\n",
      "progress: 10.0 %\n",
      "progress: 11.666666666666666 %\n",
      "progress: 13.333333333333334 %\n",
      "progress: 15.0 %\n",
      "progress: 16.666666666666664 %\n",
      "progress: 18.333333333333332 %\n",
      "progress: 20.0 %\n",
      "progress: 21.666666666666668 %\n",
      "progress: 23.333333333333332 %\n",
      "progress: 25.0 %\n",
      "progress: 26.666666666666668 %\n",
      "progress: 28.333333333333332 %\n",
      "progress: 30.0 %\n",
      "progress: 31.666666666666664 %\n",
      "progress: 33.33333333333333 %\n",
      "progress: 35.0 %\n",
      "progress: 36.666666666666664 %\n",
      "progress: 38.333333333333336 %\n",
      "progress: 40.0 %\n",
      "progress: 41.66666666666667 %\n",
      "progress: 43.333333333333336 %\n",
      "progress: 45.0 %\n",
      "progress: 46.666666666666664 %\n",
      "progress: 48.333333333333336 %\n",
      "progress: 50.0 %\n",
      "progress: 51.66666666666667 %\n",
      "progress: 53.333333333333336 %\n",
      "progress: 55.00000000000001 %\n",
      "progress: 56.666666666666664 %\n",
      "progress: 58.333333333333336 %\n",
      "progress: 60.0 %\n",
      "progress: 61.66666666666667 %\n",
      "progress: 63.33333333333333 %\n",
      "progress: 65.0 %\n",
      "progress: 66.66666666666666 %\n",
      "progress: 68.33333333333333 %\n",
      "progress: 70.0 %\n",
      "progress: 71.66666666666667 %\n",
      "progress: 73.33333333333333 %\n",
      "progress: 75.0 %\n",
      "progress: 76.66666666666667 %\n",
      "progress: 78.33333333333333 %\n",
      "progress: 80.0 %\n",
      "progress: 81.66666666666667 %\n",
      "progress: 83.33333333333334 %\n",
      "progress: 85.0 %\n",
      "progress: 86.66666666666667 %\n",
      "progress: 88.33333333333333 %\n",
      "progress: 90.0 %\n",
      "progress: 91.66666666666666 %\n",
      "progress: 93.33333333333333 %\n",
      "progress: 95.0 %\n",
      "progress: 96.66666666666667 %\n",
      "progress: 98.33333333333333 %\n",
      "mean of test accuracy\n",
      "0.9638418079096045\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "                    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                    tol=0.001, verbose=False)\n",
    "\n",
    "X = feature_dataset_reduced\n",
    "Y = labels\n",
    "\n",
    "svm_total_acc_test = []\n",
    "#performances assessment with leave three out\n",
    "n = X.shape[0]\n",
    "for i in range(n):\n",
    "    print(\"progress: \" + str(i/n*100) + \" %\")\n",
    "    for j in range(n):\n",
    "        if(j!=i):\n",
    "            i1 = [l for l in range(n)]\n",
    "            i1.remove(i)\n",
    "            i1.remove(j)\n",
    "            i2 = [i, j]\n",
    "                    \n",
    "            train=X[i1,:]\n",
    "            labels_train=Y[i1]\n",
    "\n",
    "            test= X[i2,:]\n",
    "            labels_test=Y[i2]\n",
    " \n",
    "            clf = svc      \n",
    "            #SVM fit on train data\n",
    "            clf.fit(train, labels_train)  \n",
    "\n",
    "            #Accuracy on test\n",
    "            predicted_labels_test = clf.predict(test)\n",
    "            SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "            svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"mean of test accuracy\")\n",
    "print(np.mean(svm_total_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-three-out Evaluation\n",
    "\n",
    "note: this code could be optimized to be 3! = 6 times faster, this will take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 0.0 %\n",
      "progress: 1.6666666666666667 %\n",
      "progress: 3.3333333333333335 %\n",
      "progress: 5.0 %\n",
      "progress: 6.666666666666667 %\n",
      "progress: 8.333333333333332 %\n",
      "progress: 10.0 %\n",
      "progress: 11.666666666666666 %\n",
      "progress: 13.333333333333334 %\n",
      "progress: 15.0 %\n",
      "progress: 16.666666666666664 %\n",
      "progress: 18.333333333333332 %\n",
      "progress: 20.0 %\n",
      "progress: 21.666666666666668 %\n",
      "progress: 23.333333333333332 %\n",
      "progress: 25.0 %\n",
      "progress: 26.666666666666668 %\n",
      "progress: 28.333333333333332 %\n",
      "progress: 30.0 %\n",
      "progress: 31.666666666666664 %\n",
      "progress: 33.33333333333333 %\n",
      "progress: 35.0 %\n",
      "progress: 36.666666666666664 %\n",
      "progress: 38.333333333333336 %\n",
      "progress: 40.0 %\n",
      "progress: 41.66666666666667 %\n",
      "progress: 43.333333333333336 %\n",
      "progress: 45.0 %\n",
      "progress: 46.666666666666664 %\n",
      "progress: 48.333333333333336 %\n",
      "progress: 50.0 %\n",
      "progress: 51.66666666666667 %\n",
      "progress: 53.333333333333336 %\n",
      "progress: 55.00000000000001 %\n",
      "progress: 56.666666666666664 %\n",
      "progress: 58.333333333333336 %\n",
      "progress: 60.0 %\n",
      "progress: 61.66666666666667 %\n",
      "progress: 63.33333333333333 %\n",
      "progress: 65.0 %\n",
      "progress: 66.66666666666666 %\n",
      "progress: 68.33333333333333 %\n",
      "progress: 70.0 %\n",
      "progress: 71.66666666666667 %\n",
      "progress: 73.33333333333333 %\n",
      "progress: 75.0 %\n",
      "progress: 76.66666666666667 %\n",
      "progress: 78.33333333333333 %\n",
      "progress: 80.0 %\n",
      "progress: 81.66666666666667 %\n",
      "progress: 83.33333333333334 %\n",
      "progress: 85.0 %\n",
      "progress: 86.66666666666667 %\n",
      "progress: 88.33333333333333 %\n",
      "progress: 90.0 %\n",
      "progress: 91.66666666666666 %\n",
      "progress: 93.33333333333333 %\n",
      "progress: 95.0 %\n",
      "progress: 96.66666666666667 %\n",
      "progress: 98.33333333333333 %\n",
      "mean of test accuracy\n",
      "0.9610169491525423\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "                    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                    tol=0.001, verbose=False)\n",
    "\n",
    "X = feature_dataset_reduced\n",
    "Y = labels\n",
    "\n",
    "svm_total_acc_test = []\n",
    "#performances assessment with leave three out\n",
    "n = X.shape[0]\n",
    "for i in range(n):\n",
    "    print(\"progress: \" + str(i/n*100) + \" %\")\n",
    "    for j in range(n):\n",
    "        if(j!=i):\n",
    "            for k in range(n):\n",
    "                if(k!=j and k!=i):\n",
    "            #SVM classifier definition\n",
    "                    i1 = [l for l in range(n)]\n",
    "                    i1.remove(i)\n",
    "                    i1.remove(j)\n",
    "                    i1.remove(k)\n",
    "                    i2 = [i, j, k]\n",
    "                    \n",
    "                    train=X[i1,:]\n",
    "                    labels_train=Y[i1]\n",
    "\n",
    "                    test= X[i2,:]\n",
    "                    labels_test=Y[i2]\n",
    "                #print(i1)\n",
    "                #print(i2)\n",
    "                    clf = svc      \n",
    "                #SVM fit on train data\n",
    "                    clf.fit(train, labels_train)  \n",
    "\n",
    "                #Accuracy on test\n",
    "                    predicted_labels_test = clf.predict(test)\n",
    "                    SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "                    svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"mean of test accuracy\")\n",
    "print(np.mean(svm_total_acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
