{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model, neighbors, datasets\n",
    "from sklearn import svm\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import LeavePOut\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities functions for working with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_matrix_two_blocks(y, percentage1, percentage2, seed):\n",
    "    \"\"\"Build k indices for k-fold.\"\"\"\n",
    "    if(percentage1+percentage2==1):\n",
    "        num_row = len(y)\n",
    "        #print(num_row)\n",
    "        interval_1 = int(percentage1*num_row);\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        indices = np.random.permutation(num_row);\n",
    "        first_indices = indices[0:interval_1];\n",
    "        second_indices = indices[interval_1:num_row];\n",
    "        return [np.array(first_indices),np.array(second_indices)]\n",
    "    else:\n",
    "        print('>>>>>>>>>>>ERROR:Not valid splitting percentage')\n",
    "        \n",
    "        \n",
    "##\n",
    "## This function reutrn a list of matrices. Each matrix correspond to a question instance in which each row is a channel, and in the coloumn it develop the signal in time\n",
    "## The function also manage to standardize the time length\n",
    "def channels_to_vector(channels): \n",
    "    time_instances=[];\n",
    "    dim=channels.shape;\n",
    "    #find the length min of the signal in the specified temporal instance\n",
    "    length_min=len(channels[0,1]);\n",
    "    for i in range (0,dim[1]):\n",
    "        single_measurement=channels[0,i];\n",
    "        single_length=single_measurement.shape[0]\n",
    "        if(single_length<length_min):\n",
    "                length_min=single_length;\n",
    "    #export the signals\n",
    "    for i in range (0,dim[1]):\n",
    "        single_measurement=channels[0,i];\n",
    "        dim1=single_measurement.shape;\n",
    "        time_instance=[];\n",
    "        for j  in range (0,dim1[1]):\n",
    "            if(len(single_measurement[:,j])>length_min):\n",
    "                single_signal=single_measurement[:,j][0:length_min]\n",
    "            else:\n",
    "                single_signal=single_measurement[:,j]\n",
    "            #put in a list \n",
    "            time_instance.append(np.asarray(single_signal).reshape(len(single_signal),1).T);\n",
    "       # create the matrix of the signals per a single time instance \n",
    "        time_instance=np.concatenate(time_instance);\n",
    "        time_instances.append(time_instance);   \n",
    "    return time_instances;\n",
    "\n",
    "\n",
    "##\n",
    "# Create the train data matrix\n",
    "##\n",
    "## usage\n",
    "def get_feature_matrix_and_labels(channel_structure,label,features_extracted,connectivity_feature):\n",
    "    list_train=[]\n",
    "    list_labels=[]\n",
    "    cont=0;\n",
    "    index_connectivity=0;\n",
    "    list_row=[]\n",
    "    \n",
    "    for time_instance in channel_structure:\n",
    "        dim1=time_instance.shape\n",
    "        #indipendent_components=extract_ICs(time_instance,n_ICA_components);\n",
    "        for j  in range (0,dim1[0]):\n",
    "           \n",
    "            features=features_extracted[cont,:];\n",
    "            list_row.append(features);\n",
    "            cont=cont+1;\n",
    "        \"\"\"feature_dictionary[\"fft_max_frequencies\"]=0;\n",
    "        for single_component in indipendent_components:\n",
    "            features=feature_extraction(single_component,feature_dictionary,features_extracted)\n",
    "            list_row.append(features);\"\"\"\n",
    "        list_row.append(connectivity_feature[index_connectivity,:]);\n",
    "        index_connectivity=index_connectivity+1;\n",
    "        labels=get_labels(1,label);\n",
    "        feature_row=np.concatenate(list_row);\n",
    "        list_train.append(feature_row.reshape(len(feature_row),1).T)\n",
    "        list_labels.append(labels);\n",
    "        list_row=[]\n",
    "        \n",
    "    train_TX=np.concatenate(list_train)\n",
    "    labels=np.concatenate(list_labels,axis=0)\n",
    "    \n",
    "    return train_TX,labels.T.reshape(labels.size)\n",
    "\n",
    "\n",
    "### Description\n",
    "def get_labels(number, string):\n",
    "    if(string==\"No\"):\n",
    "        return np.zeros(number)    \n",
    "    if(string==\"Yes\"):\n",
    "        return np.ones(number)\n",
    "    \n",
    "## description\n",
    "def select_features(weights,matrix,th):\n",
    "    cont=0;\n",
    "    i=0;\n",
    "    while(cont<len(weights)):\n",
    "        if(weights[cont]<th):\n",
    "\n",
    "            mask = np.ones(matrix.shape[1], dtype=bool)\n",
    "            mask[i] = False\n",
    "            matrix=matrix[:,mask]\n",
    "        else:\n",
    "            i=i+1;\n",
    "        cont=cont+1;\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def get_accuracy(predicted_labels, true_labels):\n",
    "     if (predicted_labels.size == true_labels.size):\n",
    "        return  np.sum(predicted_labels ==  true_labels )/len( true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG feature loading\n",
    "\n",
    "Import data from previous analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset have shape:\n",
      "(60, 386)\n"
     ]
    }
   ],
   "source": [
    "#Import data from mat files\n",
    "yes_EEG_contents = sio.loadmat('EEGyes.mat')\n",
    "no_EEG_contents = sio.loadmat('EEGno.mat')\n",
    "\n",
    "channels_no_EEG=no_EEG_contents[\"EEGno\"]\n",
    "channels_yes_EEG=yes_EEG_contents[\"EEGyes\"]\n",
    "\n",
    "#Features Loading\n",
    "features_extracted_yes   = sio.loadmat('FeaturesYes.mat')['FeaturesYes']\n",
    "features_extracted_no    = sio.loadmat('FeaturesNO.mat')['FeaturesNo']\n",
    "connectivity_feature_yes = sio.loadmat('ConnectivityFeaturesYes.mat')['ConnectivityFeaturesYes']\n",
    "connectivity_feature_no  = sio.loadmat('ConnectivityFeaturesNo.mat')['ConnectivityFeaturesNo']\n",
    "\n",
    "channels_structure_yes_EEG = channels_to_vector(channels_yes_EEG)\n",
    "channels_structure_no_EEG  = channels_to_vector(channels_no_EEG)\n",
    "\n",
    "##Structuring of the data:\n",
    "#the code below create the train matrix with respect to the signal given in \"channel_structure\" but using the features contained in \"features_extracted*\" and in \"connettivity_feature*\".\n",
    "feature_dataset_yes_EEG, EEG_yes_labels = get_feature_matrix_and_labels(channels_structure_yes_EEG,\"Yes\",features_extracted_yes,connectivity_feature_yes);\n",
    "\n",
    "feature_dataset_no_EEG, EEG_no_labels = get_feature_matrix_and_labels(channels_structure_no_EEG,\"No\",features_extracted_no,connectivity_feature_no);\n",
    "\n",
    "#Merge the labeled data\n",
    "feature_dataset_full = np.concatenate((feature_dataset_yes_EEG, feature_dataset_no_EEG), axis=0 )\n",
    "labels = np.concatenate((EEG_yes_labels,EEG_no_labels), axis=0)\n",
    "\n",
    "\n",
    "print(\"The dataset have shape:\")\n",
    "print(feature_dataset_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(predicted_labels, true_labels):\n",
    "     if (predicted_labels.size == true_labels.size):\n",
    "        return  np.sum(predicted_labels ==  true_labels)/len(predicted_labels)\n",
    "    \n",
    "def get_accuracy_std(predicted_labels, true_labels):\n",
    "     if (predicted_labels.size == true_labels.size):\n",
    "        return  np.sum(predicted_labels ==  true_labels)\n",
    "    \n",
    "def leave_one_out(X, Y, classifier):\n",
    "    svm_total_acc_test = []\n",
    "    for i in range(X.shape[0]):\n",
    "#SVM classifier definition\n",
    "        i1 = [j for j in range(X.shape[0])]\n",
    "        i1.remove(i)\n",
    "        i2 = i\n",
    "        train=X[i1,:]\n",
    "        labels_train=Y[i1]\n",
    "\n",
    "        test= X[i2,:]\n",
    "        labels_test=Y[i2]\n",
    "        clf_temp = classifier\n",
    "        clf_temp.fit(train, labels_train)  \n",
    "\n",
    "        #Accuracy on test\n",
    "        predicted_labels_test = clf_temp.predict(test)\n",
    "        SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "        svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "    return(np.mean(svm_total_acc_test))\n",
    "\n",
    "\n",
    "def leave_one_out_std(X, Y, classifier):\n",
    "    svm_total_acc_test = []\n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "#SVM classifier definition\n",
    "        i1 = [j for j in range(X.shape[0])]\n",
    "        i1.remove(i)\n",
    "        i2 = i\n",
    "        train=X[i1,:]\n",
    "        labels_train=Y[i1]\n",
    "\n",
    "        test = X[i2,:]\n",
    "        labels_test=Y[i2]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train)\n",
    "        train = scaler.transform(train)\n",
    "        test = scaler.transform(test)\n",
    "        \n",
    "        \n",
    "        clf_temp = classifier\n",
    "        clf_temp.fit(train, labels_train)  \n",
    "        \n",
    "        #Accuracy on test\n",
    "        predicted_labels_test = clf_temp.predict(test)\n",
    "        SVM_accuracy_test = get_accuracy_std(predicted_labels_test, labels_test)\n",
    "        svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "    return(np.mean(svm_total_acc_test))\n",
    "\n",
    "\n",
    "def leave_two_out(X, Y, classifier):\n",
    "    svm_total_acc_test = []\n",
    "    for i in range(X.shape[0]):\n",
    "        for l in range(X.shape[0]):\n",
    "            if(i!=l):\n",
    "                #scaler = StandardScaler()\n",
    "        #SVM classifier definition\n",
    "                i1 = [j for j in range(X.shape[0])]\n",
    "                i1.remove(i)\n",
    "                i2 = i\n",
    "                train=X[i1,:]\n",
    "                labels_train=Y[i1]\n",
    "\n",
    "                test = X[i2,:]\n",
    "                labels_test=Y[i2]\n",
    "\n",
    "\n",
    "                #scaler.fit(train)\n",
    "                #train = scaler.transform(train)\n",
    "                #test = scaler.transform(test)\n",
    "\n",
    "\n",
    "                clf_temp = classifier\n",
    "                clf_temp.fit(train, labels_train)  \n",
    "\n",
    "                #Accuracy on test\n",
    "                predicted_labels_test = clf_temp.predict(test)\n",
    "                SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "                svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "    return(np.mean(svm_total_acc_test))\n",
    "\n",
    "def leave_two_out_sci(X, Y, classifier):\n",
    "    svm_total_acc_test = []\n",
    "    lpo = LeavePOut(2)\n",
    "    \n",
    "    for train_index, test_index in lpo.split(X):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "                #scaler = StandardScaler()\n",
    "        \n",
    "        clf_temp = classifier\n",
    "        clf_temp.fit(X_train, y_train)  \n",
    "\n",
    "                #Accuracy on test\n",
    "        predicted_labels_test = clf_temp.predict(X_test)\n",
    "        SVM_accuracy_test = get_accuracy(predicted_labels_test, y_test)\n",
    "        svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "    return(np.mean(svm_total_acc_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the best number of features\n",
    "\n",
    "Only the top-k features that have the best ANOVA F-test Score are retained.\n",
    "An hard-margin (C=1) SVM linear classifier is trained and its performances assessed with a full search leave-one-out\n",
    "\n",
    "Might require some computational time (spoiler: best k seems to be 21)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 0.33333333333333337 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-51e54bb3a5ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             tol=0.001, verbose=False)\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mperf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleave_two_out_sci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtot_perf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-418f68b1134a>\u001b[0m in \u001b[0;36mleave_two_out_sci\u001b[0;34m(X, Y, classifier)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mclf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mclf_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;31m#Accuracy on test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tot_perf = []\n",
    "end_feat = 100\n",
    "for k in range(1,end_feat):\n",
    "    print('progress: ' + str(k/300*100) + ' %')\n",
    "    reducer = SelectKBest(f_classif, k)\n",
    "    \n",
    "    scaler2= StandardScaler()\n",
    "    feat_std = scaler2.fit_transform(feature_dataset_full)\n",
    "    feature_dataset_reduced = reducer.fit_transform(feat_std, labels)\n",
    "    svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "            decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "            max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "            tol=0.001, verbose=False)\n",
    "    perf_temp = leave_two_out_sci(feat_std, labels, svc)\n",
    "    tot_perf.append(perf_temp)\n",
    "\n",
    "best_k = np.argmax(tot_perf)+1\n",
    "print(\"smallest k that gives best Leave-one-out results:\")\n",
    "print(best_k)\n",
    "print()\n",
    "print(\"wich have lead to the top performance:\")\n",
    "print(np.max(tot_perf))\n",
    "\n",
    "\n",
    "#What are those features?\n",
    "reducer = SelectKBest(f_classif, best_k)\n",
    "feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "boolean_vec = reducer.get_support()\n",
    "idx =[]\n",
    "for i in range(len(boolean_vec)): \n",
    "    if boolean_vec[i] == True: idx.append(i)\n",
    "print()\n",
    "print(\"index of features retained:\")\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'argmax'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-134e99a13b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_perf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"smallest k that gives best Leave-one-out results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wich have lead to the top performance:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \"\"\"\n\u001b[0;32m-> 1004\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "best_k = np.argmax(tot_perf)+1\n",
    "print(\"smallest k that gives best Leave-one-out results:\")\n",
    "print(best_k)\n",
    "print()\n",
    "print(\"wich have lead to the top performance:\")\n",
    "print(np.max(tot_perf))\n",
    "\n",
    "\n",
    "#What are those features?\n",
    "reducer = SelectKBest(f_classif, best_k)\n",
    "feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "boolean_vec = reducer.get_support()\n",
    "idx =[]\n",
    "for i in range(len(boolean_vec)): \n",
    "    if boolean_vec[i] == True: idx.append(i)\n",
    "print()\n",
    "print(\"index of features retained:\")\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9731638418079096, 0.9731638418079096, 0.9731638418079096, 0.9731638418079096, 0.9731638418079096, 0.9731638418079096, 0.9731638418079096, 0.9731638418079096, 0.9731638418079096, 0.9731638418079096, 0.9731638418079096]\n"
     ]
    }
   ],
   "source": [
    "print(tot_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of performances with varying size train/test\n",
    "\n",
    "Definition of utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_SVM_experiments(X, Y, clf_parameters, fraction_train_test, num_experiments):\n",
    "    \n",
    "    seed=range(num_experiments)\n",
    "    svm_total_acc_test  = []\n",
    "    svm_total_acc_train = [] \n",
    "    dataset_length=X.shape[0];\n",
    "    \n",
    "    for single_seed in seed:\n",
    "        [i1,i2]=split_matrix_two_blocks(X, fraction_train_test, 1-fraction_train_test,single_seed)\n",
    "        \n",
    "        train =X[i1,:]\n",
    "        labels_train=Y[i1]\n",
    "        \n",
    "        test = X[i2,:]\n",
    "        labels_test=Y[i2]\n",
    "        \n",
    "        #SVM classificator definition\n",
    "        C_best = clf_parameters['C']\n",
    "        gamma_best = clf_parameters['gamma']\n",
    "        kernel_best = clf_parameters['kernel']\n",
    "        \n",
    "        clf = svm.SVC(C = C_best, kernel = kernel_best, gamma = gamma_best, random_state = single_seed)\n",
    "        #SVM fit on train data\n",
    "        clf.fit(train, labels_train)  \n",
    "        #print(test.shape)\n",
    "        #print(labels_test.shape)\n",
    "        \n",
    "        #Accuracy on test\n",
    "        predicted_labels_test = clf.predict(test)\n",
    "        SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "        svm_total_acc_test.append(SVM_accuracy_test)\n",
    "        \n",
    "        \n",
    "        #Accuracy on train\n",
    "        predicted_labels_train = clf.predict(train)\n",
    "        SVM_accuracy_train = get_accuracy(predicted_labels_train, labels_train)\n",
    "        svm_total_acc_train.append(SVM_accuracy_train)\n",
    "        #print(\"Accuracy: \"+ str(SVM_accuracy) + \"; iteration  \" + str(single_seed) )\n",
    "    return svm_total_acc_test, svm_total_acc_train\n",
    "\n",
    "def performance_assesment_fraction(X, Y, num_experiment, clf_parameters):\n",
    "    fracs = np.linspace(0.2,0.9,25)\n",
    "    accuracy_test_mean  = []\n",
    "    accuracy_test_std   = []\n",
    "    accuracy_train_mean = []\n",
    "    accuracy_train_std  = []\n",
    "\n",
    "    for frac_tr_te in fracs:\n",
    "        print(\"Evaluation progress: \" + str(int((frac_tr_te-fracs[0])/(fracs[-1]-fracs[0])*100)) + \" %\")\n",
    "        acc_test, acc_train = classification_SVM_experiments(X, Y, clf_parameters, frac_tr_te, num_experiment)\n",
    "        #saving of metrics of interest\n",
    "        accuracy_test_mean.append(np.mean(acc_test))\n",
    "        accuracy_test_std.append(np.std(acc_test))\n",
    "        accuracy_train_mean.append(np.mean(acc_train))\n",
    "        accuracy_train_std.append(np.std(acc_train))\n",
    "\n",
    "    #plot the figure\n",
    "    plt.figure(figsize=(10, 7), dpi=80)\n",
    "    plt.errorbar(fracs, accuracy_test_mean, yerr=accuracy_test_std, label=\"Error bars plot\", fmt=\"s-\",  linewidth=3)\n",
    "    plt.errorbar(fracs, accuracy_train_mean, yerr=accuracy_train_std, label=\"Error bars plot\", fmt=\"s-\",  linewidth=3)\n",
    "    plt.grid(b=True, which='major', color='k', linestyle='--', alpha = 0.4)\n",
    "    plt.minorticks_on()\n",
    "    plt.title('SVM perfomances over different train/test dataset of reduced features')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Train/test fraction')\n",
    "\n",
    "    plt.legend(['Test Accuracy', 'Train Accuracy'], loc=4)\n",
    "    plt.savefig('train_test_acc_fine_tuned2.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual calling of the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataset_full[:,292:293].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index of features retained:\n",
      "[11, 14, 18, 22, 39, 45, 46, 58, 66, 67, 70, 71, 74, 82, 93, 106, 110, 115, 118, 119, 120, 122, 128, 136, 139, 143, 158, 161, 165, 169, 173, 192, 193, 201, 213, 214, 217, 218, 228, 236, 240, 244, 248, 256, 260, 262, 263, 272, 276, 284, 287, 288, 291, 292, 304, 312, 316, 320, 340, 354, 358]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "reducer = SelectKBest(f_classif, 61)\n",
    "feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "boolean_vec = reducer.get_support()\n",
    "idx =[]\n",
    "for i in range(len(boolean_vec)): \n",
    "    if boolean_vec[i] == True: idx.append(i)\n",
    "print()\n",
    "print(\"index of features retained:\")\n",
    "print(idx)\n",
    "\n",
    "para = {'C' : 1, 'kernel' : 'linear', 'gamma' : 'auto' } #parameters of the SVM\n",
    "\n",
    "#performance_assesment_fraction(feature_dataset_full[:,292:293], labels, 500, para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-Two-out evaluation\n",
    "\n",
    "note: this code could be optimized to be 2 times faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "                    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                    tol=0.001, verbose=False)\n",
    "\n",
    "X = feature_dataset_reduced\n",
    "Y = labels\n",
    "\n",
    "svm_total_acc_test = []\n",
    "#performances assessment with leave three out\n",
    "n = X.shape[0]\n",
    "for i in range(n):\n",
    "    print(\"progress: \" + str(i/n*100) + \" %\")\n",
    "    for j in range(n):\n",
    "        if(j!=i):\n",
    "            i1 = [l for l in range(n)]\n",
    "            i1.remove(i)\n",
    "            i1.remove(j)\n",
    "            i2 = [i, j]\n",
    "                    \n",
    "            train=X[i1,:]\n",
    "            labels_train=Y[i1]\n",
    "\n",
    "            test= X[i2,:]\n",
    "            labels_test=Y[i2]\n",
    " \n",
    "            clf = svc      \n",
    "            #SVM fit on train data\n",
    "            clf.fit(train, labels_train)  \n",
    "\n",
    "            #Accuracy on test\n",
    "            predicted_labels_test = clf.predict(test)\n",
    "            SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "            svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"mean of test accuracy\")\n",
    "print(np.mean(svm_total_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-three-out Evaluation\n",
    "\n",
    "note: this code could be optimized to be 3! = 6 times faster, this will take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "                    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                    tol=0.001, verbose=False)\n",
    "\n",
    "X = feature_dataset_reduced\n",
    "Y = labels\n",
    "\n",
    "svm_total_acc_test = []\n",
    "#performances assessment with leave three out\n",
    "n = X.shape[0]\n",
    "for i in range(n):\n",
    "    print(\"progress: \" + str(i/n*100) + \" %\")\n",
    "    for j in range(n):\n",
    "        if(j!=i):\n",
    "            for k in range(n):\n",
    "                if(k!=j and k!=i):\n",
    "            #SVM classifier definition\n",
    "                    i1 = [l for l in range(n)]\n",
    "                    i1.remove(i)\n",
    "                    i1.remove(j)\n",
    "                    i1.remove(k)\n",
    "                    i2 = [i, j, k]\n",
    "                    \n",
    "                    train=X[i1,:]\n",
    "                    labels_train=Y[i1]\n",
    "\n",
    "                    test= X[i2,:]\n",
    "                    labels_test=Y[i2]\n",
    "                #print(i1)\n",
    "                #print(i2)\n",
    "                    clf = svc      \n",
    "                #SVM fit on train data\n",
    "                    clf.fit(train, labels_train)  \n",
    "\n",
    "                #Accuracy on test\n",
    "                    predicted_labels_test = clf.predict(test)\n",
    "                    SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "                    svm_total_acc_test.append(SVM_accuracy_test)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"mean of test accuracy\")\n",
    "print(np.mean(svm_total_acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def classification_SVM_experiments_std(X, Y, clf_parameters, fraction_train_test, num_experiments):\n",
    "    \n",
    "    seed=range(num_experiments)\n",
    "    svm_total_acc_test  = []\n",
    "    svm_total_acc_train = [] \n",
    "    dataset_length=X.shape[0];\n",
    "    \n",
    "    for single_seed in seed:\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        [i1,i2]=split_matrix_two_blocks(X, fraction_train_test, 1-fraction_train_test,single_seed)\n",
    "        \n",
    "        \n",
    "        train =X[i1,:]\n",
    "        labels_train=Y[i1]\n",
    "        \n",
    "        test = X[i2,:]\n",
    "        labels_test=Y[i2]\n",
    "        \n",
    "        scaler.fit(train)\n",
    "        train = scaler.transform(train)\n",
    "        test = scaler.transform(test)\n",
    "        \n",
    "        #SVM classificator definition\n",
    "        C_best = clf_parameters['C']\n",
    "        gamma_best = clf_parameters['gamma']\n",
    "        kernel_best = clf_parameters['kernel']\n",
    "        \n",
    "        clf = svm.SVC(C = C_best, kernel = kernel_best, gamma = gamma_best, random_state = single_seed)\n",
    "        #SVM fit on train data\n",
    "        clf.fit(train, labels_train)  \n",
    "        #print(test.shape)\n",
    "        #print(labels_test.shape)\n",
    "        \n",
    "        #Accuracy on test\n",
    "        predicted_labels_test = clf.predict(test)\n",
    "        SVM_accuracy_test = get_accuracy(predicted_labels_test, labels_test)\n",
    "        svm_total_acc_test.append(SVM_accuracy_test)\n",
    "        \n",
    "        \n",
    "        #Accuracy on train\n",
    "        predicted_labels_train = clf.predict(train)\n",
    "        SVM_accuracy_train = get_accuracy(predicted_labels_train, labels_train)\n",
    "        svm_total_acc_train.append(SVM_accuracy_train)\n",
    "        #print(\"Accuracy: \"+ str(SVM_accuracy) + \"; iteration  \" + str(single_seed) )\n",
    "    return svm_total_acc_test, svm_total_acc_train\n",
    "\n",
    "def performance_assesment_fraction_std(X, Y, num_experiment, clf_parameters):\n",
    "    fracs = np.linspace(0.2,0.9,60)\n",
    "    accuracy_test_mean  = []\n",
    "    accuracy_test_std   = []\n",
    "    accuracy_train_mean = []\n",
    "    accuracy_train_std  = []\n",
    "\n",
    "    for frac_tr_te in fracs:\n",
    "        print(\"Evaluation progress: \" + str(int((frac_tr_te-fracs[0])/(fracs[-1]-fracs[0])*100)) + \" %\")\n",
    "        acc_test, acc_train = classification_SVM_experiments_std(X, Y, clf_parameters, frac_tr_te, num_experiment)\n",
    "        #saving of metrics of interest\n",
    "        accuracy_test_mean.append(np.mean(acc_test))\n",
    "        accuracy_test_std.append(np.std(acc_test))\n",
    "        accuracy_train_mean.append(np.mean(acc_train))\n",
    "        accuracy_train_std.append(np.std(acc_train))\n",
    "\n",
    "    #plot the figure\n",
    "    plt.figure(figsize=(10, 7), dpi=80)\n",
    "    plt.errorbar(np.floor(fracs*60), accuracy_test_mean, yerr=accuracy_test_std, label=\"Error bars plot\", fmt=\"s-\",  linewidth=3)\n",
    "    plt.errorbar(np.floor(fracs*60), accuracy_train_mean, yerr=accuracy_train_std, label=\"Error bars plot\", fmt=\"s-\",  linewidth=3)\n",
    "    plt.grid(b=True, which='major', color='k', linestyle='--', alpha = 0.4)\n",
    "    plt.minorticks_on()\n",
    "    plt.title('SVM perfomances over different train/test dataset of reduced features')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Train instances considered')\n",
    "\n",
    "    plt.legend(['Test Accuracy', 'Train Accuracy'], loc=4)\n",
    "    plt.savefig('train_test_acc_fine_tuned2.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation progress: 0 %\n",
      "Evaluation progress: 1 %\n",
      "Evaluation progress: 3 %\n",
      "Evaluation progress: 5 %\n",
      "Evaluation progress: 6 %\n",
      "Evaluation progress: 8 %\n",
      "Evaluation progress: 10 %\n",
      "Evaluation progress: 11 %\n",
      "Evaluation progress: 13 %\n",
      "Evaluation progress: 15 %\n",
      "Evaluation progress: 16 %\n",
      "Evaluation progress: 18 %\n",
      "Evaluation progress: 20 %\n",
      "Evaluation progress: 22 %\n",
      "Evaluation progress: 23 %\n",
      "Evaluation progress: 25 %\n",
      "Evaluation progress: 27 %\n",
      "Evaluation progress: 28 %\n",
      "Evaluation progress: 30 %\n",
      "Evaluation progress: 32 %\n",
      "Evaluation progress: 33 %\n",
      "Evaluation progress: 35 %\n",
      "Evaluation progress: 37 %\n",
      "Evaluation progress: 38 %\n",
      "Evaluation progress: 40 %\n",
      "Evaluation progress: 42 %\n",
      "Evaluation progress: 44 %\n",
      "Evaluation progress: 45 %\n",
      "Evaluation progress: 47 %\n",
      "Evaluation progress: 49 %\n",
      "Evaluation progress: 50 %\n",
      "Evaluation progress: 52 %\n",
      "Evaluation progress: 54 %\n",
      "Evaluation progress: 55 %\n",
      "Evaluation progress: 57 %\n",
      "Evaluation progress: 59 %\n",
      "Evaluation progress: 61 %\n",
      "Evaluation progress: 62 %\n",
      "Evaluation progress: 64 %\n",
      "Evaluation progress: 66 %\n",
      "Evaluation progress: 67 %\n",
      "Evaluation progress: 69 %\n",
      "Evaluation progress: 71 %\n",
      "Evaluation progress: 72 %\n",
      "Evaluation progress: 74 %\n",
      "Evaluation progress: 76 %\n",
      "Evaluation progress: 77 %\n",
      "Evaluation progress: 79 %\n",
      "Evaluation progress: 81 %\n",
      "Evaluation progress: 83 %\n",
      "Evaluation progress: 84 %\n",
      "Evaluation progress: 86 %\n",
      "Evaluation progress: 88 %\n",
      "Evaluation progress: 89 %\n",
      "Evaluation progress: 91 %\n",
      "Evaluation progress: 93 %\n",
      "Evaluation progress: 94 %\n",
      "Evaluation progress: 96 %\n",
      "Evaluation progress: 98 %\n",
      "Evaluation progress: 100 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAAHnCAYAAACmDqUgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116fcceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "para = {'C' : 1, 'kernel' : 'linear', 'gamma' : 'auto' } #parameters of the SVM\n",
    "\n",
    "reducer = SelectKBest(f_classif, 61)\n",
    "feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "\n",
    "performance_assesment_fraction_std(feature_dataset_reduced, labels, 900, para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k = 21\n",
    "reducer = SelectKBest(f_classif, best_k)\n",
    "feature_dataset_reduced = reducer.fit_transform(feature_dataset_full, labels)\n",
    "scaler = StandardScaler()\n",
    "feat_std = scaler.fit_transform(feature_dataset_reduced)\n",
    "svc = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "                    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                    tol=0.001, verbose=False)\n",
    "svc.fit(feat_std, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22346332  0.64705714  0.26791996  0.7501621  -0.60590376 -0.53728717\n",
      " -0.62941718 -0.1901157   0.24270315 -0.63605794 -0.24940478 -0.11453758\n",
      " -0.29825925 -0.24942546 -0.19540089  0.07638783  0.10676724  0.13472659\n",
      "  0.48237392 -0.76131727  0.30088166]\n"
     ]
    }
   ],
   "source": [
    "coef = svc.coef_\n",
    "print(coef[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11be5f0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.bar(range(len(coef[0])),coef[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
