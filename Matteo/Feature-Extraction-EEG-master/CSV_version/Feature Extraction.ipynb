{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "from matplotlib import pyplot as plt\n",
    "from nitime import utils\n",
    "from nitime import algorithms as alg\n",
    "from nitime.timeseries import TimeSeries\n",
    "from nitime.viz import plot_tseries\n",
    "import csv\n",
    "import pywt\n",
    "import scipy.stats as sp\n",
    "from spectrum import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Names of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['Activity','Mobility','Complexity','Kurtosis','2nd Difference Mean','2nd Difference Max','Coeffiecient of Variation','Skewness','1st Difference Mean','1st Difference Max',\n",
    "          'Wavelet Approximate Mean','Wavelet Approximate Std Deviation','Wavelet Detailed Mean','Wavelet Detailed Std Deviation','Wavelet Approximate Energy','Wavelet Detailed Energy',\n",
    "          'Wavelet Approximate Entropy','Wavelet Detailed Entropy','Variance','Mean of Vertex to Vertex Slope','FFT Delta MaxPower','FFT Theta MaxPower','FFT Alpha MaxPower','FFT Beta MaxPower',\n",
    "          'Autro Regressive Mode Order 3 Coefficients for each channel ->']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hjorth Parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hjorth(input):                                             # function for hjorth \n",
    "    realinput = input\n",
    "    hjorth_activity = np.zeros(len(realinput))\n",
    "    hjorth_mobility = np.zeros(len(realinput))\n",
    "    hjorth_diffmobility = np.zeros(len(realinput))\n",
    "    hjorth_complexity = np.zeros(len(realinput))\n",
    "    diff_input = np.diff(realinput)\n",
    "    diff_diffinput = np.diff(diff_input)\n",
    "    k = 0\n",
    "    for j in realinput:\n",
    "        hjorth_activity[k] = np.var(j)\n",
    "        hjorth_mobility[k] = np.sqrt(np.var(diff_input[k])/hjorth_activity[k])\n",
    "        hjorth_diffmobility[k] = np.sqrt(np.var(diff_diffinput[k])/np.var(diff_input[k]))\n",
    "        hjorth_complexity[k] = hjorth_diffmobility[k]/hjorth_mobility[k]\n",
    "        k = k+1\n",
    "    return np.sum(hjorth_activity)/14, np.sum(hjorth_mobility)/14, np.sum(hjorth_complexity)/14                       #returning hjorth activity, hjorth mobility , hjorth complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurtosis , 2nd Diff Mean, 2nd Diff Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_kurtosis(a):\n",
    "    b = a # Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    k = 0; # For counting the current row no.\n",
    "    for i in b:\n",
    "        mean_i = np.mean(i) # Saving the mean of array i\n",
    "        std_i = np.std(i) # Saving the standard deviation of array i\n",
    "        t = 0.0\n",
    "        for j in i:\n",
    "            t += (pow((j-mean_i)/std_i,4)-3)\n",
    "        kurtosis_i = t/len(i) # Formula: (1/N)*(summation(x_i-mean)/standard_deviation)^4-3\n",
    "        output[k] = kurtosis_i # Saving the kurtosis in the array created\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/14\n",
    "\n",
    "##----------------------------------------- End Kurtosis Function ----------------------------##\n",
    "\n",
    "\n",
    "##------------------------------------- Begin 2ndDiffMean(Absolute difference) Function ------##\n",
    "##-------------------------- [ Input: 2D array (row: Channels, column: Data)] --------------- ##\n",
    "##-------------------  -- [ Output: 1D array (2ndDiffMean values for each channel)] ----------##\n",
    "\n",
    "def secDiffMean(a):\n",
    "    b = a # Extracting the data of the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
    "    k = 0; # For counting the current row no.\n",
    "    for i in b:\n",
    "    \tt = 0.0\n",
    "        for j in range(len(i)-1):\n",
    "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "        for j in range(len(i)-2):\n",
    "            t += abs(temp1[j+1]-temp1[j]) # Summing the 2nd Diffs\n",
    "        output[k] = t/(len(i)-2) # Calculating the mean of the 2nd Diffs\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/14\n",
    "\n",
    "##------------------------------------- End 2ndDiffMean Function----- -------------------------##\n",
    "\n",
    "\n",
    "##------------------------------------- Begin 2ndDiffMax Function(Absolute difference) --------##\n",
    "##-------------------------- [ Input: 2D array (row: Channels, column: Data)] -----------------##\n",
    "##--------------------- [ Output: 1D array (2ndDiffMax values for each channel)] --------------##\n",
    "\n",
    "def secDiffMax(a):\n",
    "    b = a # Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
    "    k = 0; # For counting the current row no.\n",
    "    t = 0.0\n",
    "    for i in b:\n",
    "        for j in range(len(i)-1):\n",
    "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "        t = temp1[1] - temp1[0]\n",
    "        for j in range(len(i)-2):\n",
    "            if abs(temp1[j+1]-temp1[j]) > t :\n",
    "            \tt = temp1[j+1]-temp1[j] # Comparing current Diff with the last updated Diff Max\n",
    "\n",
    "        output[k] = t # Storing the 2nd Diff Max for channel k\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/14\n",
    "\n",
    "\n",
    "\n",
    "def wrapper1(a):\n",
    "    kurtosis =  my_kurtosis(a)\n",
    "    sec_diff_mean = secDiffMean(a)\n",
    "    sec_diff_max  = secDiffMax(a)\n",
    "    return kurtosis,sec_diff_mean,sec_diff_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient of Varaition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coeff_var(a):\n",
    "    b = a #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    k = 0; #For counting the current row no.\n",
    "    for i in b:\n",
    "        mean_i = np.mean(i) #Saving the mean of array i\n",
    "        std_i = np.std(i) #Saving the standard deviation of array i\n",
    "        output[k] = std_i/mean_i #computing coefficient of variation\n",
    "        k=k+1\n",
    "    return np.sum(output)/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Skewness , 1st Difference Mean, 1st Difference Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skewness(arr):\n",
    "    data = arr \n",
    "    skew_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    index = 0; #current cell position in the output array\n",
    "   \n",
    "    for i in data:\n",
    "        skew_array[index]=sp.stats.skew(i,axis=0,bias=True)\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(skew_array)/14\n",
    "\n",
    "\n",
    "def first_diff_mean(arr):\n",
    "    data = arr \n",
    "    diff_mean_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    index = 0; #current cell position in the output array\n",
    "   \n",
    "    for i in data:\n",
    "        sum=0.0#initializing the sum at the start of each iteration\n",
    "        for j in range(len(i)-1):\n",
    "            sum += abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "           \n",
    "        diff_mean_array[index]=sum/(len(i)-1)\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(diff_mean_array)/14\n",
    "\n",
    "\n",
    "def first_diff_max(arr):\n",
    "    data = arr \n",
    "    diff_max_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    first_diff = np.zeros(len(data[0])-1)#Initialinling the array as all 0s \n",
    "    index = 0; #current cell position in the output array\n",
    "   \n",
    "    for i in data:\n",
    "        max=0.0#initializing at the start of each iteration\n",
    "        for j in range(len(i)-1):\n",
    "            first_diff[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "            if first_diff[j]>max: \n",
    "                max=first_diff[j] # finding the maximum of the first differences\n",
    "        diff_max_array[index]=max\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(diff_max_array)/14\n",
    "\n",
    "\n",
    "def wrapper2(arr):\n",
    "    skew   = skewness(arr)\n",
    "    fdmean = first_diff_mean(arr)\n",
    "    fdmax  = first_diff_max(arr)\n",
    "    return skew,fdmean,fdmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet_features(epoch):\n",
    "    cA_values = []\n",
    "    cD_values = []\n",
    "    cA_mean = []\n",
    "    cA_std = []\n",
    "    cA_Energy =[]\n",
    "    cD_mean = []\n",
    "    cD_std = []\n",
    "    cD_Energy = []\n",
    "    Entropy_D = []\n",
    "    Entropy_A = []\n",
    "    for i in range(14):\n",
    "        cA,cD=pywt.dwt(epoch[i,:],'coif1')\n",
    "        cA_values.append(cA)\n",
    "        cD_values.append(cD)\t\t#calculating the coefficients of wavelet transform.\n",
    "    for x in range(14):   \n",
    "        cA_mean.append(np.mean(cA_values[x]))\n",
    "        cA_std.append(np.std(cA_values[x]))\n",
    "        cA_Energy.append(np.sum(np.square(cA_values[x])))\n",
    "        cD_mean.append(np.mean(cD_values[x]))\t\t# mean and standard deviation values of coefficents of each channel is stored .\n",
    "        cD_std.append(np.std(cD_values[x]))\n",
    "        cD_Energy.append(np.sum(np.square(cD_values[x])))\n",
    "        Entropy_D.append(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x]))))\n",
    "        Entropy_A.append(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x]))))\n",
    "    return np.sum(cA_mean)/14,np.sum(cA_std)/14,np.sum(cD_mean)/14,np.sum(cD_std)/14,np.sum(cA_Energy)/14,np.sum(cD_Energy)/14,np.sum(Entropy_A)/14,np.sum(Entropy_D)/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and Mean of Vertex to Vertex Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "def first_diff(i):\n",
    "    b=i\n",
    "    \n",
    "    \n",
    "    out = np.zeros(len(b))\n",
    "    \n",
    "    for j in range(len(i)):\n",
    "        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n",
    "        \n",
    "        j=j+1\n",
    "        c=out[1:len(out)]\n",
    "    return c\n",
    "\n",
    "#first_diff(s)\n",
    "\n",
    "def slope_mean(p):\n",
    "    b = p #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    res = np.zeros(len(b)-1)\n",
    "    \n",
    "    k = 0; #For counting the current row no.\n",
    "    for i in b:\n",
    "        x=i\n",
    "        amp_max = i[argrelextrema(x, np.greater)[0]]\n",
    "        t_max = argrelextrema(x, np.greater)[0]\n",
    "        amp_min = i[argrelextrema(x, np.less)[0]]\n",
    "        t_min = argrelextrema(x, np.less)[0]\n",
    "        t = np.concatenate((t_max,t_min),axis=0)\n",
    "        t.sort()#sort on the basis of time\n",
    "\n",
    "        h=0\n",
    "        amp = np.zeros(len(t))\n",
    "        res = np.zeros(len(t)-1)\n",
    "        for l in range(len(t)):\n",
    "            amp[l]=i[t[l]]\n",
    "           \n",
    "        \n",
    "        amp_diff = first_diff(amp)\n",
    "        \n",
    "        t_diff = first_diff(t)\n",
    "        \n",
    "        for q in range(len(amp_diff)):\n",
    "            res[q] = amp_diff[q]/t_diff[q]         \n",
    "        output[k] = np.mean(res) \n",
    "        k=k+1\n",
    "    return np.sum(output)/14\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def first_diff(i):\n",
    "    b=i\n",
    "    \n",
    "    \n",
    "    out = np.zeros(len(b))\n",
    "    \n",
    "    for j in range(len(i)):\n",
    "        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n",
    "        \n",
    "        j=j+1\n",
    "        c=out[1:len(out)]\n",
    "    return c #returns first diff\n",
    "\n",
    "\n",
    "def slope_var(p):\n",
    "    b = p #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    res = np.zeros(len(b)-1)\n",
    "    \n",
    "    k = 0; #For counting the current row no.\n",
    "    for i in b:\n",
    "        x=i\n",
    "        amp_max = i[argrelextrema(x, np.greater)[0]]#storing maxima value\n",
    "        t_max = argrelextrema(x, np.greater)[0]#storing time for maxima\n",
    "        amp_min = i[argrelextrema(x, np.less)[0]]#storing minima value\n",
    "        t_min = argrelextrema(x, np.less)[0]#storing time for minima value\n",
    "        t = np.concatenate((t_max,t_min),axis=0) #making a single matrix of all matrix\n",
    "        t.sort() #sorting according to time\n",
    "\n",
    "        h=0\n",
    "        amp = np.zeros(len(t))\n",
    "        res = np.zeros(len(t)-1)\n",
    "        for l in range(len(t)):\n",
    "            amp[l]=i[t[l]]\n",
    "           \n",
    "        \n",
    "        amp_diff = first_diff(amp)\n",
    "        \n",
    "        t_diff = first_diff(t)\n",
    "        \n",
    "        for q in range(len(amp_diff)):\n",
    "            res[q] = amp_diff[q]/t_diff[q] #calculating slope        \n",
    "    \n",
    "        output[k] = np.var(res) \n",
    "        k=k+1#counting k\n",
    "    return np.sum(output)/14\n",
    "\n",
    "def wrapper3(epoch):\n",
    "    var1 = slope_mean(epoch)\n",
    "    var2 = slope_var(epoch)\n",
    "    return var1,var2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT features(Max Power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def maxPwelch(data_win,Fs):\n",
    " \n",
    "    \n",
    "    BandF = [0.1, 3, 7, 12, 30]\n",
    "    PMax = np.zeros([14,(len(BandF)-1)]);\n",
    "    \n",
    "    for j in range(14):\n",
    "        f,Psd = signal.welch(data_win[j,:], Fs)\n",
    "        \n",
    "        for i in range(len(BandF)-1):\n",
    "            fr = np.where((f>BandF[i]) & (f<=BandF[i+1]))\n",
    "            PMax[j,i] = np.max(Psd[fr])\n",
    "    \n",
    "    return np.sum(PMax[:,0])/14,np.sum(PMax[:,1])/14,np.sum(PMax[:,2])/14,np.sum(PMax[:,3])/14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shanon Entropy and Entropy Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def entropy(labels): # Shanon Entropy\n",
    "    \"\"\" Computes entropy of 0-1 vector. \"\"\"\n",
    "    n_labels = len(labels)\n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts[np.nonzero(counts)] / n_labels\n",
    "    n_classes = len(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "    return - np.sum(probs * np.log(probs)) / np.log(n_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model- Yule Walker Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autogressiveModelParameters(labels):\n",
    "    b_labels = len(labels)\n",
    "    feature = []\n",
    "    for i in range(14):\n",
    "        coeff, sig = alg.AR_est_YW(labels[i,:], 11,)\n",
    "        feature.append(coeff)\n",
    "    a = []     \n",
    "    for i in range(11):\n",
    "        a.append(np.sum(feature[:][i])/14)\n",
    "     \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model- Burg Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autogressiveModelParametersBurg(labels):\n",
    "    feature = []\n",
    "    feature1 = []\n",
    "    model_order = 3\n",
    "    for i in range(14):\n",
    "        AR, rho, ref = arburg(labels[i], model_order)\n",
    "        feature.append(AR);\n",
    "    for j in range(14):\n",
    "        for i in range(model_order):\n",
    "            feature1.append(feature[j][i])\n",
    "\n",
    "    return feature1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idlefiles  = [f for f in listdir('Training-Data/Idle') if isfile(join('Training-Data/Idle', f))] \n",
    "OneBackfiles = [f for f in listdir('Training-Data/1-Back') if isfile(join('Training-Data/1-Back', f))]\n",
    "TwoBackfiles = [f for f in listdir('Training-Data/2-Back') if isfile(join('Training-Data/2-Back', f))]\n",
    "files = []\n",
    "\n",
    "for i in idlefiles:\n",
    "    files.append([i,'Idle'])\n",
    "    \n",
    "for i in OneBackfiles:\n",
    "    files.append([i,'1-Back'])\n",
    "\n",
    "for i in TwoBackfiles:\n",
    "    files.append([i,'2-Back'])\n",
    "\n",
    "    \n",
    "mypath = 'Training-Data/'\n",
    "csvfile = \"Features/features.csv\"\n",
    "\n",
    "with open(csvfile, \"a\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(names) \n",
    "    for counter in range(len(files)):\n",
    "        subfolder =  files[counter][1]\n",
    "        tag = files[counter][1] \n",
    "        data_path = mypath + subfolder +'/'+files[counter][0]\n",
    "        \n",
    "        rows = csv.reader(open(data_path))\n",
    "        sigbufs = [l for l in rows]\n",
    "        sigbufs = np.array(sigbufs)\n",
    "        sigbufs = sigbufs.transpose()\n",
    "        sigbufs = sigbufs.astype(float)\n",
    "\n",
    "        for i in np.arange(1,150,3):\n",
    "            features = []\n",
    "            epoch = sigbufs[:,i*128:(i+3)*128]\n",
    "            if len(epoch[0]) == 0:\n",
    "                break\n",
    "            \n",
    "            # Hjorth Parameters\n",
    "            feature_list = hjorth(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "        \n",
    "            #Kurtosis , 2nd Diff Mean, 2nd Diff Max\n",
    "            feature_list = wrapper1(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "            \n",
    "            #Coeffeicient of Variation\n",
    "            feat = coeff_var(epoch)\n",
    "            features.append(feat)\n",
    "            \n",
    "            #Skewness , 1st Difference Mean, 1st Difference Max\n",
    "            feature_list = wrapper2(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "            \n",
    "            \n",
    "            # wavelet transform features \n",
    "            feature_list = wavelet_features(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "        \n",
    "        \n",
    "            # Variance and mean of Vertex to Vertex Slope\n",
    "            feature_list = wrapper3(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "            \n",
    "            \n",
    "            #Fast Fourier Transform features(Max Power)\n",
    "            feature_list  =  maxPwelch(epoch,128)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "        \n",
    "            #Autoregressive model Coefficients\n",
    "            feature_list = autogressiveModelParametersBurg(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat.real)\n",
    "            \n",
    "            features.append(tag);\n",
    "        \n",
    "            writer.writerow(features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization( Wait till the csv file gets populated then run the code below after the features are extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = csv.reader(open('Features/features.csv')) # Here your csv file\n",
    "lines = [l for l in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(lines[1])-1):  \n",
    "    columns = []\n",
    "    for j in range(1,len(lines)):\n",
    "        columns.append(float(lines[j][i]))\n",
    "    mean = np.mean(columns,axis = 0)\n",
    "    std_dev  = np.std(columns,axis = 0)\n",
    "    \n",
    "    for j in range(1,len(lines)):\n",
    "        lines[j][i] = (float(lines[j][i])-mean)/std_dev\n",
    "\n",
    "writer = csv.writer(open('Features/Normalizedfeatures.csv', 'wb')) # This file will store the normalized features\n",
    "writer.writerows(lines)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
